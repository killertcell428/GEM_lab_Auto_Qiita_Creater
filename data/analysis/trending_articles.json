{
  "fetched_at": "2025-12-11T17:51:16.407393",
  "articles": [
    {
      "rendered_body": "<h1 data-sourcepos=\"1:1-1:17\">\n<span id=\"ms-dosとは\" class=\"fragment\"></span><a href=\"#ms-dos%E3%81%A8%E3%81%AF\"><i class=\"fa fa-link\"></i></a>MS-DOSとは？</h1>\n<p data-sourcepos=\"2:1-3:119\">Microsoftが1985年ごろから開発していた、Windowsの前身となるOSです。<br>\nコマンドラインでの操作がメインでした。(現代で言うコマンドプロンプトみたいな感じ)</p>\n<p data-sourcepos=\"5:1-5:113\">余談ですが、Windowsはもともと<strong>MS-DOSのアプリケーション</strong>として存在していました。</p>\n<h1 data-sourcepos=\"7:1-7:32\">\n<span id=\"オープンソースらしい\" class=\"fragment\"></span><a href=\"#%E3%82%AA%E3%83%BC%E3%83%97%E3%83%B3%E3%82%BD%E3%83%BC%E3%82%B9%E3%82%89%E3%81%97%E3%81%84\"><i class=\"fa fa-link\"></i></a>オープンソースらしい</h1>\n<p data-sourcepos=\"8:1-8:39\"><iframe id=\"qiita-embed-content__e5de96feb7f0c3e537f40ec02896ab64\" src=\"https://qiita.com/embed-contents/link-card#qiita-embed-content__e5de96feb7f0c3e537f40ec02896ab64\" data-content=\"https%3A%2F%2Fgithub.com%2Fmicrosoft%2FMS-DOS.git\" frameborder=\"0\" scrolling=\"no\" loading=\"lazy\" style=\"width:100%;\" height=\"29\">\n</iframe>\n</p>\n<p data-sourcepos=\"10:1-11:54\">なんとGitHubにソースコードが公開されています。<br>\nリークとかじゃなくてMicrosoft公式から。</p>\n<p data-sourcepos=\"13:1-13:83\">OS周りの勉強をしたい人は一度見てみるといいかもしれません</p>\n<hr data-sourcepos=\"15:1-16:0\">\n<p data-sourcepos=\"17:1-17:66\">最後まで読んでいただきありがとうございます！</p>\n",
      "body": "# MS-DOSとは？\nMicrosoftが1985年ごろから開発していた、Windowsの前身となるOSです。\nコマンドラインでの操作がメインでした。(現代で言うコマンドプロンプトみたいな感じ)\n\n余談ですが、Windowsはもともと**MS-DOSのアプリケーション**として存在していました。\n\n# オープンソースらしい\nhttps://github.com/microsoft/MS-DOS.git\n\nなんとGitHubにソースコードが公開されています。\nリークとかじゃなくてMicrosoft公式から。\n\nOS周りの勉強をしたい人は一度見てみるといいかもしれません\n\n---\n\n最後まで読んでいただきありがとうございます！\n",
      "coediting": false,
      "comments_count": 0,
      "created_at": "2025-12-11T17:47:23+09:00",
      "group": null,
      "id": "170d2f3f6a27e6422654",
      "likes_count": 0,
      "private": false,
      "reactions_count": 0,
      "stocks_count": 0,
      "tags": [
        {
          "name": "OpenSource",
          "versions": []
        },
        {
          "name": "MS-DOS",
          "versions": []
        }
      ],
      "title": "MS-DOSがオープンソースらしい",
      "updated_at": "2025-12-11T17:47:23+09:00",
      "url": "https://qiita.com/Cheesecake2960/items/170d2f3f6a27e6422654",
      "user": {
        "description": "たまにQiitaに現れて、記事を投稿してます。\r\nPythonが好きです。",
        "facebook_id": "",
        "followees_count": 9,
        "followers_count": 5,
        "github_login_name": "Cheesecake2960",
        "id": "Cheesecake2960",
        "items_count": 50,
        "linkedin_id": "",
        "location": "日本",
        "name": "",
        "organization": "",
        "permanent_id": 3930283,
        "profile_image_url": "https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/3930283/profile-images/1733385927",
        "team_only": false,
        "twitter_screen_name": null,
        "website_url": ""
      },
      "page_views_count": null,
      "team_membership": null,
      "organization_url_name": null,
      "slide": false,
      "_source": "trending_by_likes"
    },
    {
      "rendered_body": "<h1 data-sourcepos=\"1:1-1:8\">\n<span id=\"概要\" class=\"fragment\"></span><a href=\"#%E6%A6%82%E8%A6%81\"><i class=\"fa fa-link\"></i></a>概要</h1>\n<p data-sourcepos=\"3:1-3:66\">Geminiでススキと遊ぶ魔法少女を描いてみました。</p>\n<h1 data-sourcepos=\"5:1-5:8\">\n<span id=\"実装\" class=\"fragment\"></span><a href=\"#%E5%AE%9F%E8%A3%85\"><i class=\"fa fa-link\"></i></a>実装</h1>\n<p data-sourcepos=\"7:1-7:60\">プロンプトと実行結果は以下の通りでした。</p>\n<div class=\"code-frame\" data-lang=\"text\" data-sourcepos=\"9:1-11:3\"><div class=\"highlight\"><pre><code>ススキと遊ぶ魔法少女を描いてください。\n</code></pre></div></div>\n<p data-sourcepos=\"13:1-13:157\"><a href=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F3192024%2Fd1f451e6-5618-4e3e-a222-4715b7ec325c.jpeg?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=c90979fc9231e673241b86582b69b95d\" target=\"_blank\" rel=\"nofollow noopener\"><img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F3192024%2Fd1f451e6-5618-4e3e-a222-4715b7ec325c.jpeg?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=c90979fc9231e673241b86582b69b95d\" alt=\"ススキと遊ぶ魔法少女_20251211.JPG\" srcset=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F3192024%2Fd1f451e6-5618-4e3e-a222-4715b7ec325c.jpeg?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;w=1400&amp;fit=max&amp;s=34dc78beca49b797a9afff5eeb187c36 1x\" data-canonical-src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/3192024/d1f451e6-5618-4e3e-a222-4715b7ec325c.jpeg\" loading=\"lazy\"></a></p>\n<h1 data-sourcepos=\"15:1-15:11\">\n<span id=\"まとめ\" class=\"fragment\"></span><a href=\"#%E3%81%BE%E3%81%A8%E3%82%81\"><i class=\"fa fa-link\"></i></a>まとめ</h1>\n<p data-sourcepos=\"17:1-17:57\">可愛い。綺麗かも。何かの役に立てばと。</p>\n",
      "body": "# 概要\n\nGeminiでススキと遊ぶ魔法少女を描いてみました。\n\n# 実装\n\nプロンプトと実行結果は以下の通りでした。\n\n```\nススキと遊ぶ魔法少女を描いてください。\n```\n\n![ススキと遊ぶ魔法少女_20251211.JPG](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/3192024/d1f451e6-5618-4e3e-a222-4715b7ec325c.jpeg)\n\n# まとめ\n\n可愛い。綺麗かも。何かの役に立てばと。\n",
      "coediting": false,
      "comments_count": 0,
      "created_at": "2025-12-11T17:47:22+09:00",
      "group": null,
      "id": "8f3f16a60697fab3f9d8",
      "likes_count": 0,
      "private": false,
      "reactions_count": 0,
      "stocks_count": 0,
      "tags": [
        {
          "name": "Gemini",
          "versions": []
        }
      ],
      "title": "Geminiでススキと遊ぶ魔法少女を描いてみた。",
      "updated_at": "2025-12-11T17:47:22+09:00",
      "url": "https://qiita.com/nori-channel/items/8f3f16a60697fab3f9d8",
      "user": {
        "description": "エンジニア。プログラマ。システム管理者。データサイエンティスト。フルスタックエンジニアを目指して…。",
        "facebook_id": "",
        "followees_count": 155,
        "followers_count": 161,
        "github_login_name": null,
        "id": "nori-channel",
        "items_count": 832,
        "linkedin_id": "",
        "location": "日本",
        "name": "のりちゃんねる",
        "organization": "",
        "permanent_id": 3192024,
        "profile_image_url": "https://s3-ap-northeast-1.amazonaws.com/qiita-image-store/0/3192024/5583094902ba528de06d89d3d2c028dac1a8159f/large.png?1676989244",
        "team_only": false,
        "twitter_screen_name": null,
        "website_url": "https://www.youtube.com/@nori-channel"
      },
      "page_views_count": null,
      "team_membership": null,
      "organization_url_name": null,
      "slide": false,
      "_source": "trending_by_likes"
    },
    {
      "rendered_body": "<p data-sourcepos=\"1:1-1:102\">この記事は <a href=\"URL_PLACEHOLDER\">Computer Society Advent Calendar 2025</a> の25日目の記事です。</p>\n<hr data-sourcepos=\"3:1-4:0\">\n<h1 data-sourcepos=\"5:1-5:14\">\n<span id=\"はじめに\" class=\"fragment\"></span><a href=\"#%E3%81%AF%E3%81%98%E3%82%81%E3%81%AB\"><i class=\"fa fa-link\"></i></a>はじめに</h1>\n<p data-sourcepos=\"6:1-6:216\">AMD Open Robotic Hackthonに参加して、なんと<strong>3位に入賞</strong>しました！この記事では、ハッカソンの概要や、私たちが作った「回転寿司ロボット」について紹介します。</p>\n<h1 data-sourcepos=\"8:1-8:37\">\n<span id=\"1-amd-open-robotic-hackthon-とは\" class=\"fragment\"></span><a href=\"#1-amd-open-robotic-hackthon-%E3%81%A8%E3%81%AF\"><i class=\"fa fa-link\"></i></a>1. AMD Open Robotic Hackthon とは</h1>\n<p data-sourcepos=\"9:1-9:254\">AMD Open Robotic Hackthonは、AMDが主催し、Hugging Faceをはじめとする企業が協賛するロボットをお題にしたハッカソンです。今回は東京とパリの2会場で同時開催されました（おそらく初開催！）。</p>\n<ul data-sourcepos=\"11:1-13:0\">\n<li data-sourcepos=\"11:1-11:74\"><a href=\"https://huggingface.co/blog/amd/openroboticshackathon\" rel=\"nofollow noopener\" target=\"_blank\">公式ブログ</a></li>\n<li data-sourcepos=\"12:1-13:0\"><a href=\"https://amdroboticshackathon.datamonsters.com/ja-jp\" rel=\"nofollow noopener\" target=\"_blank\">イベントページ</a></li>\n</ul>\n<p data-sourcepos=\"14:1-14:53\"><iframe id=\"qiita-embed-content__de721a13d39c3ac42d0374412cf2677b\" src=\"https://qiita.com/embed-contents/link-card#qiita-embed-content__de721a13d39c3ac42d0374412cf2677b\" data-content=\"https%3A%2F%2Fhuggingface.co%2Fblog%2Famd%2Fopenroboticshackathon\" frameborder=\"0\" scrolling=\"no\" loading=\"lazy\" style=\"width:100%;\" height=\"29\">\n</iframe>\n</p>\n<p data-sourcepos=\"16:1-16:51\"><iframe id=\"qiita-embed-content__8b764a84556a17e16d403d67099409f4\" src=\"https://qiita.com/embed-contents/link-card#qiita-embed-content__8b764a84556a17e16d403d67099409f4\" data-content=\"https%3A%2F%2Famdroboticshackathon.datamonsters.com%2Fja-jp\" frameborder=\"0\" scrolling=\"no\" loading=\"lazy\" style=\"width:100%;\" height=\"29\">\n</iframe>\n</p>\n<h2 data-sourcepos=\"17:1-17:34\">\n<span id=\"11-環境や設備について\" class=\"fragment\"></span><a href=\"#11-%E7%92%B0%E5%A2%83%E3%82%84%E8%A8%AD%E5%82%99%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6\"><i class=\"fa fa-link\"></i></a>1.1 環境や設備について</h2>\n<p data-sourcepos=\"18:1-19:96\">このハッカソンの特徴は、今世界中で最も注目が集まっている（はず！）オープンソースのロボットライブラリ <a href=\"https://github.com/huggingface/lerobot\" rel=\"nofollow noopener\" target=\"_blank\">huggingface/lerobot</a> を使うことです。<br>\nデータ収集からモデル学習までを手軽に行える環境が整っていました。</p>\n<p data-sourcepos=\"21:1-21:75\">ハッカソン運営から提供された機材はこんな感じです。</p>\n<ol data-sourcepos=\"23:1-27:0\">\n<li data-sourcepos=\"23:1-23:103\">\n<strong>ロボットアーム</strong>: <a href=\"https://huggingface.co/docs/lerobot/so101\" rel=\"nofollow noopener\" target=\"_blank\">LeRobot SO-101</a> (1セット)</li>\n<li data-sourcepos=\"24:1-24:63\">\n<strong>PC</strong>: Laptop ASUS Vivobook S 14 (Ryzen AI 9 HX 370搭載)</li>\n<li data-sourcepos=\"25:1-25:77\">\n<strong>学習環境</strong>: ROCm cloud インスタンス (1チームにつき2つ)</li>\n<li data-sourcepos=\"26:1-27:0\">\n<strong>その他</strong>: Webカメラ, スタンド, クランプなどのツール</li>\n</ol>\n<div>\n  <table>\n    <tr>\n      <td><a href=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fraw.githubusercontent.com%2Fhuggingface%2Flerobot%2Fmain%2Fmedia%2Fso101%2Fso101.webp?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=d9fc142fe852e1a027388bdf153a5517\" target=\"_blank\" rel=\"nofollow noopener\"><img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fraw.githubusercontent.com%2Fhuggingface%2Flerobot%2Fmain%2Fmedia%2Fso101%2Fso101.webp?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=d9fc142fe852e1a027388bdf153a5517\" alt=\"SO-101 follower arm\" title=\"SO-101 follower arm\" width=\"90%\" srcset=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fraw.githubusercontent.com%2Fhuggingface%2Flerobot%2Fmain%2Fmedia%2Fso101%2Fso101.webp?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;w=1400&amp;fit=max&amp;s=a1af8f6d3b6f9a24098c15f76c8a8fad 1x\" data-canonical-src=\"https://raw.githubusercontent.com/huggingface/lerobot/main/media/so101/so101.webp\" loading=\"lazy\"></a></td>\n      <td><a href=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fraw.githubusercontent.com%2Fhuggingface%2Flerobot%2Fmain%2Fmedia%2Fso101%2Fso101-leader.webp?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=a293bfc59146ba7ed1fd74483df28d5c\" target=\"_blank\" rel=\"nofollow noopener\"><img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fraw.githubusercontent.com%2Fhuggingface%2Flerobot%2Fmain%2Fmedia%2Fso101%2Fso101-leader.webp?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=a293bfc59146ba7ed1fd74483df28d5c\" alt=\"SO-101 leader arm\" title=\"SO-101 leader arm\" width=\"90%\" srcset=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fraw.githubusercontent.com%2Fhuggingface%2Flerobot%2Fmain%2Fmedia%2Fso101%2Fso101-leader.webp?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;w=1400&amp;fit=max&amp;s=e0797bd3cfb2756f5e127e2d272369cc 1x\" data-canonical-src=\"https://raw.githubusercontent.com/huggingface/lerobot/main/media/so101/so101-leader.webp\" loading=\"lazy\"></a></td>\n    </tr>\n  </table>\n</div>\n<p data-sourcepos=\"37:1-37:38\"><iframe id=\"qiita-embed-content__cdbaafe87ab20353061e0d15d68071e1\" src=\"https://qiita.com/embed-contents/link-card#qiita-embed-content__cdbaafe87ab20353061e0d15d68071e1\" data-content=\"https%3A%2F%2Fgithub.com%2Fhuggingface%2Flerobot\" frameborder=\"0\" scrolling=\"no\" loading=\"lazy\" style=\"width:100%;\" height=\"29\">\n</iframe>\n</p>\n<h2 data-sourcepos=\"39:1-39:25\">\n<span id=\"12-何をするの\" class=\"fragment\"></span><a href=\"#12-%E4%BD%95%E3%82%92%E3%81%99%E3%82%8B%E3%81%AE\"><i class=\"fa fa-link\"></i></a>1.2 何をするの？</h2>\n<p data-sourcepos=\"40:1-40:144\">今回のハッカソンでは、約45時間という限られた時間内に2つのミッションをクリアする必要がありました。</p>\n<h3 data-sourcepos=\"42:1-42:44\">\n<span id=\"1-lerobotを使ったhello-world\" class=\"fragment\"></span><a href=\"#1-lerobot%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%9Fhello-world\"><i class=\"fa fa-link\"></i></a>1. Lerobotを使った「Hello World!」</h3>\n<p data-sourcepos=\"43:1-44:217\">まずはLeRobot SO-101に慣れるためのミッションです。<br>\nデータ収集 → 学習 → 推論 という一連の流れを体験するのが目的。特に意味のあるタスクでなくても、アームで何か持ち上げたり移動させたりできればOKです。</p>\n<h3 data-sourcepos=\"46:1-46:55\">\n<span id=\"2-現実世界の課題を解決する本番\" class=\"fragment\"></span><a href=\"#2-%E7%8F%BE%E5%AE%9F%E4%B8%96%E7%95%8C%E3%81%AE%E8%AA%B2%E9%A1%8C%E3%82%92%E8%A7%A3%E6%B1%BA%E3%81%99%E3%82%8B%E6%9C%AC%E7%95%AA\"><i class=\"fa fa-link\"></i></a>2. 現実世界の課題を解決する（本番）</h3>\n<p data-sourcepos=\"47:1-47:129\">こっちがメインです。実世界で役に立ちそうなタスクを自分たちで考えて、実際に実装します。</p>\n<ol data-sourcepos=\"48:1-52:0\">\n<li data-sourcepos=\"48:1-48:34\">ロボットでデータ収集</li>\n<li data-sourcepos=\"49:1-49:10\">学習</li>\n<li data-sourcepos=\"50:1-50:37\">推論して、デモを見せる</li>\n<li data-sourcepos=\"51:1-52:0\">データセット、モデルの重みそして学習のログを公開・提出</li>\n</ol>\n<h2 data-sourcepos=\"53:1-53:19\">\n<span id=\"13-審査基準\" class=\"fragment\"></span><a href=\"#13-%E5%AF%A9%E6%9F%BB%E5%9F%BA%E6%BA%96\"><i class=\"fa fa-link\"></i></a>1.3 審査基準</h2>\n<p data-sourcepos=\"54:1-54:45\">勝者は100点満点で採点されます。</p>\n<ul data-sourcepos=\"56:1-62:0\">\n<li data-sourcepos=\"56:1-56:106\">\n<strong>成果物提出 (30点)</strong>: レポジトリ、動画、ドキュメントなどがちゃんとあるか</li>\n<li data-sourcepos=\"57:1-62:0\">\n<strong>プロジェクトの中身 (70点)</strong>:\n<ol data-sourcepos=\"58:5-62:0\">\n<li data-sourcepos=\"58:5-58:40\">クリエイティビティ (30)</li>\n<li data-sourcepos=\"59:5-59:34\">技術的な難しさ (20)</li>\n<li data-sourcepos=\"60:5-60:28\">使いやすさ (10)</li>\n<li data-sourcepos=\"61:5-62:0\">実際のユースケース (10)</li>\n</ol>\n</li>\n</ul>\n<h1 data-sourcepos=\"63:1-63:44\">\n<span id=\"2-アイディア回転寿司の大将\" class=\"fragment\"></span><a href=\"#2-%E3%82%A2%E3%82%A4%E3%83%87%E3%82%A3%E3%82%A2%E5%9B%9E%E8%BB%A2%E5%AF%BF%E5%8F%B8%E3%81%AE%E5%A4%A7%E5%B0%86\"><i class=\"fa fa-link\"></i></a>2. アイディア：回転寿司の大将</h1>\n<p data-sourcepos=\"64:1-64:195\">せっかく東京開催だし、日本っぽくて面白いタスクがいいよね、という話になり、チームメンバーから出たアイデアが <strong>「回転寿司」</strong> でした。</p>\n<p data-sourcepos=\"66:1-66:126\">「サーモン」みたいに食べたいネタを言うだけで、ロボットが取ってくれたら最高ですよね。</p>\n<p data-sourcepos=\"68:1-69:42\">理想的な動きはこんなイメージです↓<br>\n（「サーモン」と伝えた場合）</p>\n<p data-sourcepos=\"71:1-71:121\"><a href=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F3632218%2Fac1bfe84-16d4-4bf8-b3a6-03f61ab27e3d.gif?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=7bd1ec6773df5c06217e36cb3e39be8a\" target=\"_blank\" rel=\"nofollow noopener\"><img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F3632218%2Fac1bfe84-16d4-4bf8-b3a6-03f61ab27e3d.gif?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=7bd1ec6773df5c06217e36cb3e39be8a\" alt=\"demo.gif\" srcset=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F3632218%2Fac1bfe84-16d4-4bf8-b3a6-03f61ab27e3d.gif?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;w=1400&amp;fit=max&amp;s=f355ead3994ab7161b84d388c3247cd1 1x\" data-canonical-src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/3632218/ac1bfe84-16d4-4bf8-b3a6-03f61ab27e3d.gif\" loading=\"lazy\"></a></p>\n<h1 data-sourcepos=\"73:1-73:29\">\n<span id=\"3-学習モデルの選定\" class=\"fragment\"></span><a href=\"#3-%E5%AD%A6%E7%BF%92%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E9%81%B8%E5%AE%9A\"><i class=\"fa fa-link\"></i></a>3. 学習モデルの選定</h1>\n<p data-sourcepos=\"74:1-74:194\">やりたいことは「言語指示による条件付け」なのですが、LeRobot公式で提供されているPolicyの中から選ぶとなると、以下の3つが候補になります。</p>\n<ol data-sourcepos=\"76:1-79:0\">\n<li data-sourcepos=\"76:1-76:51\"><a href=\"https://huggingface.co/blog/smolvla\" rel=\"nofollow noopener\" target=\"_blank\">smol VLA</a></li>\n<li data-sourcepos=\"77:1-77:50\"><a href=\"https://huggingface.co/docs/lerobot/pi0\" rel=\"nofollow noopener\" target=\"_blank\">pi0</a></li>\n<li data-sourcepos=\"78:1-79:0\"><a href=\"https://huggingface.co/docs/lerobot/pi05\" rel=\"nofollow noopener\" target=\"_blank\">pi0.5</a></li>\n</ol>\n<p data-sourcepos=\"80:1-81:181\">ただ、今回はLaptopを使って推論させることを考えると、できるだけ軽いモデルを使いたい…。<br>\nさらに、審査基準に「技術的な難しさ」という項目があるため、あえて既存のものではなく<strong>独自のPolicy</strong>を実装することにしました。</p>\n<p data-sourcepos=\"83:1-84:118\">採用したのは、2025年のCoRLで発表されたばかりの <strong><a href=\"https://arxiv.org/abs/2505.21851\" rel=\"nofollow noopener\" target=\"_blank\">Streaming Flow</a></strong> です。<br>\nFlowベースのPolicyなんですが、パラメータサイズが小さく、そ性能が良いのが特徴です。</p>\n<p data-sourcepos=\"86:1-86:155\">※ちなみに私はStreaming Flowに全然詳しくないので、実装と学習まわりはチームの先輩がやってくれました（感謝）。</p>\n<p data-sourcepos=\"88:1-88:407\">lerobot公式から提供されたモデルについて、apiは統一していますので同じデータセットを使って簡単に学習することができます。そのため上記の <a href=\"https://huggingface.co/blog/smolvla\" rel=\"nofollow noopener\" target=\"_blank\">smol VLA</a>, <a href=\"https://huggingface.co/docs/lerobot/pi0\" rel=\"nofollow noopener\" target=\"_blank\">pi0</a>, <a href=\"https://huggingface.co/docs/lerobot/pi05\" rel=\"nofollow noopener\" target=\"_blank\">pi0.5</a> についてすべて学習し、実機でテストしました。</p>\n<h1 data-sourcepos=\"90:1-90:17\">\n<span id=\"4-推論デモ\" class=\"fragment\"></span><a href=\"#4-%E6%8E%A8%E8%AB%96%E3%83%87%E3%83%A2\"><i class=\"fa fa-link\"></i></a>4. 推論デモ</h1>\n<p data-sourcepos=\"91:1-91:296\"><a href=\"https://huggingface.co/blog/smolvla\" rel=\"nofollow noopener\" target=\"_blank\">smol VLA</a>、 <a href=\"https://huggingface.co/docs/lerobot/pi0\" rel=\"nofollow noopener\" target=\"_blank\">pi0</a>、 <a href=\"https://huggingface.co/docs/lerobot/pi05\" rel=\"nofollow noopener\" target=\"_blank\">pi0.5</a>そして最後に streaming flowについて実機テストして対照実験やった結果、自前実装のstreaming flowが勝ちました。</p>\n<p data-sourcepos=\"94:1-94:48\">実際に動かしてみた様子がこちら。</p>\n<p data-sourcepos=\"96:1-97:125\"><strong>「サーモン」を指定した場合:</strong><br>\n<a href=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F3632218%2Fe7510bb2-1be9-491d-b52f-aeb905229307.gif?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=c3ef9c0d0342c90028338c83ac735d4c\" target=\"_blank\" rel=\"nofollow noopener\"><img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F3632218%2Fe7510bb2-1be9-491d-b52f-aeb905229307.gif?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=c3ef9c0d0342c90028338c83ac735d4c\" alt=\"IMG_7388.gif\" srcset=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F3632218%2Fe7510bb2-1be9-491d-b52f-aeb905229307.gif?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;w=1400&amp;fit=max&amp;s=775fda5188ca38b7ae270ec3e9ce776e 1x\" data-canonical-src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/3632218/e7510bb2-1be9-491d-b52f-aeb905229307.gif\" loading=\"lazy\"></a></p>\n<p data-sourcepos=\"99:1-100:134\"><strong>「たまご」を指定した場合:</strong><br>\n<a href=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F3632218%2F659ea6cd-3d5b-4920-a945-468edc717fac.gif?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=b2763514eb390e29f77972a8ff1bff85\" target=\"_blank\" rel=\"nofollow noopener\"><img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F3632218%2F659ea6cd-3d5b-4920-a945-468edc717fac.gif?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=b2763514eb390e29f77972a8ff1bff85\" alt=\"inference_egg (1).gif\" srcset=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F3632218%2F659ea6cd-3d5b-4920-a945-468edc717fac.gif?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;w=1400&amp;fit=max&amp;s=340d390f9df282f875125c15182279aa 1x\" data-canonical-src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/3632218/659ea6cd-3d5b-4920-a945-468edc717fac.gif\" loading=\"lazy\"></a></p>\n<h1 data-sourcepos=\"102:1-102:11\">\n<span id=\"5-結果\" class=\"fragment\"></span><a href=\"#5-%E7%B5%90%E6%9E%9C\"><i class=\"fa fa-link\"></i></a>5. 結果</h1>\n<p data-sourcepos=\"103:1-104:126\">なんと<strong>3位に入賞しました!</strong> 😎<br>\n<a href=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F3632218%2F84cc496b-8c01-488c-8794-3eb877bed789.jpeg?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=136e9ebd80974fa0e6330765f6abc53c\" target=\"_blank\" rel=\"nofollow noopener\"><img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F3632218%2F84cc496b-8c01-488c-8794-3eb877bed789.jpeg?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=136e9ebd80974fa0e6330765f6abc53c\" alt=\"IMG_7420.jpg\" srcset=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F3632218%2F84cc496b-8c01-488c-8794-3eb877bed789.jpeg?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;w=1400&amp;fit=max&amp;s=06b4d8a306c66dbee6ebb91915a3ae65 1x\" data-canonical-src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/3632218/84cc496b-8c01-488c-8794-3eb877bed789.jpeg\" loading=\"lazy\"></a></p>\n<p data-sourcepos=\"107:1-107:160\">ただ、実は本番ジャッジメントのデモでは、なぜかモデルが正常に動かなくなってしまいました（本番に弱い…😭）。</p>\n<p data-sourcepos=\"109:1-109:309\">はっきりした原因は不明ですが、おそらく <strong>「光と影」に過学習</strong> してしまったんじゃないかと思います。データ収集をした昼間と違って、本番のデモは日が沈んだ後だったので、照明環境の違いで推論が狂った可能性高いです。</p>\n<p data-sourcepos=\"111:1-111:126\">それでも入賞できた理由を分析すると、おそらくこのあたりが評価されたのかなと思います。</p>\n<ol data-sourcepos=\"113:1-116:0\">\n<li data-sourcepos=\"113:1-113:321\">\n<strong>技術的な難易度</strong>: 短期間で自前実装したモデル（Streaming Flow）は、smol vlaより1000倍くらいパラメータが小さく、集積GPUのLaptopでもサクサク動いたこと。そして <strong>「回転」</strong> という難しいダイナミックスシステムにうまく対応できたこと</li>\n<li data-sourcepos=\"114:1-114:88\">\n<strong>証拠動画</strong>: 成功したときの動画をちゃんと撮ってあったこと</li>\n<li data-sourcepos=\"115:1-116:0\">\n<strong>コンセプト</strong>: アイディア自体が面白く、現実世界でのユースケース（自動化）もイメージしやすかったこと</li>\n</ol>\n<h1 data-sourcepos=\"117:1-117:29\">\n<span id=\"6-プロジェクト詳細\" class=\"fragment\"></span><a href=\"#6-%E3%83%97%E3%83%AD%E3%82%B8%E3%82%A7%E3%82%AF%E3%83%88%E8%A9%B3%E7%B4%B0\"><i class=\"fa fa-link\"></i></a>6. プロジェクト詳細</h1>\n<p data-sourcepos=\"118:1-118:51\">作ったものは以下で公開しています。</p>\n<h2 data-sourcepos=\"120:1-120:28\">\n<span id=\"61-学習済みモデル\" class=\"fragment\"></span><a href=\"#61-%E5%AD%A6%E7%BF%92%E6%B8%88%E3%81%BF%E3%83%A2%E3%83%87%E3%83%AB\"><i class=\"fa fa-link\"></i></a>6.1 学習済みモデル</h2>\n<p data-sourcepos=\"121:1-121:54\"><iframe id=\"qiita-embed-content__65b3d23552b0df010d6721c4acc2b384\" src=\"https://qiita.com/embed-contents/link-card#qiita-embed-content__65b3d23552b0df010d6721c4acc2b384\" data-content=\"https%3A%2F%2Fhuggingface.co%2FMamo1031%2Fsushi-taisho-streaming\" frameborder=\"0\" scrolling=\"no\" loading=\"lazy\" style=\"width:100%;\" height=\"29\">\n</iframe>\n</p>\n<h2 data-sourcepos=\"123:1-123:14\">\n<span id=\"62-dataset\" class=\"fragment\"></span><a href=\"#62-dataset\"><i class=\"fa fa-link\"></i></a>6.2 Dataset</h2>\n<p data-sourcepos=\"124:1-124:54\"><iframe id=\"qiita-embed-content__8e2fee907f89557a9107b80ba4224784\" src=\"https://qiita.com/embed-contents/link-card#qiita-embed-content__8e2fee907f89557a9107b80ba4224784\" data-content=\"https%3A%2F%2Fhuggingface.co%2Fdatasets%2FMamo1031%2Fsushi_dynamic\" frameborder=\"0\" scrolling=\"no\" loading=\"lazy\" style=\"width:100%;\" height=\"29\">\n</iframe>\n</p>\n<h2 data-sourcepos=\"126:1-126:22\">\n<span id=\"63-リポジトリ\" class=\"fragment\"></span><a href=\"#63-%E3%83%AA%E3%83%9D%E3%82%B8%E3%83%88%E3%83%AA\"><i class=\"fa fa-link\"></i></a>6.3 リポジトリ</h2>\n<p data-sourcepos=\"127:1-127:72\"><iframe id=\"qiita-embed-content__3d2ea136a9adadf011a90b50df108d80\" src=\"https://qiita.com/embed-contents/link-card#qiita-embed-content__3d2ea136a9adadf011a90b50df108d80\" data-content=\"https%3A%2F%2Fgithub.com%2FMamo1031%2FAMD_Robotics_Hackathon_2025_Sushi_Taisho.git\" frameborder=\"0\" scrolling=\"no\" loading=\"lazy\" style=\"width:100%;\" height=\"29\">\n</iframe>\n</p>\n<h1 data-sourcepos=\"129:1-129:11\">\n<span id=\"7-感想\" class=\"fragment\"></span><a href=\"#7-%E6%84%9F%E6%83%B3\"><i class=\"fa fa-link\"></i></a>7. 感想</h1>\n<p data-sourcepos=\"130:1-130:587\">約45時間という制限時間がある中で、ハードウェアの調整、データ収集、学習、テストなど一連のタスクを密に行う必要がありました。とても疲れましたが、すごく楽しかったです。事前学習済みモデルのfinetuningがうまく行かないとか、本番になって動くはずだったモデルが狂い始めるとか(笑)大変なこともたくさんありましたが、チーム全体で協力して、出てきた問題を試行錯誤して解決して行けたというのはすごくいい経験でした。</p>\n<p data-sourcepos=\"133:1-133:132\"><a href=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F3632218%2Fe7ea92b4-ebee-4819-a490-e27f9b183d4e.jpeg?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=7985ecdff5f1ff4977b8627f5f4691d2\" target=\"_blank\" rel=\"nofollow noopener\"><img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F3632218%2Fe7ea92b4-ebee-4819-a490-e27f9b183d4e.jpeg?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=7985ecdff5f1ff4977b8627f5f4691d2\" alt=\"1765269361380.jpeg\" srcset=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F3632218%2Fe7ea92b4-ebee-4819-a490-e27f9b183d4e.jpeg?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;w=1400&amp;fit=max&amp;s=453c55944e9cea0d52d8142eae88142d 1x\" data-canonical-src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/3632218/e7ea92b4-ebee-4819-a490-e27f9b183d4e.jpeg\" loading=\"lazy\"></a></p>\n",
      "body": "この記事は [Computer Society Advent Calendar 2025](URL_PLACEHOLDER) の25日目の記事です。\n\n---\n\n# はじめに\nAMD Open Robotic Hackthonに参加して、なんと**3位に入賞**しました！この記事では、ハッカソンの概要や、私たちが作った「回転寿司ロボット」について紹介します。\n\n# 1. AMD Open Robotic Hackthon とは\nAMD Open Robotic Hackthonは、AMDが主催し、Hugging Faceをはじめとする企業が協賛するロボットをお題にしたハッカソンです。今回は東京とパリの2会場で同時開催されました（おそらく初開催！）。\n\n- [公式ブログ](https://huggingface.co/blog/amd/openroboticshackathon)\n- [イベントページ](https://amdroboticshackathon.datamonsters.com/ja-jp)\n\nhttps://huggingface.co/blog/amd/openroboticshackathon\n\nhttps://amdroboticshackathon.datamonsters.com/ja-jp\n## 1.1 環境や設備について\nこのハッカソンの特徴は、今世界中で最も注目が集まっている（はず！）オープンソースのロボットライブラリ [huggingface/lerobot](https://github.com/huggingface/lerobot) を使うことです。\nデータ収集からモデル学習までを手軽に行える環境が整っていました。\n\nハッカソン運営から提供された機材はこんな感じです。\n\n1.  **ロボットアーム**: [LeRobot SO-101](https://huggingface.co/docs/lerobot/so101) (1セット)\n2.  **PC**: Laptop ASUS Vivobook S 14 (Ryzen AI 9 HX 370搭載)\n3.  **学習環境**: ROCm cloud インスタンス (1チームにつき2つ)\n4.  **その他**: Webカメラ, スタンド, クランプなどのツール\n\n<div align=\"center\">\n  <table>\n    <tr>\n      <td align=\"center\"><img src=\"https://raw.githubusercontent.com/huggingface/lerobot/main/media/so101/so101.webp\" alt=\"SO-101 follower arm\" title=\"SO-101 follower arm\" width=\"90%\"/></td>\n      <td align=\"center\"><img src=\"https://raw.githubusercontent.com/huggingface/lerobot/main/media/so101/so101-leader.webp\" alt=\"SO-101 leader arm\" title=\"SO-101 leader arm\" width=\"90%\"/></td>\n    </tr>\n  </table>\n</div>\n\nhttps://github.com/huggingface/lerobot\n\n## 1.2 何をするの？\n今回のハッカソンでは、約45時間という限られた時間内に2つのミッションをクリアする必要がありました。\n\n### 1. Lerobotを使った「Hello World!」\nまずはLeRobot SO-101に慣れるためのミッションです。\nデータ収集 → 学習 → 推論 という一連の流れを体験するのが目的。特に意味のあるタスクでなくても、アームで何か持ち上げたり移動させたりできればOKです。\n\n### 2. 現実世界の課題を解決する（本番）\nこっちがメインです。実世界で役に立ちそうなタスクを自分たちで考えて、実際に実装します。\n1.  ロボットでデータ収集\n2.  学習\n3.  推論して、デモを見せる\n4.  データセット、モデルの重みそして学習のログを公開・提出\n\n## 1.3 審査基準\n勝者は100点満点で採点されます。\n\n* **成果物提出 (30点)**: レポジトリ、動画、ドキュメントなどがちゃんとあるか\n* **プロジェクトの中身 (70点)**:\n    1.  クリエイティビティ (30)\n    2.  技術的な難しさ (20)\n    3.  使いやすさ (10)\n    4.  実際のユースケース (10)\n\n# 2. アイディア：回転寿司の大将\nせっかく東京開催だし、日本っぽくて面白いタスクがいいよね、という話になり、チームメンバーから出たアイデアが **「回転寿司」** でした。\n\n「サーモン」みたいに食べたいネタを言うだけで、ロボットが取ってくれたら最高ですよね。\n\n理想的な動きはこんなイメージです↓\n（「サーモン」と伝えた場合）\n\n![demo.gif](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/3632218/ac1bfe84-16d4-4bf8-b3a6-03f61ab27e3d.gif)\n\n# 3. 学習モデルの選定\nやりたいことは「言語指示による条件付け」なのですが、LeRobot公式で提供されているPolicyの中から選ぶとなると、以下の3つが候補になります。\n\n1.  [smol VLA](https://huggingface.co/blog/smolvla)\n2.  [pi0](https://huggingface.co/docs/lerobot/pi0)\n3.  [pi0.5](https://huggingface.co/docs/lerobot/pi05)\n\nただ、今回はLaptopを使って推論させることを考えると、できるだけ軽いモデルを使いたい…。\nさらに、審査基準に「技術的な難しさ」という項目があるため、あえて既存のものではなく**独自のPolicy**を実装することにしました。\n\n採用したのは、2025年のCoRLで発表されたばかりの **[Streaming Flow](https://arxiv.org/abs/2505.21851)** です。\nFlowベースのPolicyなんですが、パラメータサイズが小さく、そ性能が良いのが特徴です。\n\n※ちなみに私はStreaming Flowに全然詳しくないので、実装と学習まわりはチームの先輩がやってくれました（感謝）。\n\nlerobot公式から提供されたモデルについて、apiは統一していますので同じデータセットを使って簡単に学習することができます。そのため上記の [smol VLA](https://huggingface.co/blog/smolvla), [pi0](https://huggingface.co/docs/lerobot/pi0), [pi0.5](https://huggingface.co/docs/lerobot/pi05) についてすべて学習し、実機でテストしました。\n\n# 4. 推論デモ\n[smol VLA](https://huggingface.co/blog/smolvla)、 [pi0](https://huggingface.co/docs/lerobot/pi0)、 [pi0.5](https://huggingface.co/docs/lerobot/pi05)そして最後に streaming flowについて実機テストして対照実験やった結果、自前実装のstreaming flowが勝ちました。\n\n\n実際に動かしてみた様子がこちら。\n\n**「サーモン」を指定した場合:**\n![IMG_7388.gif](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/3632218/e7510bb2-1be9-491d-b52f-aeb905229307.gif)\n\n**「たまご」を指定した場合:**\n![inference_egg (1).gif](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/3632218/659ea6cd-3d5b-4920-a945-468edc717fac.gif)\n\n# 5. 結果\nなんと**3位に入賞しました!** 😎\n![IMG_7420.jpg](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/3632218/84cc496b-8c01-488c-8794-3eb877bed789.jpeg)\n\n\nただ、実は本番ジャッジメントのデモでは、なぜかモデルが正常に動かなくなってしまいました（本番に弱い…😭）。\n\nはっきりした原因は不明ですが、おそらく **「光と影」に過学習** してしまったんじゃないかと思います。データ収集をした昼間と違って、本番のデモは日が沈んだ後だったので、照明環境の違いで推論が狂った可能性高いです。\n\nそれでも入賞できた理由を分析すると、おそらくこのあたりが評価されたのかなと思います。\n\n1.  **技術的な難易度**: 短期間で自前実装したモデル（Streaming Flow）は、smol vlaより1000倍くらいパラメータが小さく、集積GPUのLaptopでもサクサク動いたこと。そして **「回転」** という難しいダイナミックスシステムにうまく対応できたこと\n2.  **証拠動画**: 成功したときの動画をちゃんと撮ってあったこと\n3.  **コンセプト**: アイディア自体が面白く、現実世界でのユースケース（自動化）もイメージしやすかったこと\n\n# 6. プロジェクト詳細\n作ったものは以下で公開しています。\n\n## 6.1 学習済みモデル\nhttps://huggingface.co/Mamo1031/sushi-taisho-streaming\n\n## 6.2 Dataset\nhttps://huggingface.co/datasets/Mamo1031/sushi_dynamic\n\n## 6.3 リポジトリ\nhttps://github.com/Mamo1031/AMD_Robotics_Hackathon_2025_Sushi_Taisho.git\n\n# 7. 感想\n約45時間という制限時間がある中で、ハードウェアの調整、データ収集、学習、テストなど一連のタスクを密に行う必要がありました。とても疲れましたが、すごく楽しかったです。事前学習済みモデルのfinetuningがうまく行かないとか、本番になって動くはずだったモデルが狂い始めるとか(笑)大変なこともたくさんありましたが、チーム全体で協力して、出てきた問題を試行錯誤して解決して行けたというのはすごくいい経験でした。\n\n\n![1765269361380.jpeg](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/3632218/e7ea92b4-ebee-4819-a490-e27f9b183d4e.jpeg)\n",
      "coediting": false,
      "comments_count": 0,
      "created_at": "2025-12-11T17:46:36+09:00",
      "group": null,
      "id": "be8eb2fbcb6458e61cbb",
      "likes_count": 0,
      "private": false,
      "reactions_count": 0,
      "stocks_count": 0,
      "tags": [
        {
          "name": "AMD",
          "versions": []
        },
        {
          "name": "PyTorch",
          "versions": []
        },
        {
          "name": "ROCm",
          "versions": []
        },
        {
          "name": "huggingface",
          "versions": []
        },
        {
          "name": "LeRobot",
          "versions": []
        }
      ],
      "title": "AMD Open Robotics Hackathon 参加記",
      "updated_at": "2025-12-11T17:50:35+09:00",
      "url": "https://qiita.com/tetsugo/items/be8eb2fbcb6458e61cbb",
      "user": {
        "description": "",
        "facebook_id": "",
        "followees_count": 1,
        "followers_count": 0,
        "github_login_name": "tetsugo02",
        "id": "tetsugo",
        "items_count": 3,
        "linkedin_id": "",
        "location": "",
        "name": "",
        "organization": "慶應義塾大学理工学部",
        "permanent_id": 3632218,
        "profile_image_url": "https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/3632218/profile-images/1751384836",
        "team_only": false,
        "twitter_screen_name": "tetsugo_",
        "website_url": "https://tetsugo02.github.io/"
      },
      "page_views_count": null,
      "team_membership": null,
      "organization_url_name": null,
      "slide": false,
      "_source": "trending_by_likes"
    },
    {
      "rendered_body": "<h1 data-sourcepos=\"1:1-1:11\">\n<span id=\"初めに\" class=\"fragment\"></span><a href=\"#%E5%88%9D%E3%82%81%E3%81%AB\"><i class=\"fa fa-link\"></i></a>初めに</h1>\n<p data-sourcepos=\"2:1-3:99\">私は逢甲大學 資電學院 資訊工程系の小村と申します。<br>\n上の学部学科は日本の区分で言えば、情報学部・情報学科に相当します。</p>\n<h1 data-sourcepos=\"4:1-4:29\">\n<span id=\"システム開発の動機\" class=\"fragment\"></span><a href=\"#%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E9%96%8B%E7%99%BA%E3%81%AE%E5%8B%95%E6%A9%9F\"><i class=\"fa fa-link\"></i></a>システム開発の動機</h1>\n<p data-sourcepos=\"5:1-7:483\">突然ですが、皆さんは今まで鍵をかけ忘れて家を出てしまったこと、小さい頃鍵を持たずに外出をし帰宅時に鍵が無く、家に入ることが出来ず困ったというような経験をしたことはありませんか？<br>\n私自身、幼い頃に鍵を家に置いたまま学校へ行ってしまい、帰宅しても家へ入れず、近所の公園で待ちぼうけをするということを何度も経験しました。<br>\nそんな幼い頃の辛酸を思い出し、どうすれば鍵の施錠忘れ、鍵の本体の所持忘れをなくすことができるかということを考えたときに、それならば家を出るタイミングにリアルタイムで鍵の閉め忘れ、鍵本体の忘れを通知してくれるそんなシステムを構築することで、これらの問題を解決する事ができるのではと考え、今回のシステムを開発するに至りました。</p>\n<h1 data-sourcepos=\"9:1-9:26\">\n<span id=\"プロジェクト概要\" class=\"fragment\"></span><a href=\"#%E3%83%97%E3%83%AD%E3%82%B8%E3%82%A7%E3%82%AF%E3%83%88%E6%A6%82%E8%A6%81\"><i class=\"fa fa-link\"></i></a>プロジェクト概要</h1>\n<p data-sourcepos=\"10:1-10:75\">下記が作成したシステムのGitHubリポジトリになります。</p>\n<p data-sourcepos=\"12:1-12:31\"><iframe id=\"qiita-embed-content__cd41973538d45b90b8838ac9b7248468\" src=\"https://qiita.com/embed-contents/link-card#qiita-embed-content__cd41973538d45b90b8838ac9b7248468\" data-content=\"https%3A%2F%2Fgithub.com%2FOmura24%2Ftapo\" frameborder=\"0\" scrolling=\"no\" loading=\"lazy\" style=\"width:100%;\" height=\"29\">\n</iframe>\n</p>\n<h3 data-sourcepos=\"14:1-14:28\">\n<span id=\"システムの全体像\" class=\"fragment\"></span><a href=\"#%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E3%81%AE%E5%85%A8%E4%BD%93%E5%83%8F\"><i class=\"fa fa-link\"></i></a>システムの全体像</h3>\n<p data-sourcepos=\"16:1-16:212\">本システムは、2台のTapoカメラ映像をYOLOで解析し、ドアの開閉状態（Open／Close）と鍵本体の有無を同時に判定する、AIベースの鍵持ち忘れ防止システムです。</p>\n<p data-sourcepos=\"18:1-18:243\">外出動作として「ドアが開いた」状態をYOLOが検知すると、同タイミングで鍵置き場の映像を解析し、鍵が室内に残っている場合は、LINE Messaging API Pushにより即時に通知を行います。</p>\n<iframe id=\"qiita-embed-content__0dd257a871fe5ef607c00242af009e01\" src=\"https://qiita.com/embed-contents/mermaid#qiita-embed-content__0dd257a871fe5ef607c00242af009e01\" style=\"width:100%;\" frameborder=\"0\" scrolling=\"no\" loading=\"lazy\" data-content='{\"data\":\"flowchart TB\\n\\n KCAM[鍵置き場カメラ]\\n KYOLO[YOLO 鍵検知]\\n\\n DCAM[玄関カメラ]\\n DYOLO[YOLO ドア開閉判定]\\n\\n STATE[状態判定 外出か 鍵があるか]\\n LINE[鍵忘れ LINE通知]\\n\\n KCAM --&gt; KYOLO\\n DCAM --&gt; DYOLO\\n\\n KYOLO --&gt; STATE\\n DYOLO --&gt; STATE\\n\\n STATE --&gt; LINE\",\"key\":\"213211625a5b146c36a3bd0749ef00d0\"}'>\n</iframe>\n\n<h3 data-sourcepos=\"40:1-40:25\">\n<span id=\"実際の実行画面\" class=\"fragment\"></span><a href=\"#%E5%AE%9F%E9%9A%9B%E3%81%AE%E5%AE%9F%E8%A1%8C%E7%94%BB%E9%9D%A2\"><i class=\"fa fa-link\"></i></a>実際の実行画面</h3>\n<iframe width=\"100%\" height=\"315\" src=\"https://www.youtube.com/embed/TtVnS2ZHVaY?si=Gqyz7ngJv3E17QfC\" frameborder=\"0\" allowfullscreen></iframe>\n<h1 data-sourcepos=\"44:1-44:35\">\n<span id=\"使用デバイス技術構成\" class=\"fragment\"></span><a href=\"#%E4%BD%BF%E7%94%A8%E3%83%87%E3%83%90%E3%82%A4%E3%82%B9%E6%8A%80%E8%A1%93%E6%A7%8B%E6%88%90\"><i class=\"fa fa-link\"></i></a>使用デバイス・技術構成</h1>\n<table data-sourcepos=\"45:1-50:135\">\n<thead>\n<tr data-sourcepos=\"45:1-45:94\">\n<th data-sourcepos=\"45:2-45:14\">分類</th>\n<th data-sourcepos=\"45:16-45:67\">使用機器・技術</th>\n<th data-sourcepos=\"45:69-45:93\">役割</th>\n</tr>\n</thead>\n<tbody>\n<tr data-sourcepos=\"47:1-47:120\">\n<td data-sourcepos=\"47:2-47:16\">カメラ</td>\n<td data-sourcepos=\"47:18-47:61\"><strong>Tapo C210（2台）</strong></td>\n<td data-sourcepos=\"47:63-47:119\">①ドア開閉状態の撮影 ②鍵置き場の撮影</td>\n</tr>\n<tr data-sourcepos=\"48:1-48:150\">\n<td data-sourcepos=\"48:2-48:24\">物体検出モデル</td>\n<td data-sourcepos=\"48:26-48:103\"><strong>YOLO11m（鍵検知）,YOLO11s（ドアOpen／ドアClose）</strong></td>\n<td data-sourcepos=\"48:105-48:149\">ドア開閉検知、鍵有無判定</td>\n</tr>\n<tr data-sourcepos=\"49:1-49:116\">\n<td data-sourcepos=\"49:2-49:22\">通知システム</td>\n<td data-sourcepos=\"49:24-49:65\"><strong>LINE Messaging API（Push Message）</strong></td>\n<td data-sourcepos=\"49:67-49:115\">鍵未所持時のリアルタイム通知</td>\n</tr>\n<tr data-sourcepos=\"50:1-50:135\">\n<td data-sourcepos=\"50:2-50:18\">開発言語</td>\n<td data-sourcepos=\"50:20-50:84\"><strong>Python（OpenCV,numpy,Requests）</strong></td>\n<td data-sourcepos=\"50:86-50:134\">映像取得、推論処理、通知制御</td>\n</tr>\n</tbody>\n</table>\n<h3 data-sourcepos=\"51:1-51:43\">\n<span id=\"なぜこの技術を採用したのか\" class=\"fragment\"></span><a href=\"#%E3%81%AA%E3%81%9C%E3%81%93%E3%81%AE%E6%8A%80%E8%A1%93%E3%82%92%E6%8E%A1%E7%94%A8%E3%81%97%E3%81%9F%E3%81%AE%E3%81%8B\"><i class=\"fa fa-link\"></i></a>なぜこの技術を採用したのか</h3>\n<p data-sourcepos=\"53:1-53:192\">本システムでは「外出時の鍵の持ち忘れを、リアルタイムに検知する」という目的を達成するため、処理速度と検出精度の両立が必要でした。</p>\n<h4 data-sourcepos=\"55:1-55:12\">\n<span id=\"yolo\" class=\"fragment\"></span><a href=\"#yolo\"><i class=\"fa fa-link\"></i></a>・YOLO</h4>\n<p data-sourcepos=\"56:1-56:200\">YOLO は 高い推論速度と十分な検出精度を同時に満たすため、RTSPカメラの映像を扱う本システムのような リアルタイム処理に最も適したモデルです。</p>\n<p data-sourcepos=\"58:1-58:219\">ドアの開閉判定は対象が大きく分類も二値のみのため、高速な YOLO11s を使用、一方で鍵は小物体で誤検知が起きやすいため、より高精度の YOLO11m を採用しました。</p>\n<p data-sourcepos=\"60:1-60:204\">このように、タスク特性に応じてモデルを使い分けることで、リアルタイム性（処理速度）と検出精度（信頼性）の最適なバランスを実現しています。</p>\n<h4 data-sourcepos=\"62:1-62:26\">\n<span id=\"line-messaging-api\" class=\"fragment\"></span><a href=\"#line-messaging-api\"><i class=\"fa fa-link\"></i></a>・LINE Messaging API</h4>\n<p data-sourcepos=\"63:1-63:371\">通知には LINE Messaging API を採用しました。以前別のアプリを作っていた時に利用した経験があったということと、最も身近で多くのユーザーが日常的に利用する LINE に直接通知を送ることで、専用アプリを必要とせず、鍵忘れを確実にユーザーへ伝えることができるためです。</p>\n<h1 data-sourcepos=\"65:1-65:23\">\n<span id=\"実装上の工夫点\" class=\"fragment\"></span><a href=\"#%E5%AE%9F%E8%A3%85%E4%B8%8A%E3%81%AE%E5%B7%A5%E5%A4%AB%E7%82%B9\"><i class=\"fa fa-link\"></i></a>実装上の工夫点</h1>\n<p data-sourcepos=\"67:1-70:96\"><strong>① RTSPReader（スレッド＋再接続ロジック）</strong><br>\nRTSP カメラの映像取得はネットワーク遅延や一時的な切断が発生しやすいため、単純なループ処理ではフリーズや遅延が蓄積しやすい問題を抱えています。<br>\nそこで本システムでは、カメラごとに専用スレッドを割り当て、常に最新の1フレームのみを共有する RTSPReaderを実装しました。<br>\nさらに、接続が不安定になった際には次のような仕組みで復旧します：</p>\n<ul data-sourcepos=\"71:1-74:0\">\n<li data-sourcepos=\"71:1-71:54\">接続失敗時に 指数バックオフで再接続</li>\n<li data-sourcepos=\"72:1-72:63\">フレーム取得失敗時は 即時リトライ＋再接続</li>\n<li data-sourcepos=\"73:1-74:0\">マルチスレッド＋排他制御で 安全に最新フレームを読み出せる</li>\n</ul>\n<p data-sourcepos=\"75:1-75:165\">これにより、ネットワーク揺らぎに強く、リアルタイム性を維持したまま映像処理を行える堅牢な土台を実現しています。</p>\n<div class=\"code-frame\" data-lang=\"python\" data-sourcepos=\"78:1-102:3\">\n<div class=\"code-lang\"><span class=\"bold\">expand_notifi.py</span></div>\n<div class=\"highlight\"><pre><code><span class=\"k\">def</span> <span class=\"nf\">run</span><span class=\"p\">(</span><span class=\"n\">self</span><span class=\"p\">):</span>\n    <span class=\"n\">backoff</span> <span class=\"o\">=</span> <span class=\"mf\">1.0</span>\n    <span class=\"k\">while</span> <span class=\"n\">self</span><span class=\"p\">.</span><span class=\"n\">alive</span><span class=\"p\">:</span>\n        <span class=\"k\">try</span><span class=\"p\">:</span>\n            <span class=\"k\">if</span> <span class=\"n\">self</span><span class=\"p\">.</span><span class=\"n\">cap</span> <span class=\"ow\">is</span> <span class=\"bp\">None</span> <span class=\"ow\">or</span> <span class=\"ow\">not</span> <span class=\"n\">self</span><span class=\"p\">.</span><span class=\"n\">cap</span><span class=\"p\">.</span><span class=\"nf\">isOpened</span><span class=\"p\">():</span>\n                <span class=\"k\">if</span> <span class=\"ow\">not</span> <span class=\"n\">self</span><span class=\"p\">.</span><span class=\"nf\">_open</span><span class=\"p\">():</span>\n                    <span class=\"n\">time</span><span class=\"p\">.</span><span class=\"nf\">sleep</span><span class=\"p\">(</span><span class=\"n\">backoff</span><span class=\"p\">)</span>\n                    <span class=\"n\">backoff</span> <span class=\"o\">=</span> <span class=\"nf\">min</span><span class=\"p\">(</span><span class=\"n\">backoff</span> <span class=\"o\">*</span> <span class=\"mf\">1.5</span><span class=\"p\">,</span> <span class=\"mf\">10.0</span><span class=\"p\">)</span>\n                    <span class=\"k\">continue</span>\n                <span class=\"n\">backoff</span> <span class=\"o\">=</span> <span class=\"mf\">1.0</span>\n            <span class=\"n\">ok</span><span class=\"p\">,</span> <span class=\"n\">f</span> <span class=\"o\">=</span> <span class=\"n\">self</span><span class=\"p\">.</span><span class=\"n\">cap</span><span class=\"p\">.</span><span class=\"nf\">read</span><span class=\"p\">()</span>\n            <span class=\"k\">if</span> <span class=\"ow\">not</span> <span class=\"n\">ok</span> <span class=\"ow\">or</span> <span class=\"n\">f</span> <span class=\"ow\">is</span> <span class=\"bp\">None</span><span class=\"p\">:</span>\n                <span class=\"nf\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"sh\">\"</span><span class=\"s\">[</span><span class=\"si\">{</span><span class=\"nf\">now</span><span class=\"p\">()</span><span class=\"si\">}</span><span class=\"s\">] [WARN] Read failed: </span><span class=\"si\">{</span><span class=\"n\">self</span><span class=\"p\">.</span><span class=\"n\">name</span><span class=\"si\">}</span><span class=\"s\">. Reopening...</span><span class=\"sh\">\"</span><span class=\"p\">)</span>\n                <span class=\"n\">time</span><span class=\"p\">.</span><span class=\"nf\">sleep</span><span class=\"p\">(</span><span class=\"mf\">0.3</span><span class=\"p\">)</span>\n                <span class=\"n\">self</span><span class=\"p\">.</span><span class=\"nf\">_open</span><span class=\"p\">()</span>\n                <span class=\"k\">continue</span>\n            <span class=\"k\">with</span> <span class=\"n\">self</span><span class=\"p\">.</span><span class=\"n\">lock</span><span class=\"p\">:</span>\n                <span class=\"n\">self</span><span class=\"p\">.</span><span class=\"n\">frame</span> <span class=\"o\">=</span> <span class=\"n\">f</span>\n        <span class=\"k\">except</span> <span class=\"nb\">Exception</span> <span class=\"k\">as</span> <span class=\"n\">e</span><span class=\"p\">:</span>\n            <span class=\"nf\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"sh\">\"</span><span class=\"s\">[</span><span class=\"si\">{</span><span class=\"nf\">now</span><span class=\"p\">()</span><span class=\"si\">}</span><span class=\"s\">] [WARN] </span><span class=\"si\">{</span><span class=\"n\">self</span><span class=\"p\">.</span><span class=\"n\">name</span><span class=\"si\">}</span><span class=\"s\"> exception: </span><span class=\"si\">{</span><span class=\"n\">e</span><span class=\"si\">}</span><span class=\"s\">. Reopening...</span><span class=\"sh\">\"</span><span class=\"p\">)</span>\n            <span class=\"n\">time</span><span class=\"p\">.</span><span class=\"nf\">sleep</span><span class=\"p\">(</span><span class=\"mf\">0.5</span><span class=\"p\">)</span>\n            <span class=\"n\">self</span><span class=\"p\">.</span><span class=\"nf\">_open</span><span class=\"p\">()</span>\n<span class=\"p\">)</span>\n</code></pre></div>\n</div>\n<p data-sourcepos=\"103:1-105:18\"><strong>② YOLO 推論＋投票平滑化</strong><br>\n物体検出は単フレームごとに誤検知が起こりやすいため、本システムでは直近7フレームの推論結果をキューに蓄積し、多数決で最終判定を行う投票平滑化を採用しています。<br>\nこれにより、</p>\n<ul data-sourcepos=\"106:1-111:0\">\n<li data-sourcepos=\"106:1-107:0\">\n<p data-sourcepos=\"106:3-106:44\">一瞬だけ鍵が検出されなかった</p>\n</li>\n<li data-sourcepos=\"108:1-109:0\">\n<p data-sourcepos=\"108:3-108:60\">ドアが半開きでopened,closedのラベルが揺れる</p>\n</li>\n<li data-sourcepos=\"110:1-111:0\">\n<p data-sourcepos=\"110:3-110:41\">逆光やノイズで誤検知が出る</p>\n</li>\n</ul>\n<p data-sourcepos=\"112:1-112:160\">といった 単発の判定揺らぎを排除し、誤検知を大幅に減らす事で、安定した開閉判定・鍵判定を得ることができます。</p>\n<div class=\"code-frame\" data-lang=\"python\" data-sourcepos=\"113:1-133:3\">\n<div class=\"code-lang\"><span class=\"bold\">expand_notifi.py</span></div>\n<div class=\"highlight\"><pre><code><span class=\"n\">VOTE_KEY</span><span class=\"p\">,</span> <span class=\"n\">VOTE_DOOR</span> <span class=\"o\">=</span> <span class=\"mi\">7</span><span class=\"p\">,</span> <span class=\"mi\">7</span>\n<span class=\"c1\"># 推論結果の平滑化用キュー\n</span><span class=\"n\">key_votes</span>  <span class=\"o\">=</span> <span class=\"nf\">deque</span><span class=\"p\">(</span><span class=\"n\">maxlen</span><span class=\"o\">=</span><span class=\"n\">VOTE_KEY</span><span class=\"p\">)</span>\n<span class=\"n\">door_votes</span> <span class=\"o\">=</span> <span class=\"nf\">deque</span><span class=\"p\">(</span><span class=\"n\">maxlen</span><span class=\"o\">=</span><span class=\"n\">VOTE_DOOR</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># YOLO 推論（鍵）\n</span><span class=\"n\">r1</span> <span class=\"o\">=</span> <span class=\"n\">key_model</span><span class=\"p\">.</span><span class=\"nf\">predict</span><span class=\"p\">(</span><span class=\"n\">f1</span><span class=\"p\">,</span> <span class=\"n\">imgsz</span><span class=\"o\">=</span><span class=\"n\">IMG_KEY</span><span class=\"p\">,</span> <span class=\"n\">conf</span><span class=\"o\">=</span><span class=\"n\">CONF_KEY</span><span class=\"p\">,</span> <span class=\"n\">iou</span><span class=\"o\">=</span><span class=\"n\">IOU_KEY</span><span class=\"p\">,</span> <span class=\"n\">verbose</span><span class=\"o\">=</span><span class=\"bp\">False</span><span class=\"p\">)[</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n<span class=\"c1\"># ... 省略 ...\n</span><span class=\"n\">key_votes</span><span class=\"p\">.</span><span class=\"nf\">append</span><span class=\"p\">(</span><span class=\"sh\">\"</span><span class=\"s\">present</span><span class=\"sh\">\"</span> <span class=\"k\">if</span> <span class=\"n\">key_present</span> <span class=\"k\">else</span> <span class=\"sh\">\"</span><span class=\"s\">absent</span><span class=\"sh\">\"</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># YOLO 推論（ドア）\n</span><span class=\"n\">r2</span> <span class=\"o\">=</span> <span class=\"n\">door_model</span><span class=\"p\">.</span><span class=\"nf\">predict</span><span class=\"p\">(</span><span class=\"n\">f2</span><span class=\"p\">,</span> <span class=\"n\">imgsz</span><span class=\"o\">=</span><span class=\"n\">IMG_DOOR</span><span class=\"p\">,</span> <span class=\"n\">conf</span><span class=\"o\">=</span><span class=\"n\">CONF_DOOR</span><span class=\"p\">,</span> <span class=\"n\">iou</span><span class=\"o\">=</span><span class=\"n\">IOU_DOOR</span><span class=\"p\">,</span> <span class=\"n\">verbose</span><span class=\"o\">=</span><span class=\"bp\">False</span><span class=\"p\">)[</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n<span class=\"c1\"># ... 省略 ...\n</span><span class=\"n\">door_votes</span><span class=\"p\">.</span><span class=\"nf\">append</span><span class=\"p\">(</span><span class=\"n\">door_label</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># 多数決で安定した状態にする\n</span><span class=\"n\">key_smooth</span>  <span class=\"o\">=</span> <span class=\"nf\">majority</span><span class=\"p\">(</span><span class=\"n\">key_votes</span><span class=\"p\">,</span>  <span class=\"n\">default</span><span class=\"o\">=</span><span class=\"sh\">\"</span><span class=\"s\">absent</span><span class=\"sh\">\"</span><span class=\"p\">)</span>\n<span class=\"n\">door_smooth</span> <span class=\"o\">=</span> <span class=\"nf\">majority</span><span class=\"p\">(</span><span class=\"n\">door_votes</span><span class=\"p\">,</span> <span class=\"n\">default</span><span class=\"o\">=</span><span class=\"bp\">None</span><span class=\"p\">)</span>\n\n</code></pre></div>\n</div>\n<p data-sourcepos=\"135:1-136:287\"><strong>③ 外出判定と通知ロジック（状態遷移）</strong><br>\nYOLO によるドア判定は「opened / closed」という二値情報を取得できますが、実際の家庭環境では以下のような理由でドア状態が頻繁に揺らぎ、外出と無関係なタイミングで通知が発生するという問題が多発しました。</p>\n<ul data-sourcepos=\"138:1-143:0\">\n<li data-sourcepos=\"138:1-139:0\">\n<p data-sourcepos=\"138:3-138:92\">帰宅時にも「opened」が検出されてイベントや通知が発生してしまう</p>\n</li>\n<li data-sourcepos=\"140:1-141:0\">\n<p data-sourcepos=\"140:3-140:86\">ドアが半開き状態で揺れると opened/closed が短時間に切り替わる</p>\n</li>\n<li data-sourcepos=\"142:1-143:0\">\n<p data-sourcepos=\"142:3-142:72\">人物がドアと重なりYOLOの識別が一時的に曖昧になる</p>\n</li>\n</ul>\n<p data-sourcepos=\"144:1-145:109\">これらの問題に対応するため、単純な「opened になったら通知する」という仕組みではなく、<br>\nドア開閉の前後関係を理解するための状態遷移ロジック を新しく設計しました。</p>\n<div class=\"code-frame\" data-lang=\"text\" data-sourcepos=\"146:1-150:3\"><div class=\"highlight\"><pre><code>    STATE_HOME            自宅にいる\n    STATE_AWAY_ARMED      外出状態\n    STATE_RETURN_SUPPRESS 帰宅直後\n</code></pre></div></div>\n<p data-sourcepos=\"153:1-164:94\">この状態に基づき、<br>\n最初はドアの状態はclosed<br>\n↓<br>\nHOME かつ → opened のタイミングのみ外出開始として扱う(stateがSTATE_AWAY_ARMEDに移行)<br>\n↓<br>\nこの時の opened は通知対象（鍵の有無で分岐）<br>\n↓<br>\nドアの状態がclosedへ移行<br>\n↓<br>\n次の帰宅時の STATE_AWAY_ARMED かつ → opened は誤通知になるため通知を抑制(stateがSTATE_RETURN_SUPPRESSに移行)<br>\n↓<br>\nドアが十分に closed 状態を継続すると HOME に復帰(stateがSTATE_HOMEに移行)</p>\n<p data-sourcepos=\"166:1-167:393\">といった判定が可能になりました。<br>\n特に帰宅時は外出時と見た目が同じなため、誤通知の発生する大きな要因でした。そこで状態遷移を導入したことで、不要な通知を抑制しつつ外出イベントだけを正確に扱えるようになり、鍵の有無とドア開閉を組み合わせた安定した外出判定が可能となり、通知システムを実現できました。</p>\n<div class=\"code-frame\" data-lang=\"python\" data-sourcepos=\"168:1-238:3\">\n<div class=\"code-lang\"><span class=\"bold\">expand_notifi.py</span></div>\n<div class=\"highlight\"><pre><code><span class=\"c1\"># ---- 外出判定用の状態定数 ----\n</span><span class=\"n\">STATE_HOME</span>            <span class=\"o\">=</span> <span class=\"mi\">0</span>  <span class=\"c1\"># 自宅にいる\n</span><span class=\"n\">STATE_AWAY_ARMED</span>      <span class=\"o\">=</span> <span class=\"mi\">1</span>  <span class=\"c1\"># 外出中\n</span><span class=\"n\">STATE_RETURN_SUPPRESS</span> <span class=\"o\">=</span> <span class=\"mi\">2</span>  <span class=\"c1\"># 帰宅直後\n</span>\n<span class=\"c1\"># 状態管理用の変数\n</span><span class=\"n\">state</span> <span class=\"o\">=</span> <span class=\"n\">STATE_HOME</span>\n<span class=\"n\">return_suppressed_once</span> <span class=\"o\">=</span> <span class=\"bp\">False</span>\n<span class=\"n\">notified</span> <span class=\"o\">=</span> <span class=\"bp\">False</span>\n<span class=\"n\">prev_door_state</span> <span class=\"o\">=</span> <span class=\"bp\">None</span>\n<span class=\"n\">closed_streak</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>\n<span class=\"n\">closed_event_done</span> <span class=\"o\">=</span> <span class=\"bp\">False</span>\n<span class=\"n\">first_closed_skip</span> <span class=\"o\">=</span> <span class=\"bp\">True</span>\n<span class=\"n\">RESET_CLOSED_FRAMES</span> <span class=\"o\">=</span> <span class=\"mi\">5</span>\n\n<span class=\"c1\"># ===== メインループ内 =====\n</span>\n<span class=\"c1\"># イベント検出（closed/None → opened）\n</span><span class=\"n\">pred_warn</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">door_smooth</span> <span class=\"o\">==</span> <span class=\"sh\">\"</span><span class=\"s\">opened</span><span class=\"sh\">\"</span> <span class=\"ow\">and</span> <span class=\"n\">key_smooth</span> <span class=\"o\">==</span> <span class=\"sh\">\"</span><span class=\"s\">present</span><span class=\"sh\">\"</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># 1) ドア状態が closed/None → opened に変化した瞬間だけを見る\n</span><span class=\"k\">if</span> <span class=\"n\">prev_door_state</span> <span class=\"o\">!=</span> <span class=\"sh\">\"</span><span class=\"s\">opened</span><span class=\"sh\">\"</span> <span class=\"ow\">and</span> <span class=\"n\">door_smooth</span> <span class=\"o\">==</span> <span class=\"sh\">\"</span><span class=\"s\">opened</span><span class=\"sh\">\"</span><span class=\"p\">:</span>\n    <span class=\"n\">closed_streak</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>\n\n    <span class=\"k\">if</span> <span class=\"n\">state</span> <span class=\"o\">==</span> <span class=\"n\">STATE_HOME</span><span class=\"p\">:</span>\n        <span class=\"c1\"># 初回 opened を「外出開始」とみなす\n</span>        <span class=\"n\">state</span> <span class=\"o\">=</span> <span class=\"n\">STATE_AWAY_ARMED</span>\n        <span class=\"n\">return_suppressed_once</span> <span class=\"o\">=</span> <span class=\"bp\">False</span>\n\n        <span class=\"c1\"># 通知（pred_warn=True かつ 未通知）\n</span>        <span class=\"k\">if</span> <span class=\"n\">pred_warn</span> <span class=\"ow\">and</span> <span class=\"ow\">not</span> <span class=\"n\">notified</span><span class=\"p\">:</span>\n            <span class=\"n\">msg</span> <span class=\"o\">=</span> <span class=\"sh\">\"</span><span class=\"s\">【注意】ドアが開きました。鍵を忘れています！</span><span class=\"sh\">\"</span>\n            <span class=\"nf\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"sh\">\"</span><span class=\"s\">[</span><span class=\"si\">{</span><span class=\"nf\">now</span><span class=\"p\">()</span><span class=\"si\">}</span><span class=\"s\">] ⚠️</span><span class=\"si\">{</span><span class=\"n\">msg</span><span class=\"si\">}</span><span class=\"sh\">\"</span><span class=\"p\">)</span>\n            <span class=\"nf\">line_push</span><span class=\"p\">(</span><span class=\"n\">msg</span><span class=\"p\">)</span>\n            <span class=\"n\">notified</span> <span class=\"o\">=</span> <span class=\"bp\">True</span>\n\n    <span class=\"k\">elif</span> <span class=\"n\">state</span> <span class=\"o\">==</span> <span class=\"n\">STATE_AWAY_ARMED</span><span class=\"p\">:</span>\n        <span class=\"c1\"># 次の opened は「帰宅」とみなし通知を 1 回だけ抑制\n</span>        <span class=\"k\">if</span> <span class=\"ow\">not</span> <span class=\"n\">return_suppressed_once</span><span class=\"p\">:</span>\n            <span class=\"nf\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"sh\">\"</span><span class=\"s\">[</span><span class=\"si\">{</span><span class=\"nf\">now</span><span class=\"p\">()</span><span class=\"si\">}</span><span class=\"s\">] ↩️ 帰宅とみなし通知もEVENTも抑制(この開扉はスキップ)</span><span class=\"sh\">\"</span><span class=\"p\">)</span>\n            <span class=\"n\">state</span> <span class=\"o\">=</span> <span class=\"n\">STATE_RETURN_SUPPRESS</span>\n            <span class=\"n\">return_suppressed_once</span> <span class=\"o\">=</span> <span class=\"bp\">True</span>\n\n\n<span class=\"c1\"># 2) ドアが十分な時間 closed を保ったら HOME に戻す\n</span><span class=\"k\">if</span> <span class=\"n\">door_smooth</span> <span class=\"o\">==</span> <span class=\"sh\">\"</span><span class=\"s\">closed</span><span class=\"sh\">\"</span><span class=\"p\">:</span>\n    <span class=\"k\">if</span> <span class=\"n\">prev_door_state</span> <span class=\"o\">==</span> <span class=\"sh\">\"</span><span class=\"s\">opened</span><span class=\"sh\">\"</span><span class=\"p\">:</span>\n        <span class=\"n\">closed_streak</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>\n        <span class=\"n\">closed_event_done</span> <span class=\"o\">=</span> <span class=\"bp\">False</span>\n    <span class=\"k\">else</span><span class=\"p\">:</span>\n        <span class=\"n\">closed_streak</span> <span class=\"o\">+=</span> <span class=\"mi\">1</span>\n\n    <span class=\"k\">if</span> <span class=\"n\">first_closed_skip</span><span class=\"p\">:</span>\n        <span class=\"n\">first_closed_skip</span> <span class=\"o\">=</span> <span class=\"bp\">False</span>\n        <span class=\"n\">closed_event_done</span> <span class=\"o\">=</span> <span class=\"bp\">True</span>\n    <span class=\"k\">elif</span> <span class=\"ow\">not</span> <span class=\"n\">closed_event_done</span> <span class=\"ow\">and</span> <span class=\"n\">closed_streak</span> <span class=\"o\">&gt;=</span> <span class=\"n\">RESET_CLOSED_FRAMES</span><span class=\"p\">:</span>\n        <span class=\"n\">closed_event_done</span> <span class=\"o\">=</span> <span class=\"bp\">True</span>\n\n        <span class=\"k\">if</span> <span class=\"n\">state</span> <span class=\"o\">==</span> <span class=\"n\">STATE_RETURN_SUPPRESS</span><span class=\"p\">:</span>\n            <span class=\"c1\"># 帰宅完了 → HOME へ復帰\n</span>            <span class=\"n\">state</span> <span class=\"o\">=</span> <span class=\"n\">STATE_HOME</span>\n            <span class=\"n\">return_suppressed_once</span> <span class=\"o\">=</span> <span class=\"bp\">False</span>\n\n<span class=\"k\">elif</span> <span class=\"n\">door_smooth</span> <span class=\"o\">==</span> <span class=\"sh\">\"</span><span class=\"s\">opened</span><span class=\"sh\">\"</span><span class=\"p\">:</span>\n    <span class=\"c1\"># opened に戻ったら closed 連続カウンタはリセット\n</span>    <span class=\"n\">closed_streak</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>\n    <span class=\"n\">closed_event_done</span> <span class=\"o\">=</span> <span class=\"bp\">False</span>\n\n\n</code></pre></div>\n</div>\n<p data-sourcepos=\"240:1-241:337\"><strong>④ データ増強とモデル精度改善の取り組み</strong><br>\n初期段階では鍵の学習データは約700枚でしたが、精度向上のためデータ数を段階的に増やし、最終的には約3,500枚まで拡張しました。特に2,500枚を超えたあたりから、モデル精度が明確に向上し、実運用に耐えうるレベルまで到達したと感じています。</p>\n<p data-sourcepos=\"243:1-243:106\">以下に、最終モデルのテストで得られた混同行列（Confusion Matrix）を示します。</p>\n<p data-sourcepos=\"245:1-246:144\"><a href=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F4291559%2Fd150cb05-cd8e-447a-8601-653cc9c62bcf.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=1b5ca223bc0a8a6dc604922a83802efe\" target=\"_blank\" rel=\"nofollow noopener\"><img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F4291559%2Fd150cb05-cd8e-447a-8601-653cc9c62bcf.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=1b5ca223bc0a8a6dc604922a83802efe\" alt=\"confusion_matrix.png\" srcset=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F4291559%2Fd150cb05-cd8e-447a-8601-653cc9c62bcf.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;w=1400&amp;fit=max&amp;s=7401ffa503bd149c9c1973ed38770c39 1x\" data-canonical-src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/4291559/d150cb05-cd8e-447a-8601-653cc9c62bcf.png\" loading=\"lazy\"></a><br>\n<a href=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F4291559%2F11e3bc63-bfb8-47fb-ae46-7e99ebe167aa.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=0372fa80d75bb9af8d418de19e14b0ae\" target=\"_blank\" rel=\"nofollow noopener\"><img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F4291559%2F11e3bc63-bfb8-47fb-ae46-7e99ebe167aa.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=0372fa80d75bb9af8d418de19e14b0ae\" alt=\"confusion_matrix_normalized.png\" srcset=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F4291559%2F11e3bc63-bfb8-47fb-ae46-7e99ebe167aa.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;w=1400&amp;fit=max&amp;s=bc40ac9afdbbd9e1fd19e3771443175d 1x\" data-canonical-src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/4291559/11e3bc63-bfb8-47fb-ae46-7e99ebe167aa.png\" loading=\"lazy\"></a></p>\n<h1 data-sourcepos=\"250:1-250:26\">\n<span id=\"課題と今後の展望\" class=\"fragment\"></span><a href=\"#%E8%AA%B2%E9%A1%8C%E3%81%A8%E4%BB%8A%E5%BE%8C%E3%81%AE%E5%B1%95%E6%9C%9B\"><i class=\"fa fa-link\"></i></a>課題と今後の展望</h1>\n<p data-sourcepos=\"251:1-252:136\"><strong>鍵の検出精度向上</strong> : テスト評価の結果、鍵が写っているにもかかわらず検出できなかったFalse Negative（見逃し）が60件発生し、鍵の検出率（Recall）は約80%に留まりました。<br>\nNormalized Confusion Matrixでも0.20（20%）が見逃しと示されており、検出漏れの改善が課題となっています。</p>\n<p data-sourcepos=\"254:1-254:51\">見逃しが発生した主な要因としては、</p>\n<ul data-sourcepos=\"256:1-261:0\">\n<li data-sourcepos=\"256:1-257:0\">\n<p data-sourcepos=\"256:3-256:66\">他の物体に隠れる・重なる （オクルージョン）</p>\n</li>\n<li data-sourcepos=\"258:1-259:0\">\n<p data-sourcepos=\"258:3-258:102\">背景と色が似ている、または光の反射で形状が変わる （特徴の不明瞭化）</p>\n</li>\n<li data-sourcepos=\"260:1-261:0\">\n<p data-sourcepos=\"260:3-260:90\">鍵が小さく写ることで特徴量が不足する （小物体検出の難しさ）</p>\n</li>\n</ul>\n<p data-sourcepos=\"262:1-263:292\">といった撮影環境特有の問題が大きく影響していると考えられます。<br>\n今後は、オクルージョンを含む画像、反射・光量変化のある画像、鍵が遠距離で小さく写る画像など、より多様な学習データを追加することで、見逃しの削減と検出精度の安定化を図ることが重要 だと考えています。</p>\n<p data-sourcepos=\"265:1-267:201\"><strong>鍵以外の物体や事象の検知</strong> :<br>\n将来的には、鍵だけではなく財布などの持ち物、さらにはガス栓の閉め忘れといった「外出時に起こりやすいインシデント」も同時に検知し、忘れ物や不注意全般を未然に防ぐシステムへ拡張することを検討しています。ただし、検出対象を増やすとモデルサイズの肥大化や推論負荷の増加によって、リアルタイム性を損なう可能性があり、この点は解決すべき大きな課題です。<br>\nそのため今後は、処理負荷を抑えつつ多物体・多事象の検知に対応できる構成を模索し、最適なアーキテクチャを検討していきたいと考えています。</p>\n",
      "body": "# 初めに\n私は逢甲大學 資電學院 資訊工程系の小村と申します。\n上の学部学科は日本の区分で言えば、情報学部・情報学科に相当します。\n# システム開発の動機\n突然ですが、皆さんは今まで鍵をかけ忘れて家を出てしまったこと、小さい頃鍵を持たずに外出をし帰宅時に鍵が無く、家に入ることが出来ず困ったというような経験をしたことはありませんか？\n私自身、幼い頃に鍵を家に置いたまま学校へ行ってしまい、帰宅しても家へ入れず、近所の公園で待ちぼうけをするということを何度も経験しました。\nそんな幼い頃の辛酸を思い出し、どうすれば鍵の施錠忘れ、鍵の本体の所持忘れをなくすことができるかということを考えたときに、それならば家を出るタイミングにリアルタイムで鍵の閉め忘れ、鍵本体の忘れを通知してくれるそんなシステムを構築することで、これらの問題を解決する事ができるのではと考え、今回のシステムを開発するに至りました。\n\n# プロジェクト概要\n下記が作成したシステムのGitHubリポジトリになります。\n\nhttps://github.com/Omura24/tapo\n\n### システムの全体像\n\n本システムは、2台のTapoカメラ映像をYOLOで解析し、ドアの開閉状態（Open／Close）と鍵本体の有無を同時に判定する、AIベースの鍵持ち忘れ防止システムです。\n\n外出動作として「ドアが開いた」状態をYOLOが検知すると、同タイミングで鍵置き場の映像を解析し、鍵が室内に残っている場合は、LINE Messaging API Pushにより即時に通知を行います。\n```mermaid\nflowchart TB\n\n    KCAM[鍵置き場カメラ]\n    KYOLO[YOLO 鍵検知]\n\n    DCAM[玄関カメラ]\n    DYOLO[YOLO ドア開閉判定]\n\n    STATE[状態判定 外出か 鍵があるか]\n    LINE[鍵忘れ LINE通知]\n\n    KCAM --> KYOLO\n    DCAM --> DYOLO\n\n    KYOLO --> STATE\n    DYOLO --> STATE\n\n    STATE --> LINE\n```\n\n### 実際の実行画面\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/TtVnS2ZHVaY?si=Gqyz7ngJv3E17QfC\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n\n# 使用デバイス・技術構成\n| 分類      | 使用機器・技術                              | 役割                  |\n| ------- | ------------------------------------ | ------------------- |\n| カメラ     | **Tapo C210（2台）**                    | ①ドア開閉状態の撮影 ②鍵置き場の撮影 |\n| 物体検出モデル | **YOLO11m（鍵検知）,YOLO11s（ドアOpen／ドアClose）**             | ドア開閉検知、鍵有無判定        |\n| 通知システム  | **LINE Messaging API（Push Message）** | 鍵未所持時のリアルタイム通知      |\n| 開発言語    | **Python（OpenCV,numpy,Requests）**                           | 映像取得、推論処理、通知制御      |\n### なぜこの技術を採用したのか\n\n本システムでは「外出時の鍵の持ち忘れを、リアルタイムに検知する」という目的を達成するため、処理速度と検出精度の両立が必要でした。\n\n#### ・YOLO\nYOLO は 高い推論速度と十分な検出精度を同時に満たすため、RTSPカメラの映像を扱う本システムのような リアルタイム処理に最も適したモデルです。\n\nドアの開閉判定は対象が大きく分類も二値のみのため、高速な YOLO11s を使用、一方で鍵は小物体で誤検知が起きやすいため、より高精度の YOLO11m を採用しました。\n\nこのように、タスク特性に応じてモデルを使い分けることで、リアルタイム性（処理速度）と検出精度（信頼性）の最適なバランスを実現しています。\n\n#### ・LINE Messaging API\n通知には LINE Messaging API を採用しました。以前別のアプリを作っていた時に利用した経験があったということと、最も身近で多くのユーザーが日常的に利用する LINE に直接通知を送ることで、専用アプリを必要とせず、鍵忘れを確実にユーザーへ伝えることができるためです。\n\n# 実装上の工夫点\n\n**① RTSPReader（スレッド＋再接続ロジック）**\nRTSP カメラの映像取得はネットワーク遅延や一時的な切断が発生しやすいため、単純なループ処理ではフリーズや遅延が蓄積しやすい問題を抱えています。\nそこで本システムでは、カメラごとに専用スレッドを割り当て、常に最新の1フレームのみを共有する RTSPReaderを実装しました。\nさらに、接続が不安定になった際には次のような仕組みで復旧します：\n- 接続失敗時に 指数バックオフで再接続\n- フレーム取得失敗時は 即時リトライ＋再接続\n- マルチスレッド＋排他制御で 安全に最新フレームを読み出せる\n\nこれにより、ネットワーク揺らぎに強く、リアルタイム性を維持したまま映像処理を行える堅牢な土台を実現しています。\n\n\n```python:expand_notifi.py\ndef run(self):\n    backoff = 1.0\n    while self.alive:\n        try:\n            if self.cap is None or not self.cap.isOpened():\n                if not self._open():\n                    time.sleep(backoff)\n                    backoff = min(backoff * 1.5, 10.0)\n                    continue\n                backoff = 1.0\n            ok, f = self.cap.read()\n            if not ok or f is None:\n                print(f\"[{now()}] [WARN] Read failed: {self.name}. Reopening...\")\n                time.sleep(0.3)\n                self._open()\n                continue\n            with self.lock:\n                self.frame = f\n        except Exception as e:\n            print(f\"[{now()}] [WARN] {self.name} exception: {e}. Reopening...\")\n            time.sleep(0.5)\n            self._open()\n)\n```\n**② YOLO 推論＋投票平滑化**\n物体検出は単フレームごとに誤検知が起こりやすいため、本システムでは直近7フレームの推論結果をキューに蓄積し、多数決で最終判定を行う投票平滑化を採用しています。\nこれにより、\n- 一瞬だけ鍵が検出されなかった\n\n- ドアが半開きでopened,closedのラベルが揺れる\n\n- 逆光やノイズで誤検知が出る\n\nといった 単発の判定揺らぎを排除し、誤検知を大幅に減らす事で、安定した開閉判定・鍵判定を得ることができます。\n```python:expand_notifi.py\nVOTE_KEY, VOTE_DOOR = 7, 7\n# 推論結果の平滑化用キュー\nkey_votes  = deque(maxlen=VOTE_KEY)\ndoor_votes = deque(maxlen=VOTE_DOOR)\n\n# YOLO 推論（鍵）\nr1 = key_model.predict(f1, imgsz=IMG_KEY, conf=CONF_KEY, iou=IOU_KEY, verbose=False)[0]\n# ... 省略 ...\nkey_votes.append(\"present\" if key_present else \"absent\")\n\n# YOLO 推論（ドア）\nr2 = door_model.predict(f2, imgsz=IMG_DOOR, conf=CONF_DOOR, iou=IOU_DOOR, verbose=False)[0]\n# ... 省略 ...\ndoor_votes.append(door_label)\n\n# 多数決で安定した状態にする\nkey_smooth  = majority(key_votes,  default=\"absent\")\ndoor_smooth = majority(door_votes, default=None)\n\n```\n\n**③ 外出判定と通知ロジック（状態遷移）**\nYOLO によるドア判定は「opened / closed」という二値情報を取得できますが、実際の家庭環境では以下のような理由でドア状態が頻繁に揺らぎ、外出と無関係なタイミングで通知が発生するという問題が多発しました。\n\n- 帰宅時にも「opened」が検出されてイベントや通知が発生してしまう\n\n- ドアが半開き状態で揺れると opened/closed が短時間に切り替わる\n\n- 人物がドアと重なりYOLOの識別が一時的に曖昧になる\n\nこれらの問題に対応するため、単純な「opened になったら通知する」という仕組みではなく、\nドア開閉の前後関係を理解するための状態遷移ロジック を新しく設計しました。\n```\n    STATE_HOME            自宅にいる\n    STATE_AWAY_ARMED      外出状態\n    STATE_RETURN_SUPPRESS 帰宅直後\n```\n\n\nこの状態に基づき、\n最初はドアの状態はclosed\n↓\nHOME かつ → opened のタイミングのみ外出開始として扱う(stateがSTATE_AWAY_ARMEDに移行)\n↓\nこの時の opened は通知対象（鍵の有無で分岐）\n↓\nドアの状態がclosedへ移行\n↓\n次の帰宅時の STATE_AWAY_ARMED かつ → opened は誤通知になるため通知を抑制(stateがSTATE_RETURN_SUPPRESSに移行)\n↓\nドアが十分に closed 状態を継続すると HOME に復帰(stateがSTATE_HOMEに移行)\n\nといった判定が可能になりました。\n特に帰宅時は外出時と見た目が同じなため、誤通知の発生する大きな要因でした。そこで状態遷移を導入したことで、不要な通知を抑制しつつ外出イベントだけを正確に扱えるようになり、鍵の有無とドア開閉を組み合わせた安定した外出判定が可能となり、通知システムを実現できました。\n```python:expand_notifi.py\n# ---- 外出判定用の状態定数 ----\nSTATE_HOME            = 0  # 自宅にいる\nSTATE_AWAY_ARMED      = 1  # 外出中\nSTATE_RETURN_SUPPRESS = 2  # 帰宅直後\n\n# 状態管理用の変数\nstate = STATE_HOME\nreturn_suppressed_once = False\nnotified = False\nprev_door_state = None\nclosed_streak = 0\nclosed_event_done = False\nfirst_closed_skip = True\nRESET_CLOSED_FRAMES = 5\n\n# ===== メインループ内 =====\n\n# イベント検出（closed/None → opened）\npred_warn = (door_smooth == \"opened\" and key_smooth == \"present\")\n\n# 1) ドア状態が closed/None → opened に変化した瞬間だけを見る\nif prev_door_state != \"opened\" and door_smooth == \"opened\":\n    closed_streak = 0\n\n    if state == STATE_HOME:\n        # 初回 opened を「外出開始」とみなす\n        state = STATE_AWAY_ARMED\n        return_suppressed_once = False\n\n        # 通知（pred_warn=True かつ 未通知）\n        if pred_warn and not notified:\n            msg = \"【注意】ドアが開きました。鍵を忘れています！\"\n            print(f\"[{now()}] ⚠️{msg}\")\n            line_push(msg)\n            notified = True\n\n    elif state == STATE_AWAY_ARMED:\n        # 次の opened は「帰宅」とみなし通知を 1 回だけ抑制\n        if not return_suppressed_once:\n            print(f\"[{now()}] ↩️ 帰宅とみなし通知もEVENTも抑制(この開扉はスキップ)\")\n            state = STATE_RETURN_SUPPRESS\n            return_suppressed_once = True\n\n\n# 2) ドアが十分な時間 closed を保ったら HOME に戻す\nif door_smooth == \"closed\":\n    if prev_door_state == \"opened\":\n        closed_streak = 1\n        closed_event_done = False\n    else:\n        closed_streak += 1\n\n    if first_closed_skip:\n        first_closed_skip = False\n        closed_event_done = True\n    elif not closed_event_done and closed_streak >= RESET_CLOSED_FRAMES:\n        closed_event_done = True\n\n        if state == STATE_RETURN_SUPPRESS:\n            # 帰宅完了 → HOME へ復帰\n            state = STATE_HOME\n            return_suppressed_once = False\n\nelif door_smooth == \"opened\":\n    # opened に戻ったら closed 連続カウンタはリセット\n    closed_streak = 0\n    closed_event_done = False\n\n\n```\n\n**④ データ増強とモデル精度改善の取り組み**\n初期段階では鍵の学習データは約700枚でしたが、精度向上のためデータ数を段階的に増やし、最終的には約3,500枚まで拡張しました。特に2,500枚を超えたあたりから、モデル精度が明確に向上し、実運用に耐えうるレベルまで到達したと感じています。\n\n以下に、最終モデルのテストで得られた混同行列（Confusion Matrix）を示します。\n\n![confusion_matrix.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/4291559/d150cb05-cd8e-447a-8601-653cc9c62bcf.png)\n![confusion_matrix_normalized.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/4291559/11e3bc63-bfb8-47fb-ae46-7e99ebe167aa.png)\n\n\n\n# 課題と今後の展望\n**鍵の検出精度向上** : テスト評価の結果、鍵が写っているにもかかわらず検出できなかったFalse Negative（見逃し）が60件発生し、鍵の検出率（Recall）は約80%に留まりました。\nNormalized Confusion Matrixでも0.20（20%）が見逃しと示されており、検出漏れの改善が課題となっています。\n\n見逃しが発生した主な要因としては、\n\n- 他の物体に隠れる・重なる （オクルージョン）\n\n- 背景と色が似ている、または光の反射で形状が変わる （特徴の不明瞭化）\n\n- 鍵が小さく写ることで特徴量が不足する （小物体検出の難しさ）\n\nといった撮影環境特有の問題が大きく影響していると考えられます。\n今後は、オクルージョンを含む画像、反射・光量変化のある画像、鍵が遠距離で小さく写る画像など、より多様な学習データを追加することで、見逃しの削減と検出精度の安定化を図ることが重要 だと考えています。\n\n**鍵以外の物体や事象の検知** : \n将来的には、鍵だけではなく財布などの持ち物、さらにはガス栓の閉め忘れといった「外出時に起こりやすいインシデント」も同時に検知し、忘れ物や不注意全般を未然に防ぐシステムへ拡張することを検討しています。ただし、検出対象を増やすとモデルサイズの肥大化や推論負荷の増加によって、リアルタイム性を損なう可能性があり、この点は解決すべき大きな課題です。\nそのため今後は、処理負荷を抑えつつ多物体・多事象の検知に対応できる構成を模索し、最適なアーキテクチャを検討していきたいと考えています。\n",
      "coediting": false,
      "comments_count": 0,
      "created_at": "2025-12-11T17:45:55+09:00",
      "group": null,
      "id": "03fe84ee836f6fb77450",
      "likes_count": 0,
      "private": false,
      "reactions_count": 0,
      "stocks_count": 0,
      "tags": [
        {
          "name": "Python",
          "versions": []
        },
        {
          "name": "RTSP",
          "versions": []
        },
        {
          "name": "IoT",
          "versions": []
        },
        {
          "name": "LINEmessagingAPI",
          "versions": []
        },
        {
          "name": "YOLO",
          "versions": []
        }
      ],
      "title": "鍵の持ち忘れをリアルタイム検知しLINE通知：Tapo × YOLO × Pythonで構築したIoTシステム",
      "updated_at": "2025-12-11T17:51:13+09:00",
      "url": "https://qiita.com/shakekan/items/03fe84ee836f6fb77450",
      "user": {
        "description": null,
        "facebook_id": null,
        "followees_count": 1,
        "followers_count": 0,
        "github_login_name": null,
        "id": "shakekan",
        "items_count": 1,
        "linkedin_id": null,
        "location": null,
        "name": "",
        "organization": null,
        "permanent_id": 4291559,
        "profile_image_url": "https://secure.gravatar.com/avatar/c540dd5e247180505bfe994922204961",
        "team_only": false,
        "twitter_screen_name": null,
        "website_url": null
      },
      "page_views_count": null,
      "team_membership": null,
      "organization_url_name": null,
      "slide": false,
      "_source": "trending_by_likes"
    },
    {
      "rendered_body": "<h1 data-sourcepos=\"1:1-1:74\">\n<span id=\"i2cモジュール２バイト書き込み１バイト読み込み\" class=\"fragment\"></span><a href=\"#i2c%E3%83%A2%E3%82%B8%E3%83%A5%E3%83%BC%E3%83%AB%EF%BC%92%E3%83%90%E3%82%A4%E3%83%88%E6%9B%B8%E3%81%8D%E8%BE%BC%E3%81%BF%EF%BC%91%E3%83%90%E3%82%A4%E3%83%88%E8%AA%AD%E3%81%BF%E8%BE%BC%E3%81%BF\"><i class=\"fa fa-link\"></i></a>I2Cモジュール　２バイト書き込み、１バイト読み込み</h1>\n<p data-sourcepos=\"2:1-2:64\">たたき台に、16bit IOexpander MCP23017　を使います。</p>\n<div data-sourcepos=\"4:1-10:3\" class=\"note info\">\n<span class=\"fa fa-fw fa-check-circle\"></span><div>\n<h3 data-sourcepos=\"5:1-5:19\">\n<span id=\"i2c用語確認\" class=\"fragment\"></span><a href=\"#i2c%E7%94%A8%E8%AA%9E%E7%A2%BA%E8%AA%8D\"><i class=\"fa fa-link\"></i></a>I2C用語確認</h3>\n<p data-sourcepos=\"6:1-9:95\">STM32のリファレンスマニュアルのI2Cデバイス用語<br>\n従来のMasterが、<strong>Controller</strong><br>\n従来のSlaveが、<strong>Target</strong><br>\nに変更になっています。PICマイコンのHost-Clientと同じような変更です。</p>\n</div>\n</div>\n<p data-sourcepos=\"11:1-12:126\">コードは、LLライブラリーを使用しています。<br>\n<a href=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F3693934%2F4dd64b2a-81fd-469c-b453-a78be9729b7d.jpeg?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=f6cd6d29d2588751bcda5e6ef95b65ee\" target=\"_blank\" rel=\"nofollow noopener\"><img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F3693934%2F4dd64b2a-81fd-469c-b453-a78be9729b7d.jpeg?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=f6cd6d29d2588751bcda5e6ef95b65ee\" alt=\"IMG_5468.JPG\" srcset=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F3693934%2F4dd64b2a-81fd-469c-b453-a78be9729b7d.jpeg?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;w=1400&amp;fit=max&amp;s=92698464771d294db1892e8aea632d41 1x\" data-canonical-src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/3693934/4dd64b2a-81fd-469c-b453-a78be9729b7d.jpeg\" loading=\"lazy\"></a></p>\n<div data-sourcepos=\"14:1-25:3\" class=\"note info\">\n<span class=\"fa fa-fw fa-check-circle\"></span><div>\n<h3 data-sourcepos=\"15:1-15:23\">\n<span id=\"i2c1-mx側の処理\" class=\"fragment\"></span><a href=\"#i2c1-mx%E5%81%B4%E3%81%AE%E5%87%A6%E7%90%86\"><i class=\"fa fa-link\"></i></a>I2C1 MX側の処理</h3>\n<p data-sourcepos=\"16:1-18:132\">1.MX生成のI2Cモジュール初期化コードに手を加える必要なし。<br>\n2.I2C1担当のGPIOはMXでプルアップした。<br>\n<a href=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F3693934%2Fcd814eec-4cf7-40d1-ab76-19228e88a6e8.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=17b679f130bc7081c883fb11e4fadbc6\" target=\"_blank\" rel=\"nofollow noopener\"><img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F3693934%2Fcd814eec-4cf7-40d1-ab76-19228e88a6e8.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=17b679f130bc7081c883fb11e4fadbc6\" alt=\"I2C設定画面.png\" srcset=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F3693934%2Fcd814eec-4cf7-40d1-ab76-19228e88a6e8.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;w=1400&amp;fit=max&amp;s=4555f889d5bbf366b5736c4526a80f34 1x\" data-canonical-src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/3693934/cd814eec-4cf7-40d1-ab76-19228e88a6e8.png\" loading=\"lazy\"></a></p>\n<p data-sourcepos=\"0:0-0:0\">以前の配線に追加した端子 Nucleo-F446RE</p>\n<table data-sourcepos=\"20:1-24:21\">\n<thead>\n<tr data-sourcepos=\"20:1-20:93\">\n<th style=\"text-align: center\" data-sourcepos=\"20:53-20:66\">コネクタ</th>\n<th style=\"text-align: center\" data-sourcepos=\"20:68-20:75\">番号</th>\n<th style=\"text-align: center\" data-sourcepos=\"20:77-20:85\">ピン名</th>\n<th style=\"text-align: center\" data-sourcepos=\"20:87-20:92\">機能</th>\n</tr>\n</thead>\n<tbody>\n<tr data-sourcepos=\"23:1-23:20\">\n<td style=\"text-align: center\" data-sourcepos=\"23:2-23:4\">CN5</td>\n<td style=\"text-align: center\" data-sourcepos=\"23:6-23:6\">3</td>\n<td style=\"text-align: center\" data-sourcepos=\"23:8-23:10\">RB6</td>\n<td style=\"text-align: center\" data-sourcepos=\"23:12-23:19\">I2C1 SCL</td>\n</tr>\n<tr data-sourcepos=\"24:1-24:21\">\n<td style=\"text-align: center\" data-sourcepos=\"24:2-24:4\">CN7</td>\n<td style=\"text-align: center\" data-sourcepos=\"24:6-24:7\">21</td>\n<td style=\"text-align: center\" data-sourcepos=\"24:9-24:11\">RB7</td>\n<td style=\"text-align: center\" data-sourcepos=\"24:13-24:20\">I2C1 SDA</td>\n</tr>\n</tbody>\n</table>\n</div>\n</div>\n<div data-sourcepos=\"27:1-36:3\" class=\"note info\">\n<span class=\"fa fa-fw fa-check-circle\"></span><div>\n<h3 data-sourcepos=\"28:1-28:31\">\n<span id=\"i2cモジュールの要点\" class=\"fragment\"></span><a href=\"#i2c%E3%83%A2%E3%82%B8%E3%83%A5%E3%83%BC%E3%83%AB%E3%81%AE%E8%A6%81%E7%82%B9\"><i class=\"fa fa-link\"></i></a>I2Cモジュールの要点</h3>\n<p data-sourcepos=\"29:1-31:189\"><strong>1.STM32F446REのI2C Controller Mode のAck/NAck確認は、ハードが行っている。</strong><br>\n　エラーが発生した場合、割り込みで処理する。なので、基本、ソフトで、Ack返信待ちをする必要はないが、Targetデバイスが、返信しないと、フリーズする。メリットは、プログラム構成がすっきりしていること。<br>\nユーザーから見えないステートマシンが、I2Cの状態遷移での具体的な処理をおこなっていると想定。なので、Ack確認が、自動になっている。</p>\n<p data-sourcepos=\"33:1-33:116\"><strong>2.TargetアドレスのLSBビットのRWビットで、送信モードと、受信モードに入れ替わる。</strong></p>\n</div>\n</div>\n<h1 data-sourcepos=\"38:1-38:38\">\n<span id=\"i2cモジュール基本コード\" class=\"fragment\"></span><a href=\"#i2c%E3%83%A2%E3%82%B8%E3%83%A5%E3%83%BC%E3%83%AB%E5%9F%BA%E6%9C%AC%E3%82%B3%E3%83%BC%E3%83%89\"><i class=\"fa fa-link\"></i></a>I2Cモジュール　基本コード</h1>\n<p data-sourcepos=\"39:1-39:270\">2バイトデータ書き込みと、１バイトデータ読み込みを作成。これで、MCP23017のレジスタ設定と、その値の読み込みが可能になります。通信がずっこけると、フリーズするので、改良の余地はあります。</p>\n<p data-sourcepos=\"41:1-41:193\">あと、OV７６７０カメラのSCCB通信時の仕様対応で、Controllerモードのときに、Ack確認をすっ飛ばせるか、確認したいです。それは、またあとで。</p>\n<p data-sourcepos=\"43:1-43:51\">とりあえず、通信できるコードです。</p>\n<div class=\"code-frame\" data-lang=\"C\" data-sourcepos=\"45:1-67:3\">\n<div class=\"code-lang\"><span class=\"bold\">myI2C.h</span></div>\n<div class=\"highlight\"><pre><code><span class=\"cp\">#ifndef INC_MYI2C_H_\n#define INC_MYI2C_H_\n</span>\n<span class=\"cp\">#include</span> <span class=\"cpf\">\"main.h\"</span><span class=\"cp\">\n#include</span> <span class=\"cpf\">\"myUsart.h\"</span><span class=\"cp\">\n</span>\n<span class=\"cm\">/*\n * I2Cx drivers\n */</span>\n<span class=\"k\">extern</span> <span class=\"kt\">void</span> <span class=\"nf\">I2Cx_b2Write</span><span class=\"p\">(</span><span class=\"n\">I2C_TypeDef</span> <span class=\"o\">*</span><span class=\"n\">I2Cx</span><span class=\"p\">,</span> <span class=\"kt\">uint8_t</span> <span class=\"n\">devAdd</span><span class=\"p\">,</span> <span class=\"kt\">uint8_t</span> <span class=\"n\">data1</span><span class=\"p\">,</span> <span class=\"kt\">uint8_t</span> <span class=\"n\">data2</span><span class=\"p\">);</span>\n<span class=\"k\">extern</span> <span class=\"kt\">uint8_t</span> <span class=\"nf\">I2Cx_b1Read</span><span class=\"p\">(</span><span class=\"n\">I2C_TypeDef</span> <span class=\"o\">*</span><span class=\"n\">I2Cx</span><span class=\"p\">,</span><span class=\"kt\">uint8_t</span> <span class=\"n\">devAdd</span><span class=\"p\">,</span><span class=\"kt\">uint8_t</span> <span class=\"n\">data1</span><span class=\"p\">);</span>\n\n\n<span class=\"cm\">/*\n * MCP23017 drive\n */</span>\n<span class=\"cp\">#define MCP23017DeviceAdd 0x4C\n</span><span class=\"k\">extern</span> <span class=\"kt\">uint8_t</span> <span class=\"n\">MCP23017_InitData</span><span class=\"p\">[</span><span class=\"mi\">11</span><span class=\"p\">];</span>\n<span class=\"k\">extern</span> <span class=\"kt\">void</span> <span class=\"nf\">MCP23017_Init</span><span class=\"p\">(</span><span class=\"kt\">uint8_t</span> <span class=\"n\">deviceAdd</span><span class=\"p\">);</span>\n\n<span class=\"cp\">#endif </span><span class=\"cm\">/* INC_MYI2C_H_ */</span><span class=\"cp\">\n</span></code></pre></div>\n</div>\n<div class=\"code-frame\" data-lang=\"C\" data-sourcepos=\"69:1-190:3\">\n<div class=\"code-lang\"><span class=\"bold\">myI2C.c</span></div>\n<div class=\"highlight\"><pre><code><span class=\"cp\">#include</span> <span class=\"cpf\">\"myI2C.h\"</span><span class=\"cp\">\n</span>\n\n<span class=\"cm\">/**\n * I2C1_b2Write\n * @brief 2byte writting\n * @param *I2Cx: I2Cx Instance\n * @param devAdd: Client Address\n * @param data1: send data1\n * @param data2: send data2\n */</span>\n<span class=\"kt\">void</span> <span class=\"nf\">I2C1_b2Write</span><span class=\"p\">(</span><span class=\"n\">I2C_TypeDef</span> <span class=\"o\">*</span><span class=\"n\">I2Cx</span><span class=\"p\">,</span> <span class=\"kt\">uint8_t</span> <span class=\"n\">devAdd</span><span class=\"p\">,</span> <span class=\"kt\">uint8_t</span> <span class=\"n\">data1</span><span class=\"p\">,</span> <span class=\"kt\">uint8_t</span> <span class=\"n\">data2</span><span class=\"p\">)</span>\n<span class=\"p\">{</span>\n\t<span class=\"kt\">uint32_t</span> <span class=\"n\">val</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span>\n\t<span class=\"c1\">//StartCondition</span>\n\t<span class=\"n\">LL_I2C_GenerateStartCondition</span><span class=\"p\">(</span><span class=\"n\">I2Cx</span><span class=\"p\">);</span>\n\t<span class=\"k\">while</span><span class=\"p\">(</span><span class=\"o\">!</span><span class=\"n\">LL_I2C_IsActiveFlag_SB</span><span class=\"p\">(</span><span class=\"n\">I2Cx</span><span class=\"p\">));</span>\n\t<span class=\"c1\">//Device Address send</span>\n\t<span class=\"n\">LL_I2C_TransmitData8</span><span class=\"p\">(</span><span class=\"n\">I2Cx</span><span class=\"p\">,</span><span class=\"n\">devAdd</span><span class=\"p\">);</span>\n\t<span class=\"k\">while</span><span class=\"p\">(</span><span class=\"o\">!</span><span class=\"n\">LL_I2C_IsActiveFlag_ADDR</span><span class=\"p\">(</span><span class=\"n\">I2Cx</span><span class=\"p\">));</span>\n\t<span class=\"c1\">//Reset ADDR bit after SR1 SR2 reading</span>\n\t<span class=\"n\">val</span><span class=\"o\">=</span><span class=\"n\">I2Cx</span><span class=\"o\">-&gt;</span><span class=\"n\">SR1</span><span class=\"p\">;</span>\n\t<span class=\"n\">val</span><span class=\"o\">=</span><span class=\"n\">I2Cx</span><span class=\"o\">-&gt;</span><span class=\"n\">SR2</span><span class=\"p\">;</span>\n\t<span class=\"c1\">//Data1 send mode</span>\n\t<span class=\"k\">while</span><span class=\"p\">(</span><span class=\"o\">!</span><span class=\"n\">LL_I2C_IsActiveFlag_TXE</span><span class=\"p\">(</span><span class=\"n\">I2Cx</span><span class=\"p\">));</span>\n\t<span class=\"n\">LL_I2C_TransmitData8</span><span class=\"p\">(</span><span class=\"n\">I2Cx</span><span class=\"p\">,</span><span class=\"n\">data1</span><span class=\"p\">);</span>\n\t<span class=\"c1\">//Data2 send</span>\n\t<span class=\"k\">while</span><span class=\"p\">(</span><span class=\"o\">!</span><span class=\"n\">LL_I2C_IsActiveFlag_TXE</span><span class=\"p\">(</span><span class=\"n\">I2Cx</span><span class=\"p\">));</span>\n\t<span class=\"n\">LL_I2C_TransmitData8</span><span class=\"p\">(</span><span class=\"n\">I2Cx</span><span class=\"p\">,</span><span class=\"n\">data2</span><span class=\"p\">);</span>\n\t<span class=\"c1\">//Stop Condition</span>\n\t<span class=\"k\">while</span><span class=\"p\">(</span><span class=\"o\">!</span><span class=\"n\">LL_I2C_IsActiveFlag_TXE</span><span class=\"p\">(</span><span class=\"n\">I2Cx</span><span class=\"p\">));</span>\n\t<span class=\"n\">LL_I2C_GenerateStopCondition</span><span class=\"p\">(</span><span class=\"n\">I2Cx</span><span class=\"p\">);</span>\n<span class=\"p\">}</span>\n\n\n<span class=\"cm\">/*\n * I2Cx_b1Read\n * @brief 1byte read\n * @param I2Cx: I2C instance\n * @param devAdd: I2C Client Address\n * @param data1: send data\n * @retrun ret:received data\n */</span>\n<span class=\"kt\">uint8_t</span> <span class=\"nf\">I2Cx_b1Read</span><span class=\"p\">(</span><span class=\"n\">I2C_TypeDef</span> <span class=\"o\">*</span><span class=\"n\">I2Cx</span><span class=\"p\">,</span><span class=\"kt\">uint8_t</span> <span class=\"n\">devAdd</span><span class=\"p\">,</span><span class=\"kt\">uint8_t</span> <span class=\"n\">data1</span><span class=\"p\">)</span>\n<span class=\"p\">{</span>\n\t<span class=\"kt\">uint8_t</span> <span class=\"n\">val</span><span class=\"p\">,</span> <span class=\"n\">ret</span><span class=\"p\">;</span>\n\t<span class=\"n\">val</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span>\n\t<span class=\"c1\">//StartCondition</span>\n\t<span class=\"n\">LL_I2C_GenerateStartCondition</span><span class=\"p\">(</span><span class=\"n\">I2Cx</span><span class=\"p\">);</span>\n\t<span class=\"k\">while</span><span class=\"p\">(</span><span class=\"o\">!</span><span class=\"n\">LL_I2C_IsActiveFlag_SB</span><span class=\"p\">(</span><span class=\"n\">I2Cx</span><span class=\"p\">));</span>\n\t<span class=\"c1\">//Device Address send</span>\n\t<span class=\"n\">LL_I2C_TransmitData8</span><span class=\"p\">(</span><span class=\"n\">I2Cx</span><span class=\"p\">,</span><span class=\"n\">devAdd</span><span class=\"p\">);</span>\n\t<span class=\"k\">while</span><span class=\"p\">(</span><span class=\"o\">!</span><span class=\"n\">LL_I2C_IsActiveFlag_ADDR</span><span class=\"p\">(</span><span class=\"n\">I2Cx</span><span class=\"p\">));</span>\n\t<span class=\"c1\">//Reset ADDR bit after reading SR1 and SR2</span>\n\t<span class=\"n\">val</span><span class=\"o\">=</span><span class=\"n\">I2Cx</span><span class=\"o\">-&gt;</span><span class=\"n\">SR1</span><span class=\"p\">;</span>\n\t<span class=\"n\">val</span><span class=\"o\">=</span><span class=\"n\">I2Cx</span><span class=\"o\">-&gt;</span><span class=\"n\">SR2</span><span class=\"p\">;</span>\n\t<span class=\"c1\">//Data1 send</span>\n\t<span class=\"k\">while</span><span class=\"p\">(</span><span class=\"o\">!</span><span class=\"n\">LL_I2C_IsActiveFlag_TXE</span><span class=\"p\">(</span><span class=\"n\">I2Cx</span><span class=\"p\">));</span>\n\t<span class=\"n\">LL_I2C_TransmitData8</span><span class=\"p\">(</span><span class=\"n\">I2Cx</span><span class=\"p\">,</span><span class=\"n\">data1</span><span class=\"p\">);</span>\n\t<span class=\"c1\">//ReStart Condition</span>\n\t<span class=\"c1\">//while(!LL_I2C_IsActiveFlag_TXE(I2Cx));</span>\n\t<span class=\"n\">LL_I2C_GenerateStartCondition</span><span class=\"p\">(</span><span class=\"n\">I2Cx</span><span class=\"p\">);</span>\n\t<span class=\"k\">while</span><span class=\"p\">(</span><span class=\"o\">!</span><span class=\"n\">LL_I2C_IsActiveFlag_SB</span><span class=\"p\">(</span><span class=\"n\">I2Cx</span><span class=\"p\">));</span>\n\t<span class=\"c1\">//Device Adress send &amp; set read bit</span>\n\t<span class=\"c1\">//while(!LL_I2C_IsActiveFlag_TXE(I2Cx));</span>\n\t<span class=\"n\">LL_I2C_TransmitData8</span><span class=\"p\">(</span><span class=\"n\">I2Cx</span><span class=\"p\">,</span><span class=\"n\">devAdd</span><span class=\"o\">|</span><span class=\"mh\">0x01</span><span class=\"p\">);</span>\n\t<span class=\"k\">while</span><span class=\"p\">(</span><span class=\"o\">!</span><span class=\"n\">LL_I2C_IsActiveFlag_ADDR</span><span class=\"p\">(</span><span class=\"n\">I2Cx</span><span class=\"p\">));</span>\n\t<span class=\"n\">val</span> <span class=\"o\">=</span> <span class=\"n\">I2Cx</span><span class=\"o\">-&gt;</span><span class=\"n\">SR1</span><span class=\"p\">;</span>\n\t<span class=\"n\">val</span> <span class=\"o\">=</span> <span class=\"n\">I2Cx</span><span class=\"o\">-&gt;</span><span class=\"n\">SR2</span><span class=\"p\">;</span>\n\t<span class=\"c1\">//Receive data mode</span>\n\t<span class=\"n\">LL_I2C_AcknowledgeNextData</span><span class=\"p\">(</span><span class=\"n\">I2Cx</span><span class=\"p\">,</span><span class=\"n\">LL_I2C_ACK</span><span class=\"p\">);</span>\n\t<span class=\"k\">while</span><span class=\"p\">(</span><span class=\"o\">!</span><span class=\"n\">LL_I2C_IsActiveFlag_RXNE</span><span class=\"p\">(</span><span class=\"n\">I2Cx</span><span class=\"p\">));</span>\n\t<span class=\"n\">ret</span> <span class=\"o\">=</span> <span class=\"n\">LL_I2C_ReceiveData8</span><span class=\"p\">(</span><span class=\"n\">I2Cx</span><span class=\"p\">);</span>\n\t<span class=\"n\">LL_I2C_AcknowledgeNextData</span><span class=\"p\">(</span><span class=\"n\">I2Cx</span><span class=\"p\">,</span><span class=\"n\">LL_I2C_NACK</span><span class=\"p\">);</span>\n\t<span class=\"c1\">//Stop Condition</span>\n\t<span class=\"n\">LL_I2C_GenerateStopCondition</span><span class=\"p\">(</span><span class=\"n\">I2Cx</span><span class=\"p\">);</span>\n\n\t<span class=\"k\">return</span> <span class=\"n\">ret</span><span class=\"p\">;</span>\n<span class=\"p\">}</span>\n\n\n\n\n<span class=\"c1\">//*******************************************</span>\n<span class=\"c1\">// MCP23017</span>\n<span class=\"c1\">//*******************************************</span>\n\n<span class=\"kt\">uint8_t</span> <span class=\"n\">MCP23017_InitData</span><span class=\"p\">[</span><span class=\"mi\">11</span><span class=\"p\">]</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"mh\">0x00</span><span class=\"p\">,</span><span class=\"mh\">0x00</span><span class=\"p\">,</span><span class=\"mh\">0x00</span><span class=\"p\">,</span><span class=\"mh\">0x00</span><span class=\"p\">,</span><span class=\"mh\">0x00</span><span class=\"p\">,</span><span class=\"mh\">0x80</span><span class=\"p\">,</span><span class=\"mh\">0x00</span><span class=\"p\">,</span><span class=\"mh\">0x00</span><span class=\"p\">,</span><span class=\"mh\">0x00</span><span class=\"p\">,</span><span class=\"mh\">0x00</span><span class=\"p\">,</span><span class=\"mh\">0x00</span><span class=\"p\">};</span>\n\n<span class=\"cm\">/*\n * MPC23017_Init\n * MCP23017 initializing\n * @param: deviceAdd I2C Client Address\n */</span>\n<span class=\"kt\">void</span> <span class=\"nf\">MCP23017_Init</span><span class=\"p\">(</span><span class=\"kt\">uint8_t</span> <span class=\"n\">deviceAdd</span><span class=\"p\">)</span>\n<span class=\"p\">{</span>\n\t<span class=\"kt\">uint8_t</span> <span class=\"n\">i</span><span class=\"p\">,</span><span class=\"n\">val</span><span class=\"p\">;</span>\n\n\t<span class=\"n\">I2C1_b2Write</span><span class=\"p\">(</span><span class=\"n\">I2C1</span><span class=\"p\">,</span> <span class=\"n\">MCP23017DeviceAdd</span><span class=\"p\">,</span> <span class=\"mh\">0x0A</span><span class=\"p\">,</span> <span class=\"mh\">0x80</span><span class=\"p\">);</span><span class=\"c1\">//Bank chenge</span>\n\t<span class=\"n\">val</span> <span class=\"o\">=</span> <span class=\"n\">I2Cx_b1Read</span><span class=\"p\">(</span><span class=\"n\">I2C1</span><span class=\"p\">,</span> <span class=\"n\">MCP23017DeviceAdd</span><span class=\"p\">,</span> <span class=\"mh\">0x05</span><span class=\"p\">);</span>\n\t<span class=\"n\">printf</span><span class=\"p\">(</span><span class=\"s\">\"[05]=%02X</span><span class=\"se\">\\r</span><span class=\"s\">\"</span><span class=\"p\">,</span><span class=\"n\">val</span><span class=\"p\">);</span>\n\t<span class=\"k\">for</span><span class=\"p\">(</span><span class=\"n\">i</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">&lt;=</span><span class=\"mh\">0x0A</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">++</span><span class=\"p\">)</span>\n\t<span class=\"p\">{</span>\n\t\t<span class=\"n\">I2C1_b2Write</span><span class=\"p\">(</span><span class=\"n\">I2C1</span><span class=\"p\">,</span> <span class=\"n\">MCP23017DeviceAdd</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">MCP23017_InitData</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]);</span>\n\t\t<span class=\"n\">I2C1_b2Write</span><span class=\"p\">(</span><span class=\"n\">I2C1</span><span class=\"p\">,</span> <span class=\"n\">MCP23017DeviceAdd</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"o\">+</span><span class=\"mh\">0x10</span><span class=\"p\">,</span> <span class=\"n\">MCP23017_InitData</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]);</span>\n\t<span class=\"p\">}</span>\n\n\t<span class=\"k\">for</span><span class=\"p\">(</span><span class=\"n\">i</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">&lt;=</span><span class=\"mh\">0x0A</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">++</span><span class=\"p\">)</span>\n\t<span class=\"p\">{</span>\n\t\t<span class=\"n\">val</span> <span class=\"o\">=</span> <span class=\"n\">I2Cx_b1Read</span><span class=\"p\">(</span><span class=\"n\">I2C1</span><span class=\"p\">,</span> <span class=\"n\">MCP23017DeviceAdd</span><span class=\"p\">,</span><span class=\"n\">i</span><span class=\"p\">);</span>\n\t\t<span class=\"n\">printf</span><span class=\"p\">(</span><span class=\"s\">\"[%02x]=%02x</span><span class=\"se\">\\r</span><span class=\"s\">\"</span><span class=\"p\">,</span><span class=\"n\">i</span><span class=\"p\">,</span><span class=\"n\">val</span><span class=\"p\">);</span>\n\t<span class=\"p\">}</span>\n\n\t<span class=\"k\">for</span><span class=\"p\">(</span><span class=\"n\">i</span><span class=\"o\">=</span><span class=\"mh\">0x10</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">&lt;=</span><span class=\"mh\">0x1A</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">++</span><span class=\"p\">)</span>\n\t<span class=\"p\">{</span>\n\t\t<span class=\"n\">val</span> <span class=\"o\">=</span> <span class=\"n\">I2Cx_b1Read</span><span class=\"p\">(</span><span class=\"n\">I2C1</span><span class=\"p\">,</span> <span class=\"n\">MCP23017DeviceAdd</span><span class=\"p\">,</span><span class=\"n\">i</span><span class=\"p\">);</span>\n\t\t<span class=\"n\">printf</span><span class=\"p\">(</span><span class=\"s\">\"[%02x]=%02x</span><span class=\"se\">\\r</span><span class=\"s\">\"</span><span class=\"p\">,</span><span class=\"n\">i</span><span class=\"p\">,</span><span class=\"n\">val</span><span class=\"p\">);</span>\n\t<span class=\"p\">}</span>\n<span class=\"p\">}</span>\n\n</code></pre></div>\n</div>\n",
      "body": "# I2Cモジュール　２バイト書き込み、１バイト読み込み\nたたき台に、16bit IOexpander MCP23017　を使います。\n\n::: note\n### I2C用語確認\nSTM32のリファレンスマニュアルのI2Cデバイス用語\n従来のMasterが、**Controller**\n従来のSlaveが、**Target**\nに変更になっています。PICマイコンのHost-Clientと同じような変更です。\n:::\nコードは、LLライブラリーを使用しています。\n![IMG_5468.JPG](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/3693934/4dd64b2a-81fd-469c-b453-a78be9729b7d.jpeg)\n\n:::note\n### I2C1 MX側の処理\n1.MX生成のI2Cモジュール初期化コードに手を加える必要なし。\n2.I2C1担当のGPIOはMXでプルアップした。\n![I2C設定画面.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/3693934/cd814eec-4cf7-40d1-ab76-19228e88a6e8.png)\n\n以前の配線に追加した端子 Nucleo-F446RE\n| コネクタ | 番号 |ピン名|機能|\n|:-:|:-:|:-:|:-:|\n|CN5|3|RB6|I2C1 SCL|\n|CN7|21|RB7|I2C1 SDA|\n:::\n\n:::note\n### I2Cモジュールの要点\n**1.STM32F446REのI2C Controller Mode のAck/NAck確認は、ハードが行っている。**\n　エラーが発生した場合、割り込みで処理する。なので、基本、ソフトで、Ack返信待ちをする必要はないが、Targetデバイスが、返信しないと、フリーズする。メリットは、プログラム構成がすっきりしていること。\nユーザーから見えないステートマシンが、I2Cの状態遷移での具体的な処理をおこなっていると想定。なので、Ack確認が、自動になっている。\n\n**2.TargetアドレスのLSBビットのRWビットで、送信モードと、受信モードに入れ替わる。**\n\n\n:::\n\n# I2Cモジュール　基本コード\n2バイトデータ書き込みと、１バイトデータ読み込みを作成。これで、MCP23017のレジスタ設定と、その値の読み込みが可能になります。通信がずっこけると、フリーズするので、改良の余地はあります。\n\nあと、OV７６７０カメラのSCCB通信時の仕様対応で、Controllerモードのときに、Ack確認をすっ飛ばせるか、確認したいです。それは、またあとで。\n\nとりあえず、通信できるコードです。\n\n```C:myI2C.h\n#ifndef INC_MYI2C_H_\n#define INC_MYI2C_H_\n\n#include \"main.h\"\n#include \"myUsart.h\"\n\n/*\n * I2Cx drivers\n */\nextern void I2Cx_b2Write(I2C_TypeDef *I2Cx, uint8_t devAdd, uint8_t data1, uint8_t data2);\nextern uint8_t I2Cx_b1Read(I2C_TypeDef *I2Cx,uint8_t devAdd,uint8_t data1);\n\n\n/*\n * MCP23017 drive\n */\n#define MCP23017DeviceAdd 0x4C\nextern uint8_t MCP23017_InitData[11];\nextern void MCP23017_Init(uint8_t deviceAdd);\n\n#endif /* INC_MYI2C_H_ */\n```\n\n```C:myI2C.c\n#include \"myI2C.h\"\n\n\n/**\n * I2C1_b2Write\n * @brief 2byte writting\n * @param *I2Cx: I2Cx Instance\n * @param devAdd: Client Address\n * @param data1: send data1\n * @param data2: send data2\n */\nvoid I2C1_b2Write(I2C_TypeDef *I2Cx, uint8_t devAdd, uint8_t data1, uint8_t data2)\n{\n\tuint32_t val=0;\n\t//StartCondition\n\tLL_I2C_GenerateStartCondition(I2Cx);\n\twhile(!LL_I2C_IsActiveFlag_SB(I2Cx));\n\t//Device Address send\n\tLL_I2C_TransmitData8(I2Cx,devAdd);\n\twhile(!LL_I2C_IsActiveFlag_ADDR(I2Cx));\n\t//Reset ADDR bit after SR1 SR2 reading\n\tval=I2Cx->SR1;\n\tval=I2Cx->SR2;\n\t//Data1 send mode\n\twhile(!LL_I2C_IsActiveFlag_TXE(I2Cx));\n\tLL_I2C_TransmitData8(I2Cx,data1);\n\t//Data2 send\n\twhile(!LL_I2C_IsActiveFlag_TXE(I2Cx));\n\tLL_I2C_TransmitData8(I2Cx,data2);\n\t//Stop Condition\n\twhile(!LL_I2C_IsActiveFlag_TXE(I2Cx));\n\tLL_I2C_GenerateStopCondition(I2Cx);\n}\n\n\n/*\n * I2Cx_b1Read\n * @brief 1byte read\n * @param I2Cx: I2C instance\n * @param devAdd: I2C Client Address\n * @param data1: send data\n * @retrun ret:received data\n */\nuint8_t I2Cx_b1Read(I2C_TypeDef *I2Cx,uint8_t devAdd,uint8_t data1)\n{\n\tuint8_t val, ret;\n\tval=0;\n\t//StartCondition\n\tLL_I2C_GenerateStartCondition(I2Cx);\n\twhile(!LL_I2C_IsActiveFlag_SB(I2Cx));\n\t//Device Address send\n\tLL_I2C_TransmitData8(I2Cx,devAdd);\n\twhile(!LL_I2C_IsActiveFlag_ADDR(I2Cx));\n\t//Reset ADDR bit after reading SR1 and SR2\n\tval=I2Cx->SR1;\n\tval=I2Cx->SR2;\n\t//Data1 send\n\twhile(!LL_I2C_IsActiveFlag_TXE(I2Cx));\n\tLL_I2C_TransmitData8(I2Cx,data1);\n\t//ReStart Condition\n\t//while(!LL_I2C_IsActiveFlag_TXE(I2Cx));\n\tLL_I2C_GenerateStartCondition(I2Cx);\n\twhile(!LL_I2C_IsActiveFlag_SB(I2Cx));\n\t//Device Adress send & set read bit\n\t//while(!LL_I2C_IsActiveFlag_TXE(I2Cx));\n\tLL_I2C_TransmitData8(I2Cx,devAdd|0x01);\n\twhile(!LL_I2C_IsActiveFlag_ADDR(I2Cx));\n\tval = I2Cx->SR1;\n\tval = I2Cx->SR2;\n\t//Receive data mode\n\tLL_I2C_AcknowledgeNextData(I2Cx,LL_I2C_ACK);\n\twhile(!LL_I2C_IsActiveFlag_RXNE(I2Cx));\n\tret = LL_I2C_ReceiveData8(I2Cx);\n\tLL_I2C_AcknowledgeNextData(I2Cx,LL_I2C_NACK);\n\t//Stop Condition\n\tLL_I2C_GenerateStopCondition(I2Cx);\n\n\treturn ret;\n}\n\n\n\n\n//*******************************************\n// MCP23017\n//*******************************************\n\nuint8_t MCP23017_InitData[11]={0x00,0x00,0x00,0x00,0x00,0x80,0x00,0x00,0x00,0x00,0x00};\n\n/*\n * MPC23017_Init\n * MCP23017 initializing\n * @param: deviceAdd I2C Client Address\n */\nvoid MCP23017_Init(uint8_t deviceAdd)\n{\n\tuint8_t i,val;\n\n\tI2C1_b2Write(I2C1, MCP23017DeviceAdd, 0x0A, 0x80);//Bank chenge\n\tval = I2Cx_b1Read(I2C1, MCP23017DeviceAdd, 0x05);\n\tprintf(\"[05]=%02X\\r\",val);\n\tfor(i=0; i<=0x0A; i++)\n\t{\n\t\tI2C1_b2Write(I2C1, MCP23017DeviceAdd, i, MCP23017_InitData[i]);\n\t\tI2C1_b2Write(I2C1, MCP23017DeviceAdd, i+0x10, MCP23017_InitData[i]);\n\t}\n\n\tfor(i=0; i<=0x0A; i++)\n\t{\n\t\tval = I2Cx_b1Read(I2C1, MCP23017DeviceAdd,i);\n\t\tprintf(\"[%02x]=%02x\\r\",i,val);\n\t}\n\n\tfor(i=0x10; i<=0x1A; i++)\n\t{\n\t\tval = I2Cx_b1Read(I2C1, MCP23017DeviceAdd,i);\n\t\tprintf(\"[%02x]=%02x\\r\",i,val);\n\t}\n}\n\n```\n",
      "coediting": false,
      "comments_count": 0,
      "created_at": "2025-12-11T17:44:52+09:00",
      "group": null,
      "id": "663195101581335dda26",
      "likes_count": 0,
      "private": false,
      "reactions_count": 0,
      "stocks_count": 0,
      "tags": [
        {
          "name": "STM32",
          "versions": []
        },
        {
          "name": "Nucleo-F446RE",
          "versions": []
        }
      ],
      "title": "Nucleo-F446RE ４.I2C通信　読み書き",
      "updated_at": "2025-12-11T17:44:52+09:00",
      "url": "https://qiita.com/etoolsLab369/items/663195101581335dda26",
      "user": {
        "description": null,
        "facebook_id": null,
        "followees_count": 1,
        "followers_count": 8,
        "github_login_name": null,
        "id": "etoolsLab369",
        "items_count": 71,
        "linkedin_id": null,
        "location": null,
        "name": "",
        "organization": null,
        "permanent_id": 3693934,
        "profile_image_url": "https://secure.gravatar.com/avatar/298b8e5a54213ff92411fb08410fd2b9",
        "team_only": false,
        "twitter_screen_name": null,
        "website_url": null
      },
      "page_views_count": null,
      "team_membership": null,
      "organization_url_name": null,
      "slide": false,
      "_source": "trending_by_likes"
    },
    {
      "rendered_body": "<h1 data-sourcepos=\"1:1-1:138\">\n<span id=\"difyとgemini-llmを活用したバイオインフォマティクス向けragチャットボット構築とbigquery連携実装ガイド\" class=\"fragment\"></span><a href=\"#dify%E3%81%A8gemini-llm%E3%82%92%E6%B4%BB%E7%94%A8%E3%81%97%E3%81%9F%E3%83%90%E3%82%A4%E3%82%AA%E3%82%A4%E3%83%B3%E3%83%95%E3%82%A9%E3%83%9E%E3%83%86%E3%82%A3%E3%82%AF%E3%82%B9%E5%90%91%E3%81%91rag%E3%83%81%E3%83%A3%E3%83%83%E3%83%88%E3%83%9C%E3%83%83%E3%83%88%E6%A7%8B%E7%AF%89%E3%81%A8bigquery%E9%80%A3%E6%90%BA%E5%AE%9F%E8%A3%85%E3%82%AC%E3%82%A4%E3%83%89\"><i class=\"fa fa-link\"></i></a>DifyとGemini LLMを活用したバイオインフォマティクス向けRAGチャットボット構築とBigQuery連携実装ガイド</h1>\n<blockquote data-sourcepos=\"3:1-4:201\">\n<p data-sourcepos=\"3:3-4:201\"><strong>対象読者</strong><br>\nバイオインフォマティクス研究者・エンジニア、AIチャットボット開発者、クラウド技術者、Qiita記事自動投稿に関心のある中級以上のプログラマー</p>\n</blockquote>\n<blockquote data-sourcepos=\"6:1-13:95\">\n<p data-sourcepos=\"6:3-6:41\"><strong>動作確認環境 / 前提条件</strong></p>\n<ul data-sourcepos=\"7:3-13:95\">\n<li data-sourcepos=\"7:3-7:43\">OS: Ubuntu 22.04 LTS / macOS Monterey</li>\n<li data-sourcepos=\"8:3-8:22\">Python 3.9以上</li>\n<li data-sourcepos=\"9:3-9:43\">Google Cloud SDK最新バージョン</li>\n<li data-sourcepos=\"10:3-10:32\">BigQueryアクセス権限</li>\n<li data-sourcepos=\"11:3-11:49\">Difyアカウント（無料プラン可）</li>\n<li data-sourcepos=\"12:3-12:51\">Google Cloud Vertex AI Gemini LLM利用権限</li>\n<li data-sourcepos=\"13:3-13:95\">前提知識: Pythonプログラミング基礎、REST API利用経験、GCPの基本操作</li>\n</ul>\n</blockquote>\n<blockquote data-sourcepos=\"15:1-18:107\">\n<p data-sourcepos=\"15:3-15:41\"><strong>この記事で得られること</strong></p>\n<ol data-sourcepos=\"16:3-18:107\">\n<li data-sourcepos=\"16:3-16:110\">Difyノーコードプラットフォームでバイオ知識ナレッジベースを構築する手順</li>\n<li data-sourcepos=\"17:3-17:95\">PythonでのGemini LLM連携による埋め込み検索＋自然言語応答の実装例</li>\n<li data-sourcepos=\"18:3-18:107\">BigQueryでのチャットボットログ蓄積と分析基盤設計、Next.jsによるWeb最適化例</li>\n</ol>\n</blockquote>\n<hr data-sourcepos=\"20:1-21:0\">\n<h2 data-sourcepos=\"22:1-22:79\">\n<span id=\"-導入aiナレッジベースとragチャットボットの重要性\" class=\"fragment\"></span><a href=\"#-%E5%B0%8E%E5%85%A5ai%E3%83%8A%E3%83%AC%E3%83%83%E3%82%B8%E3%83%99%E3%83%BC%E3%82%B9%E3%81%A8rag%E3%83%81%E3%83%A3%E3%83%83%E3%83%88%E3%83%9C%E3%83%83%E3%83%88%E3%81%AE%E9%87%8D%E8%A6%81%E6%80%A7\"><i class=\"fa fa-link\"></i></a>🧭 導入：AIナレッジベースとRAGチャットボットの重要性</h2>\n<p data-sourcepos=\"24:1-24:373\">GEM Labの若手調査員として新大陸の未知生命の探索調査を進める中、「大量の研究論文や解析報告をどう効率的に活用・共有するか」が課題となりました。バイオインフォマティクス領域ではデータも知識も膨大で散逸しやすく、調査活動の迅速な意思決定に支障をきたします。</p>\n<p data-sourcepos=\"26:1-26:455\">こうした課題を解決してくれるのが、最新のAI大規模言語モデル（LLM）を用いた<strong>RAG（Retrieval-Augmented Generation）チャットボット</strong>です。RAGは知識検索機能を組み合わせLLMの生成力で自然言語応答を行います。特にDifyのようなノーコードプラットフォームと、Google CloudのGemini LLMの組み合わせは導入の敷居が低く、かつ高度な対話が可能です。</p>\n<p data-sourcepos=\"28:1-28:396\">本記事では、GEM Labの調査員の視点でバイオインフォマティクス特化型チャットボットの構築から、大規模評価ログの管理、WebUI最適化までの技術的ワークフローを具体的に紹介します。これにより、読者の皆さんにも自分の研究や事業に適用可能な汎用技術として習得できる内容としています。</p>\n<hr data-sourcepos=\"30:1-31:0\">\n<h2 data-sourcepos=\"32:1-32:88\">\n<span id=\"-トピックの概要difyとgemini-llmで実現するragチャットボット\" class=\"fragment\"></span><a href=\"#-%E3%83%88%E3%83%94%E3%83%83%E3%82%AF%E3%81%AE%E6%A6%82%E8%A6%81dify%E3%81%A8gemini-llm%E3%81%A7%E5%AE%9F%E7%8F%BE%E3%81%99%E3%82%8Brag%E3%83%81%E3%83%A3%E3%83%83%E3%83%88%E3%83%9C%E3%83%83%E3%83%88\"><i class=\"fa fa-link\"></i></a>📘 トピックの概要：DifyとGemini LLMで実現するRAGチャットボット</h2>\n<h3 data-sourcepos=\"34:1-34:38\">\n<span id=\"difyプラットフォームとは\" class=\"fragment\"></span><a href=\"#dify%E3%83%97%E3%83%A9%E3%83%83%E3%83%88%E3%83%95%E3%82%A9%E3%83%BC%E3%83%A0%E3%81%A8%E3%81%AF\"><i class=\"fa fa-link\"></i></a>Difyプラットフォームとは</h3>\n<p data-sourcepos=\"35:1-35:332\">Difyはノーコードで文章のチャンク分割・埋め込み検索を実現できるクラウドサービスです。大量文書を小さな情報単位に分割（チャンク化）し、意味的に近い情報を高速検索できます。GEM Labの未知生命データ解析報告もこの方式で管理可能です。</p>\n<h3 data-sourcepos=\"37:1-37:23\">\n<span id=\"gemini-llmの特徴\" class=\"fragment\"></span><a href=\"#gemini-llm%E3%81%AE%E7%89%B9%E5%BE%B4\"><i class=\"fa fa-link\"></i></a>Gemini LLMの特徴</h3>\n<p data-sourcepos=\"38:1-38:251\">Google Cloud Vertex AIで提供されるGemini LLMは、膨大な科学論文や技術データを学習した強力な大規模言語モデルです。検索した文書チャンクを入力に文脈を理解し、自然な回答を生成します。</p>\n<h3 data-sourcepos=\"40:1-40:22\">\n<span id=\"ragの技術背景\" class=\"fragment\"></span><a href=\"#rag%E3%81%AE%E6%8A%80%E8%A1%93%E8%83%8C%E6%99%AF\"><i class=\"fa fa-link\"></i></a>RAGの技術背景</h3>\n<p data-sourcepos=\"41:1-41:49\">RAGは大まかに2段階に分けられます：</p>\n<ol data-sourcepos=\"43:1-45:0\">\n<li data-sourcepos=\"43:1-43:129\">\n<strong>Retrieval（検索）</strong>：ユーザーの質問に関連する文書チャンクを埋め込みベクトル検索で特定</li>\n<li data-sourcepos=\"44:1-45:0\">\n<strong>Augmented Generation（拡張生成）</strong>：Gemini LLMに検索結果を与え、質問への回答を生成</li>\n</ol>\n<p data-sourcepos=\"46:1-46:141\">こうしてLLMの大量知識保持に加え、最新のローカル知見を活用できるハイブリッド設計が成り立ちます。</p>\n<p data-sourcepos=\"48:1-49:153\">（文章で図解イメージ案：<br>\n「質問入力 → ベクトル埋め込み → Dify検索 → 関連文書チャンク抽出 → Gemini LLMへ提供 → 自然言語回答生成」）</p>\n<hr data-sourcepos=\"51:1-52:0\">\n<h2 data-sourcepos=\"53:1-53:73\">\n<span id=\"-技術的な仕組みragとbigquery評価ログ基盤の詳細\" class=\"fragment\"></span><a href=\"#-%E6%8A%80%E8%A1%93%E7%9A%84%E3%81%AA%E4%BB%95%E7%B5%84%E3%81%BFrag%E3%81%A8bigquery%E8%A9%95%E4%BE%A1%E3%83%AD%E3%82%B0%E5%9F%BA%E7%9B%A4%E3%81%AE%E8%A9%B3%E7%B4%B0\"><i class=\"fa fa-link\"></i></a>🔧 技術的な仕組み：RAGとBigQuery評価ログ基盤の詳細</h2>\n<h3 data-sourcepos=\"55:1-55:67\">\n<span id=\"1-文章チャンクの再帰分割と重複チャンク戦略\" class=\"fragment\"></span><a href=\"#1-%E6%96%87%E7%AB%A0%E3%83%81%E3%83%A3%E3%83%B3%E3%82%AF%E3%81%AE%E5%86%8D%E5%B8%B0%E5%88%86%E5%89%B2%E3%81%A8%E9%87%8D%E8%A4%87%E3%83%81%E3%83%A3%E3%83%B3%E3%82%AF%E6%88%A6%E7%95%A5\"><i class=\"fa fa-link\"></i></a>1. 文章チャンクの再帰分割と重複チャンク戦略</h3>\n<p data-sourcepos=\"56:1-57:103\">長大な論文や報告を単純に分割すると、切れ目で意味があいまいになることがあります。再帰的な分割アルゴリズムで小単位に分割しつつ、前後のチャンクを重複させることで文脈を保持。<br>\nこの手法はDifyプラットフォーム上でGUI操作もしくはAPI経由で設定可能です。</p>\n<h3 data-sourcepos=\"59:1-59:37\">\n<span id=\"2-埋め込みベクトル検索\" class=\"fragment\"></span><a href=\"#2-%E5%9F%8B%E3%82%81%E8%BE%BC%E3%81%BF%E3%83%99%E3%82%AF%E3%83%88%E3%83%AB%E6%A4%9C%E7%B4%A2\"><i class=\"fa fa-link\"></i></a>2. 埋め込みベクトル検索</h3>\n<p data-sourcepos=\"60:1-60:227\">チャンク文書はBERT系埋め込みモデルでベクトル化され、検索時はcos類似度等で関連度スコアを算出。高速な類似度検索はANNアルゴリズム（HNSWなど）でスケールします。</p>\n<h3 data-sourcepos=\"62:1-62:48\">\n<span id=\"3-bigquery上の推論評価ログ管理\" class=\"fragment\"></span><a href=\"#3-bigquery%E4%B8%8A%E3%81%AE%E6%8E%A8%E8%AB%96%E8%A9%95%E4%BE%A1%E3%83%AD%E3%82%B0%E7%AE%A1%E7%90%86\"><i class=\"fa fa-link\"></i></a>3. BigQuery上の推論・評価ログ管理</h3>\n<p data-sourcepos=\"63:1-63:102\">GEM Labの膨大な推論データを扱うためBigQueryに下記テーブルを設計しました：</p>\n<ul data-sourcepos=\"65:1-68:0\">\n<li data-sourcepos=\"65:1-65:95\">\n<strong>InferenceLog</strong>：質問文、検索チャンクID、Gemini応答文、タイムスタンプ</li>\n<li data-sourcepos=\"66:1-66:94\">\n<strong>ResponseMetadata</strong>：Geminiの生成パラメータ（温度、最大トークン数等）</li>\n<li data-sourcepos=\"67:1-68:0\">\n<strong>UserFeedback</strong>：調査員からの評価スコアやコメント</li>\n</ul>\n<p data-sourcepos=\"69:1-69:129\">これらを結合分析し、対話性能の継続的改善と異常検知、性能モニタリングに活用しています。</p>\n<hr data-sourcepos=\"71:1-72:0\">\n<h2 data-sourcepos=\"73:1-73:102\">\n<span id=\"-実践編difyでのナレッジベース構築とpythonによる関連検索応答生成\" class=\"fragment\"></span><a href=\"#-%E5%AE%9F%E8%B7%B5%E7%B7%A8dify%E3%81%A7%E3%81%AE%E3%83%8A%E3%83%AC%E3%83%83%E3%82%B8%E3%83%99%E3%83%BC%E3%82%B9%E6%A7%8B%E7%AF%89%E3%81%A8python%E3%81%AB%E3%82%88%E3%82%8B%E9%96%A2%E9%80%A3%E6%A4%9C%E7%B4%A2%E5%BF%9C%E7%AD%94%E7%94%9F%E6%88%90\"><i class=\"fa fa-link\"></i></a>🧪 実践編：Difyでのナレッジベース構築とPythonによる関連検索＋応答生成</h2>\n<h3 data-sourcepos=\"75:1-75:84\">\n<span id=\"1-dify-guiでのテキストアップロードチャンク識別設定手順\" class=\"fragment\"></span><a href=\"#1-dify-gui%E3%81%A7%E3%81%AE%E3%83%86%E3%82%AD%E3%82%B9%E3%83%88%E3%82%A2%E3%83%83%E3%83%97%E3%83%AD%E3%83%BC%E3%83%89%E3%83%81%E3%83%A3%E3%83%B3%E3%82%AF%E8%AD%98%E5%88%A5%E8%A8%AD%E5%AE%9A%E6%89%8B%E9%A0%86\"><i class=\"fa fa-link\"></i></a>1. Dify GUIでのテキストアップロード・チャンク識別設定手順</h3>\n<div class=\"code-frame\" data-lang=\"bash\" data-sourcepos=\"77:1-85:3\"><div class=\"highlight\"><pre><code><span class=\"c\"># Difyへログイン後の基本操作概要</span>\n<span class=\"c\"># 1. ナレッジベース作成 → [新規作成]クリック</span>\n<span class=\"c\"># 2. バイオ関連文書をPDF・テキストでアップロード</span>\n<span class=\"c\"># 3. チャンクサイズ（例：500トークン）とオーバーラップ率（例：20%）を設定</span>\n<span class=\"c\"># 4. 自動チャンク生成ボタン押下 → 分割処理実行開始</span>\n<span class=\"c\"># 5. 埋め込みベクトル生成&amp;インデックス作成の進捗を待つ</span>\n<span class=\"c\"># 6. 検索設定で類似度閾値や結果取得件数を調整</span>\n</code></pre></div></div>\n<blockquote data-sourcepos=\"87:1-87:119\">\n<p data-sourcepos=\"87:3-87:119\">GUIのため細部ステップは画面キャプチャ付きの公式ドキュメント参照がおすすめです。</p>\n</blockquote>\n<h3 data-sourcepos=\"89:1-89:80\">\n<span id=\"2-python擬似コードでの埋め込み検索とgemini-api呼び出し例\" class=\"fragment\"></span><a href=\"#2-python%E6%93%AC%E4%BC%BC%E3%82%B3%E3%83%BC%E3%83%89%E3%81%A7%E3%81%AE%E5%9F%8B%E3%82%81%E8%BE%BC%E3%81%BF%E6%A4%9C%E7%B4%A2%E3%81%A8gemini-api%E5%91%BC%E3%81%B3%E5%87%BA%E3%81%97%E4%BE%8B\"><i class=\"fa fa-link\"></i></a>2. Python擬似コードでの埋め込み検索とGemini API呼び出し例</h3>\n<div class=\"code-frame\" data-lang=\"python\" data-sourcepos=\"91:1-142:3\"><div class=\"highlight\"><pre><code><span class=\"kn\">import</span> <span class=\"n\">requests</span>\n<span class=\"kn\">import</span> <span class=\"n\">json</span>\n\n<span class=\"c1\"># DifyのAPIキーとGemini LLMエンドポイント\n</span><span class=\"n\">DIFY_API_URL</span> <span class=\"o\">=</span> <span class=\"sh\">\"</span><span class=\"s\">https://api.dify.ai/v1/search</span><span class=\"sh\">\"</span>\n<span class=\"n\">DIFY_API_KEY</span> <span class=\"o\">=</span> <span class=\"sh\">\"</span><span class=\"s\">your_dify_api_key</span><span class=\"sh\">\"</span>\n\n<span class=\"n\">GEMINI_API_URL</span> <span class=\"o\">=</span> <span class=\"sh\">\"</span><span class=\"s\">https://vertexai.googleapis.com/v1/projects/{project_id}/locations/{location}/models/{model}:predict</span><span class=\"sh\">\"</span>\n<span class=\"n\">GEMINI_API_KEY</span> <span class=\"o\">=</span> <span class=\"sh\">\"</span><span class=\"s\">your_gemini_api_key</span><span class=\"sh\">\"</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">search_chunks</span><span class=\"p\">(</span><span class=\"n\">question</span><span class=\"p\">:</span> <span class=\"nb\">str</span><span class=\"p\">):</span>\n    <span class=\"n\">headers</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n        <span class=\"sh\">\"</span><span class=\"s\">Authorization</span><span class=\"sh\">\"</span><span class=\"p\">:</span> <span class=\"sa\">f</span><span class=\"sh\">\"</span><span class=\"s\">Bearer </span><span class=\"si\">{</span><span class=\"n\">DIFY_API_KEY</span><span class=\"si\">}</span><span class=\"sh\">\"</span><span class=\"p\">,</span>\n        <span class=\"sh\">\"</span><span class=\"s\">Content-Type</span><span class=\"sh\">\"</span><span class=\"p\">:</span> <span class=\"sh\">\"</span><span class=\"s\">application/json</span><span class=\"sh\">\"</span><span class=\"p\">,</span>\n    <span class=\"p\">}</span>\n    <span class=\"n\">payload</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n        <span class=\"sh\">\"</span><span class=\"s\">query</span><span class=\"sh\">\"</span><span class=\"p\">:</span> <span class=\"n\">question</span><span class=\"p\">,</span>\n        <span class=\"sh\">\"</span><span class=\"s\">top_k</span><span class=\"sh\">\"</span><span class=\"p\">:</span> <span class=\"mi\">5</span>\n    <span class=\"p\">}</span>\n    <span class=\"n\">response</span> <span class=\"o\">=</span> <span class=\"n\">requests</span><span class=\"p\">.</span><span class=\"nf\">post</span><span class=\"p\">(</span><span class=\"n\">DIFY_API_URL</span><span class=\"p\">,</span> <span class=\"n\">headers</span><span class=\"o\">=</span><span class=\"n\">headers</span><span class=\"p\">,</span> <span class=\"n\">json</span><span class=\"o\">=</span><span class=\"n\">payload</span><span class=\"p\">)</span>\n    <span class=\"n\">response</span><span class=\"p\">.</span><span class=\"nf\">raise_for_status</span><span class=\"p\">()</span>\n    <span class=\"k\">return</span> <span class=\"n\">response</span><span class=\"p\">.</span><span class=\"nf\">json</span><span class=\"p\">()</span>  <span class=\"c1\"># 検索チャンクの詳細リスト\n</span>\n<span class=\"k\">def</span> <span class=\"nf\">generate_answer</span><span class=\"p\">(</span><span class=\"n\">context_chunks</span><span class=\"p\">:</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">question</span><span class=\"p\">:</span> <span class=\"nb\">str</span><span class=\"p\">):</span>\n    <span class=\"n\">prompt</span> <span class=\"o\">=</span> <span class=\"sa\">f</span><span class=\"sh\">\"</span><span class=\"s\">以下の情報を参考に質問に回答してください：</span><span class=\"se\">\\n</span><span class=\"si\">{</span><span class=\"sh\">''</span><span class=\"p\">.</span><span class=\"nf\">join</span><span class=\"p\">([</span><span class=\"n\">c</span><span class=\"p\">[</span><span class=\"sh\">'</span><span class=\"s\">text</span><span class=\"sh\">'</span><span class=\"p\">]</span> <span class=\"k\">for</span> <span class=\"n\">c</span> <span class=\"ow\">in</span> <span class=\"n\">context_chunks</span><span class=\"p\">])</span><span class=\"si\">}</span><span class=\"se\">\\n</span><span class=\"s\">質問：</span><span class=\"si\">{</span><span class=\"n\">question</span><span class=\"si\">}</span><span class=\"se\">\\n</span><span class=\"s\">回答：</span><span class=\"sh\">\"</span>\n    <span class=\"n\">headers</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n        <span class=\"sh\">\"</span><span class=\"s\">Authorization</span><span class=\"sh\">\"</span><span class=\"p\">:</span> <span class=\"sa\">f</span><span class=\"sh\">\"</span><span class=\"s\">Bearer </span><span class=\"si\">{</span><span class=\"n\">GEMINI_API_KEY</span><span class=\"si\">}</span><span class=\"sh\">\"</span><span class=\"p\">,</span>\n        <span class=\"sh\">\"</span><span class=\"s\">Content-Type</span><span class=\"sh\">\"</span><span class=\"p\">:</span> <span class=\"sh\">\"</span><span class=\"s\">application/json</span><span class=\"sh\">\"</span><span class=\"p\">,</span>\n    <span class=\"p\">}</span>\n    <span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n        <span class=\"sh\">\"</span><span class=\"s\">instances</span><span class=\"sh\">\"</span><span class=\"p\">:</span> <span class=\"p\">[{</span><span class=\"sh\">\"</span><span class=\"s\">content</span><span class=\"sh\">\"</span><span class=\"p\">:</span> <span class=\"n\">prompt</span><span class=\"p\">}],</span>\n        <span class=\"sh\">\"</span><span class=\"s\">parameters</span><span class=\"sh\">\"</span><span class=\"p\">:</span> <span class=\"p\">{</span>\n            <span class=\"sh\">\"</span><span class=\"s\">temperature</span><span class=\"sh\">\"</span><span class=\"p\">:</span> <span class=\"mf\">0.3</span><span class=\"p\">,</span>\n            <span class=\"sh\">\"</span><span class=\"s\">maxOutputTokens</span><span class=\"sh\">\"</span><span class=\"p\">:</span> <span class=\"mi\">512</span>\n        <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n    <span class=\"n\">response</span> <span class=\"o\">=</span> <span class=\"n\">requests</span><span class=\"p\">.</span><span class=\"nf\">post</span><span class=\"p\">(</span><span class=\"n\">GEMINI_API_URL</span><span class=\"p\">,</span> <span class=\"n\">headers</span><span class=\"o\">=</span><span class=\"n\">headers</span><span class=\"p\">,</span> <span class=\"n\">json</span><span class=\"o\">=</span><span class=\"n\">data</span><span class=\"p\">)</span>\n    <span class=\"n\">response</span><span class=\"p\">.</span><span class=\"nf\">raise_for_status</span><span class=\"p\">()</span>\n    <span class=\"n\">pred</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"p\">.</span><span class=\"nf\">json</span><span class=\"p\">()</span>\n    <span class=\"k\">return</span> <span class=\"n\">pred</span><span class=\"p\">[</span><span class=\"sh\">'</span><span class=\"s\">predictions</span><span class=\"sh\">'</span><span class=\"p\">][</span><span class=\"mi\">0</span><span class=\"p\">][</span><span class=\"sh\">'</span><span class=\"s\">content</span><span class=\"sh\">'</span><span class=\"p\">]</span>\n\n<span class=\"k\">if</span> <span class=\"n\">__name__</span> <span class=\"o\">==</span> <span class=\"sh\">\"</span><span class=\"s\">__main__</span><span class=\"sh\">\"</span><span class=\"p\">:</span>\n    <span class=\"n\">user_question</span> <span class=\"o\">=</span> <span class=\"sh\">\"</span><span class=\"s\">RNA-seqデータの正規化方法は何ですか？</span><span class=\"sh\">\"</span>\n    <span class=\"n\">search_result</span> <span class=\"o\">=</span> <span class=\"nf\">search_chunks</span><span class=\"p\">(</span><span class=\"n\">user_question</span><span class=\"p\">)</span>\n    <span class=\"n\">context</span> <span class=\"o\">=</span> <span class=\"n\">search_result</span><span class=\"p\">.</span><span class=\"nf\">get</span><span class=\"p\">(</span><span class=\"sh\">\"</span><span class=\"s\">results</span><span class=\"sh\">\"</span><span class=\"p\">,</span> <span class=\"p\">[])</span>\n    <span class=\"n\">answer</span> <span class=\"o\">=</span> <span class=\"nf\">generate_answer</span><span class=\"p\">(</span><span class=\"n\">context</span><span class=\"p\">,</span> <span class=\"n\">user_question</span><span class=\"p\">)</span>\n    <span class=\"nf\">print</span><span class=\"p\">(</span><span class=\"sh\">\"</span><span class=\"s\">=== 質問 ===</span><span class=\"sh\">\"</span><span class=\"p\">)</span>\n    <span class=\"nf\">print</span><span class=\"p\">(</span><span class=\"n\">user_question</span><span class=\"p\">)</span>\n    <span class=\"nf\">print</span><span class=\"p\">(</span><span class=\"sh\">\"</span><span class=\"s\">=== 回答 ===</span><span class=\"sh\">\"</span><span class=\"p\">)</span>\n    <span class=\"nf\">print</span><span class=\"p\">(</span><span class=\"n\">answer</span><span class=\"p\">)</span>\n</code></pre></div></div>\n<ul data-sourcepos=\"144:1-144:35\">\n<li data-sourcepos=\"144:1-144:35\"><strong>ディレクトリ構成例</strong></li>\n</ul>\n<div class=\"code-frame\" data-lang=\"text\" data-sourcepos=\"145:1-150:3\"><div class=\"highlight\"><pre><code>project-root/\n├── main.py             # 上記コード\n├── requirements.txt    # requestsやGCPクライアント記載\n└── README.md\n</code></pre></div></div>\n<ul data-sourcepos=\"152:1-152:20\">\n<li data-sourcepos=\"152:1-152:20\"><strong>依存関係</strong></li>\n</ul>\n<div class=\"code-frame\" data-lang=\"text\" data-sourcepos=\"153:1-155:3\"><div class=\"highlight\"><pre><code>requests==2.28.1\n</code></pre></div></div>\n<hr data-sourcepos=\"157:1-158:0\">\n<h2 data-sourcepos=\"159:1-159:92\">\n<span id=\"-応用発展実用例バイオデータ解析とnextjsによるui最適化\" class=\"fragment\"></span><a href=\"#-%E5%BF%9C%E7%94%A8%E7%99%BA%E5%B1%95%E5%AE%9F%E7%94%A8%E4%BE%8B%E3%83%90%E3%82%A4%E3%82%AA%E3%83%87%E3%83%BC%E3%82%BF%E8%A7%A3%E6%9E%90%E3%81%A8nextjs%E3%81%AB%E3%82%88%E3%82%8Bui%E6%9C%80%E9%81%A9%E5%8C%96\"><i class=\"fa fa-link\"></i></a>🚀 応用・発展・実用例：バイオデータ解析とNext.jsによるUI最適化</h2>\n<h3 data-sourcepos=\"161:1-161:55\">\n<span id=\"バイオインフォメティクスへの適用例\" class=\"fragment\"></span><a href=\"#%E3%83%90%E3%82%A4%E3%82%AA%E3%82%A4%E3%83%B3%E3%83%95%E3%82%A9%E3%83%A1%E3%83%86%E3%82%A3%E3%82%AF%E3%82%B9%E3%81%B8%E3%81%AE%E9%81%A9%E7%94%A8%E4%BE%8B\"><i class=\"fa fa-link\"></i></a>バイオインフォメティクスへの適用例</h3>\n<ul data-sourcepos=\"162:1-164:0\">\n<li data-sourcepos=\"162:1-162:176\">ゲノム・RNA-seq解析論文のRAG検索で、解析方法やパラメータの即時回答を実現。調査員は未知生命ゲノムの特徴把握に活用可能。</li>\n<li data-sourcepos=\"163:1-164:0\">BigQueryの推論・評価ログから、質問傾向やGemini応答品質を分析し継続的チューニング。</li>\n</ul>\n<h3 data-sourcepos=\"165:1-165:84\">\n<span id=\"bigqueryスキーマ設計例推論レスポンス評価テーブル\" class=\"fragment\"></span><a href=\"#bigquery%E3%82%B9%E3%82%AD%E3%83%BC%E3%83%9E%E8%A8%AD%E8%A8%88%E4%BE%8B%E6%8E%A8%E8%AB%96%E3%83%AC%E3%82%B9%E3%83%9D%E3%83%B3%E3%82%B9%E8%A9%95%E4%BE%A1%E3%83%86%E3%83%BC%E3%83%96%E3%83%AB\"><i class=\"fa fa-link\"></i></a>BigQueryスキーマ設計例（推論・レスポンス・評価テーブル）</h3>\n<div class=\"code-frame\" data-lang=\"sql\" data-sourcepos=\"167:1-191:3\"><div class=\"highlight\"><pre><code><span class=\"k\">CREATE</span> <span class=\"k\">TABLE</span> <span class=\"n\">InferenceLog</span> <span class=\"p\">(</span>\n    <span class=\"n\">id</span> <span class=\"n\">STRING</span> <span class=\"k\">PRIMARY</span> <span class=\"k\">KEY</span><span class=\"p\">,</span>\n    <span class=\"n\">user_query</span> <span class=\"n\">STRING</span><span class=\"p\">,</span>\n    <span class=\"n\">retrieved_chunks</span> <span class=\"n\">ARRAY</span><span class=\"o\">&lt;</span><span class=\"n\">STRING</span><span class=\"o\">&gt;</span><span class=\"p\">,</span>\n    <span class=\"n\">gemini_response</span> <span class=\"n\">STRING</span><span class=\"p\">,</span>\n    <span class=\"nb\">timestamp</span> <span class=\"nb\">TIMESTAMP</span>\n<span class=\"p\">);</span>\n\n<span class=\"k\">CREATE</span> <span class=\"k\">TABLE</span> <span class=\"n\">ResponseMetadata</span> <span class=\"p\">(</span>\n    <span class=\"n\">inference_id</span> <span class=\"n\">STRING</span><span class=\"p\">,</span>\n    <span class=\"n\">temperature</span> <span class=\"n\">FLOAT64</span><span class=\"p\">,</span>\n    <span class=\"n\">max_tokens</span> <span class=\"n\">INT64</span><span class=\"p\">,</span>\n    <span class=\"n\">model_version</span> <span class=\"n\">STRING</span><span class=\"p\">,</span>\n    <span class=\"k\">FOREIGN</span> <span class=\"k\">KEY</span> <span class=\"p\">(</span><span class=\"n\">inference_id</span><span class=\"p\">)</span> <span class=\"k\">REFERENCES</span> <span class=\"n\">InferenceLog</span><span class=\"p\">(</span><span class=\"n\">id</span><span class=\"p\">)</span>\n<span class=\"p\">);</span>\n\n<span class=\"k\">CREATE</span> <span class=\"k\">TABLE</span> <span class=\"n\">UserFeedback</span> <span class=\"p\">(</span>\n    <span class=\"n\">inference_id</span> <span class=\"n\">STRING</span><span class=\"p\">,</span>\n    <span class=\"n\">feedback_score</span> <span class=\"n\">INT64</span><span class=\"p\">,</span> <span class=\"c1\">-- 1-5評価</span>\n    <span class=\"k\">comment</span> <span class=\"n\">STRING</span><span class=\"p\">,</span>\n    <span class=\"nb\">timestamp</span> <span class=\"nb\">TIMESTAMP</span><span class=\"p\">,</span>\n    <span class=\"k\">FOREIGN</span> <span class=\"k\">KEY</span> <span class=\"p\">(</span><span class=\"n\">inference_id</span><span class=\"p\">)</span> <span class=\"k\">REFERENCES</span> <span class=\"n\">InferenceLog</span><span class=\"p\">(</span><span class=\"n\">id</span><span class=\"p\">)</span>\n<span class=\"p\">);</span>\n</code></pre></div></div>\n<h3 data-sourcepos=\"193:1-193:65\">\n<span id=\"nextjs-proxytsでのプリフェッチ制御コード抜粋\" class=\"fragment\"></span><a href=\"#nextjs-proxyts%E3%81%A7%E3%81%AE%E3%83%97%E3%83%AA%E3%83%95%E3%82%A7%E3%83%83%E3%83%81%E5%88%B6%E5%BE%A1%E3%82%B3%E3%83%BC%E3%83%89%E6%8A%9C%E7%B2%8B\"><i class=\"fa fa-link\"></i></a>Next.js proxy.tsでのプリフェッチ制御コード抜粋</h3>\n<div class=\"code-frame\" data-lang=\"typescript\" data-sourcepos=\"195:1-225:3\"><div class=\"highlight\"><pre><code><span class=\"c1\">// proxy.ts: Next.js API routeでGemini API呼び出し簡略化かつプリフェッチ無効化設定</span>\n<span class=\"k\">import</span> <span class=\"kd\">type</span> <span class=\"p\">{</span> <span class=\"nx\">NextApiRequest</span><span class=\"p\">,</span> <span class=\"nx\">NextApiResponse</span> <span class=\"p\">}</span> <span class=\"k\">from</span> <span class=\"dl\">'</span><span class=\"s1\">next</span><span class=\"dl\">'</span><span class=\"p\">;</span>\n\n<span class=\"k\">export</span> <span class=\"kd\">const</span> <span class=\"nx\">config</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n  <span class=\"na\">api</span><span class=\"p\">:</span> <span class=\"p\">{</span>\n    <span class=\"na\">bodyParser</span><span class=\"p\">:</span> <span class=\"kc\">true</span><span class=\"p\">,</span>\n    <span class=\"na\">externalResolver</span><span class=\"p\">:</span> <span class=\"kc\">true</span><span class=\"p\">,</span>\n  <span class=\"p\">},</span>\n<span class=\"p\">};</span>\n\n<span class=\"k\">export</span> <span class=\"k\">default</span> <span class=\"k\">async</span> <span class=\"kd\">function</span> <span class=\"nf\">handler</span><span class=\"p\">(</span><span class=\"nx\">req</span><span class=\"p\">:</span> <span class=\"nx\">NextApiRequest</span><span class=\"p\">,</span> <span class=\"nx\">res</span><span class=\"p\">:</span> <span class=\"nx\">NextApiResponse</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n  <span class=\"c1\">// プリフェッチ制御：GETメソッド時の過剰呼出し防止</span>\n  <span class=\"k\">if </span><span class=\"p\">(</span><span class=\"nx\">req</span><span class=\"p\">.</span><span class=\"nx\">method</span> <span class=\"o\">===</span> <span class=\"dl\">'</span><span class=\"s1\">GET</span><span class=\"dl\">'</span> <span class=\"o\">&amp;&amp;</span> <span class=\"nx\">req</span><span class=\"p\">.</span><span class=\"nx\">headers</span><span class=\"p\">[</span><span class=\"dl\">'</span><span class=\"s1\">x-nextjs-data-prefetch</span><span class=\"dl\">'</span><span class=\"p\">]</span> <span class=\"o\">===</span> <span class=\"dl\">'</span><span class=\"s1\">1</span><span class=\"dl\">'</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"k\">return</span> <span class=\"nx\">res</span><span class=\"p\">.</span><span class=\"nf\">status</span><span class=\"p\">(</span><span class=\"mi\">204</span><span class=\"p\">).</span><span class=\"nf\">end</span><span class=\"p\">();</span>\n  <span class=\"p\">}</span>\n  \n  <span class=\"c1\">// Gemini API呼び出し処理をここに記述</span>\n  <span class=\"c1\">// 例: fetchでPOST送信し結果を返す</span>\n  <span class=\"kd\">const</span> <span class=\"nx\">response</span> <span class=\"o\">=</span> <span class=\"k\">await</span> <span class=\"nf\">fetch</span><span class=\"p\">(</span><span class=\"nx\">process</span><span class=\"p\">.</span><span class=\"nx\">env</span><span class=\"p\">.</span><span class=\"nx\">GEMINI_API_ENDPOINT</span><span class=\"o\">!</span><span class=\"p\">,</span> <span class=\"p\">{</span>\n    <span class=\"na\">method</span><span class=\"p\">:</span> <span class=\"dl\">'</span><span class=\"s1\">POST</span><span class=\"dl\">'</span><span class=\"p\">,</span>\n    <span class=\"na\">headers</span><span class=\"p\">:</span> <span class=\"p\">{</span>\n      <span class=\"dl\">'</span><span class=\"s1\">Content-Type</span><span class=\"dl\">'</span><span class=\"p\">:</span> <span class=\"dl\">'</span><span class=\"s1\">application/json</span><span class=\"dl\">'</span><span class=\"p\">,</span>\n      <span class=\"dl\">'</span><span class=\"s1\">Authorization</span><span class=\"dl\">'</span><span class=\"p\">:</span> <span class=\"s2\">`Bearer </span><span class=\"p\">${</span><span class=\"nx\">process</span><span class=\"p\">.</span><span class=\"nx\">env</span><span class=\"p\">.</span><span class=\"nx\">GEMINI_API_KEY</span><span class=\"p\">}</span><span class=\"s2\">`</span><span class=\"p\">,</span>\n    <span class=\"p\">},</span>\n    <span class=\"na\">body</span><span class=\"p\">:</span> <span class=\"nx\">JSON</span><span class=\"p\">.</span><span class=\"nf\">stringify</span><span class=\"p\">(</span><span class=\"nx\">req</span><span class=\"p\">.</span><span class=\"nx\">body</span><span class=\"p\">),</span>\n  <span class=\"p\">});</span>\n  <span class=\"kd\">const</span> <span class=\"nx\">data</span> <span class=\"o\">=</span> <span class=\"k\">await</span> <span class=\"nx\">response</span><span class=\"p\">.</span><span class=\"nf\">json</span><span class=\"p\">();</span>\n  <span class=\"nx\">res</span><span class=\"p\">.</span><span class=\"nf\">status</span><span class=\"p\">(</span><span class=\"nx\">response</span><span class=\"p\">.</span><span class=\"nx\">status</span><span class=\"p\">).</span><span class=\"nf\">json</span><span class=\"p\">(</span><span class=\"nx\">data</span><span class=\"p\">);</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n<hr data-sourcepos=\"227:1-228:0\">\n<h2 data-sourcepos=\"229:1-229:32\">\n<span id=\"-まとめtakeaways\" class=\"fragment\"></span><a href=\"#-%E3%81%BE%E3%81%A8%E3%82%81takeaways\"><i class=\"fa fa-link\"></i></a>📝 まとめ（Takeaways）</h2>\n<ul data-sourcepos=\"231:1-236:0\">\n<li data-sourcepos=\"231:1-231:156\">DifyとGemini LLMの連携で、バイオインフォマティクス領域の専門知識を活用したRAGチャットボットを手軽に構築可能</li>\n<li data-sourcepos=\"232:1-232:112\">文章チャンクの再帰分割・重複戦略と埋め込み検索により高度な文脈理解を実現</li>\n<li data-sourcepos=\"233:1-233:93\">BigQueryを用いた推論・評価ログ管理は継続的品質改善の基盤となる</li>\n<li data-sourcepos=\"234:1-234:91\">Next.jsのAPIルートを活用したWebUI最適化でユーザー体験向上が可能</li>\n<li data-sourcepos=\"235:1-236:0\">GEM Labの調査環境で得られた知見は将来的な未知生命の迅速解析・意思決定を後押しする</li>\n</ul>\n<hr data-sourcepos=\"237:1-238:0\">\n<h2 data-sourcepos=\"239:1-239:10\">\n<span id=\"-faq\" class=\"fragment\"></span><a href=\"#-faq\"><i class=\"fa fa-link\"></i></a>❓ FAQ</h2>\n<p data-sourcepos=\"241:1-241:59\"><strong>Q1: Gemini LLMを使う際に注意すべき点は？</strong></p>\n<ul data-sourcepos=\"242:1-244:0\">\n<li data-sourcepos=\"242:1-242:100\">セキュリティトークン管理を厳重にし、不正利用を防止してください。</li>\n<li data-sourcepos=\"243:1-244:0\">モデルの応答生成パラメータはケースに応じて調整し、無用な長文生成を避けることが重要です。</li>\n</ul>\n<p data-sourcepos=\"245:1-245:86\"><strong>Q2: Difyノーコードプラットフォームの無料プランで制限は？</strong></p>\n<ul data-sourcepos=\"246:1-247:0\">\n<li data-sourcepos=\"246:1-247:0\">一部機能制限や同時利用リクエスト数制限があります。大規模運用時は有料プラン検討を推奨します。</li>\n</ul>\n<p data-sourcepos=\"248:1-248:51\"><strong>Q3: BigQueryの料金を抑える工夫は？</strong></p>\n<ul data-sourcepos=\"249:1-250:0\">\n<li data-sourcepos=\"249:1-250:0\">ログは必要最小限に絞り、パーティショニングやクラスタリングを活用してクエリコスト低減を図ります。</li>\n</ul>\n<p data-sourcepos=\"251:1-251:61\"><strong>Q4: 他言語やフレームワークでの応用は？</strong></p>\n<ul data-sourcepos=\"252:1-253:0\">\n<li data-sourcepos=\"252:1-253:0\">REST APIベースなので、Python以外にNode.jsやGoなど任意言語からの連携が可能です。</li>\n</ul>\n<hr data-sourcepos=\"254:1-255:0\">\n<h2 data-sourcepos=\"256:1-256:35\">\n<span id=\"-参考文献リンク集\" class=\"fragment\"></span><a href=\"#-%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE%E3%83%AA%E3%83%B3%E3%82%AF%E9%9B%86\"><i class=\"fa fa-link\"></i></a>🔗 参考文献・リンク集</h2>\n<ul data-sourcepos=\"258:1-265:0\">\n<li data-sourcepos=\"258:1-258:48\"><a href=\"https://www.dify.ai/\" rel=\"nofollow noopener\" target=\"_blank\">Dify 公式サイト</a></li>\n<li data-sourcepos=\"259:1-259:114\"><a href=\"https://cloud.google.com/vertex-ai/docs/generative-ai/learn/gemini-models\" rel=\"nofollow noopener\" target=\"_blank\">Google Cloud Vertex AI Gemini LLM</a></li>\n<li data-sourcepos=\"260:1-260:79\"><a href=\"https://cloud.google.com/bigquery/docs\" rel=\"nofollow noopener\" target=\"_blank\">BigQuery 公式ドキュメント</a></li>\n<li data-sourcepos=\"261:1-261:73\"><a href=\"https://nextjs.org/docs/api-routes/introduction\" rel=\"nofollow noopener\" target=\"_blank\">Next.js API Routes</a></li>\n<li data-sourcepos=\"262:1-265:0\">過去の関連Qiita記事\n<ul data-sourcepos=\"263:3-265:0\">\n<li data-sourcepos=\"263:3-263:139\"><a href=\"https://qiita.com/cocokara_bioinfo/items/4bd415ef2f801497951e\" id=\"reference-63efa376bc2936534d07\">PythonでQiita記事投稿を自動化するパイプライン構築</a></li>\n<li data-sourcepos=\"264:3-265:0\"><a href=\"https://qiita.com/cocokara_bioinfo/items/7440c80d8e6a98177957\" id=\"reference-5883d22086266fd31595\">Python × GitHub Actions でのQiita自動投稿パイプライン</a></li>\n</ul>\n</li>\n</ul>\n<hr data-sourcepos=\"266:1-267:0\">\n<p data-sourcepos=\"268:1-268:265\">GEM Labの調査活動は今後もAIとクラウド技術を駆使した未知生命解析高度化を目指します。次回はGemini LLMのカスタムチューニングや多言語チャットボット展開に迫る予定です。乞うご期待ください。</p>\n",
      "body": "# DifyとGemini LLMを活用したバイオインフォマティクス向けRAGチャットボット構築とBigQuery連携実装ガイド\n\n> **対象読者**  \n> バイオインフォマティクス研究者・エンジニア、AIチャットボット開発者、クラウド技術者、Qiita記事自動投稿に関心のある中級以上のプログラマー\n\n> **動作確認環境 / 前提条件**  \n> - OS: Ubuntu 22.04 LTS / macOS Monterey  \n> - Python 3.9以上  \n> - Google Cloud SDK最新バージョン  \n> - BigQueryアクセス権限  \n> - Difyアカウント（無料プラン可）  \n> - Google Cloud Vertex AI Gemini LLM利用権限  \n> - 前提知識: Pythonプログラミング基礎、REST API利用経験、GCPの基本操作\n\n> **この記事で得られること**  \n> 1. Difyノーコードプラットフォームでバイオ知識ナレッジベースを構築する手順  \n> 2. PythonでのGemini LLM連携による埋め込み検索＋自然言語応答の実装例  \n> 3. BigQueryでのチャットボットログ蓄積と分析基盤設計、Next.jsによるWeb最適化例\n\n---\n\n## 🧭 導入：AIナレッジベースとRAGチャットボットの重要性\n\nGEM Labの若手調査員として新大陸の未知生命の探索調査を進める中、「大量の研究論文や解析報告をどう効率的に活用・共有するか」が課題となりました。バイオインフォマティクス領域ではデータも知識も膨大で散逸しやすく、調査活動の迅速な意思決定に支障をきたします。\n\nこうした課題を解決してくれるのが、最新のAI大規模言語モデル（LLM）を用いた**RAG（Retrieval-Augmented Generation）チャットボット**です。RAGは知識検索機能を組み合わせLLMの生成力で自然言語応答を行います。特にDifyのようなノーコードプラットフォームと、Google CloudのGemini LLMの組み合わせは導入の敷居が低く、かつ高度な対話が可能です。\n\n本記事では、GEM Labの調査員の視点でバイオインフォマティクス特化型チャットボットの構築から、大規模評価ログの管理、WebUI最適化までの技術的ワークフローを具体的に紹介します。これにより、読者の皆さんにも自分の研究や事業に適用可能な汎用技術として習得できる内容としています。\n\n---\n\n## 📘 トピックの概要：DifyとGemini LLMで実現するRAGチャットボット\n\n### Difyプラットフォームとは  \nDifyはノーコードで文章のチャンク分割・埋め込み検索を実現できるクラウドサービスです。大量文書を小さな情報単位に分割（チャンク化）し、意味的に近い情報を高速検索できます。GEM Labの未知生命データ解析報告もこの方式で管理可能です。\n\n### Gemini LLMの特徴  \nGoogle Cloud Vertex AIで提供されるGemini LLMは、膨大な科学論文や技術データを学習した強力な大規模言語モデルです。検索した文書チャンクを入力に文脈を理解し、自然な回答を生成します。\n\n### RAGの技術背景  \nRAGは大まかに2段階に分けられます：\n\n1. **Retrieval（検索）**：ユーザーの質問に関連する文書チャンクを埋め込みベクトル検索で特定  \n2. **Augmented Generation（拡張生成）**：Gemini LLMに検索結果を与え、質問への回答を生成\n\nこうしてLLMの大量知識保持に加え、最新のローカル知見を活用できるハイブリッド設計が成り立ちます。\n\n（文章で図解イメージ案：  \n「質問入力 → ベクトル埋め込み → Dify検索 → 関連文書チャンク抽出 → Gemini LLMへ提供 → 自然言語回答生成」）\n\n---\n\n## 🔧 技術的な仕組み：RAGとBigQuery評価ログ基盤の詳細\n\n### 1. 文章チャンクの再帰分割と重複チャンク戦略  \n長大な論文や報告を単純に分割すると、切れ目で意味があいまいになることがあります。再帰的な分割アルゴリズムで小単位に分割しつつ、前後のチャンクを重複させることで文脈を保持。  \nこの手法はDifyプラットフォーム上でGUI操作もしくはAPI経由で設定可能です。\n\n### 2. 埋め込みベクトル検索  \nチャンク文書はBERT系埋め込みモデルでベクトル化され、検索時はcos類似度等で関連度スコアを算出。高速な類似度検索はANNアルゴリズム（HNSWなど）でスケールします。\n\n### 3. BigQuery上の推論・評価ログ管理  \nGEM Labの膨大な推論データを扱うためBigQueryに下記テーブルを設計しました：\n\n- **InferenceLog**：質問文、検索チャンクID、Gemini応答文、タイムスタンプ\n- **ResponseMetadata**：Geminiの生成パラメータ（温度、最大トークン数等）\n- **UserFeedback**：調査員からの評価スコアやコメント\n\nこれらを結合分析し、対話性能の継続的改善と異常検知、性能モニタリングに活用しています。\n\n---\n\n## 🧪 実践編：Difyでのナレッジベース構築とPythonによる関連検索＋応答生成\n\n### 1. Dify GUIでのテキストアップロード・チャンク識別設定手順\n\n```bash\n# Difyへログイン後の基本操作概要\n# 1. ナレッジベース作成 → [新規作成]クリック\n# 2. バイオ関連文書をPDF・テキストでアップロード\n# 3. チャンクサイズ（例：500トークン）とオーバーラップ率（例：20%）を設定\n# 4. 自動チャンク生成ボタン押下 → 分割処理実行開始\n# 5. 埋め込みベクトル生成&インデックス作成の進捗を待つ\n# 6. 検索設定で類似度閾値や結果取得件数を調整\n```\n\n> GUIのため細部ステップは画面キャプチャ付きの公式ドキュメント参照がおすすめです。\n\n### 2. Python擬似コードでの埋め込み検索とGemini API呼び出し例\n\n```python\nimport requests\nimport json\n\n# DifyのAPIキーとGemini LLMエンドポイント\nDIFY_API_URL = \"https://api.dify.ai/v1/search\"\nDIFY_API_KEY = \"your_dify_api_key\"\n\nGEMINI_API_URL = \"https://vertexai.googleapis.com/v1/projects/{project_id}/locations/{location}/models/{model}:predict\"\nGEMINI_API_KEY = \"your_gemini_api_key\"\n\ndef search_chunks(question: str):\n    headers = {\n        \"Authorization\": f\"Bearer {DIFY_API_KEY}\",\n        \"Content-Type\": \"application/json\",\n    }\n    payload = {\n        \"query\": question,\n        \"top_k\": 5\n    }\n    response = requests.post(DIFY_API_URL, headers=headers, json=payload)\n    response.raise_for_status()\n    return response.json()  # 検索チャンクの詳細リスト\n\ndef generate_answer(context_chunks: list, question: str):\n    prompt = f\"以下の情報を参考に質問に回答してください：\\n{''.join([c['text'] for c in context_chunks])}\\n質問：{question}\\n回答：\"\n    headers = {\n        \"Authorization\": f\"Bearer {GEMINI_API_KEY}\",\n        \"Content-Type\": \"application/json\",\n    }\n    data = {\n        \"instances\": [{\"content\": prompt}],\n        \"parameters\": {\n            \"temperature\": 0.3,\n            \"maxOutputTokens\": 512\n        }\n    }\n    response = requests.post(GEMINI_API_URL, headers=headers, json=data)\n    response.raise_for_status()\n    pred = response.json()\n    return pred['predictions'][0]['content']\n\nif __name__ == \"__main__\":\n    user_question = \"RNA-seqデータの正規化方法は何ですか？\"\n    search_result = search_chunks(user_question)\n    context = search_result.get(\"results\", [])\n    answer = generate_answer(context, user_question)\n    print(\"=== 質問 ===\")\n    print(user_question)\n    print(\"=== 回答 ===\")\n    print(answer)\n```\n\n- **ディレクトリ構成例**  \n```\nproject-root/\n├── main.py             # 上記コード\n├── requirements.txt    # requestsやGCPクライアント記載\n└── README.md\n```\n\n- **依存関係**  \n```\nrequests==2.28.1\n```\n\n---\n\n## 🚀 応用・発展・実用例：バイオデータ解析とNext.jsによるUI最適化\n\n### バイオインフォメティクスへの適用例  \n- ゲノム・RNA-seq解析論文のRAG検索で、解析方法やパラメータの即時回答を実現。調査員は未知生命ゲノムの特徴把握に活用可能。  \n- BigQueryの推論・評価ログから、質問傾向やGemini応答品質を分析し継続的チューニング。  \n\n### BigQueryスキーマ設計例（推論・レスポンス・評価テーブル）\n\n```sql\nCREATE TABLE InferenceLog (\n    id STRING PRIMARY KEY,\n    user_query STRING,\n    retrieved_chunks ARRAY<STRING>,\n    gemini_response STRING,\n    timestamp TIMESTAMP\n);\n\nCREATE TABLE ResponseMetadata (\n    inference_id STRING,\n    temperature FLOAT64,\n    max_tokens INT64,\n    model_version STRING,\n    FOREIGN KEY (inference_id) REFERENCES InferenceLog(id)\n);\n\nCREATE TABLE UserFeedback (\n    inference_id STRING,\n    feedback_score INT64, -- 1-5評価\n    comment STRING,\n    timestamp TIMESTAMP,\n    FOREIGN KEY (inference_id) REFERENCES InferenceLog(id)\n);\n```\n\n### Next.js proxy.tsでのプリフェッチ制御コード抜粋\n\n```typescript\n// proxy.ts: Next.js API routeでGemini API呼び出し簡略化かつプリフェッチ無効化設定\nimport type { NextApiRequest, NextApiResponse } from 'next';\n\nexport const config = {\n  api: {\n    bodyParser: true,\n    externalResolver: true,\n  },\n};\n\nexport default async function handler(req: NextApiRequest, res: NextApiResponse) {\n  // プリフェッチ制御：GETメソッド時の過剰呼出し防止\n  if (req.method === 'GET' && req.headers['x-nextjs-data-prefetch'] === '1') {\n    return res.status(204).end();\n  }\n  \n  // Gemini API呼び出し処理をここに記述\n  // 例: fetchでPOST送信し結果を返す\n  const response = await fetch(process.env.GEMINI_API_ENDPOINT!, {\n    method: 'POST',\n    headers: {\n      'Content-Type': 'application/json',\n      'Authorization': `Bearer ${process.env.GEMINI_API_KEY}`,\n    },\n    body: JSON.stringify(req.body),\n  });\n  const data = await response.json();\n  res.status(response.status).json(data);\n}\n```\n\n---\n\n## 📝 まとめ（Takeaways）\n\n- DifyとGemini LLMの連携で、バイオインフォマティクス領域の専門知識を活用したRAGチャットボットを手軽に構築可能  \n- 文章チャンクの再帰分割・重複戦略と埋め込み検索により高度な文脈理解を実現  \n- BigQueryを用いた推論・評価ログ管理は継続的品質改善の基盤となる  \n- Next.jsのAPIルートを活用したWebUI最適化でユーザー体験向上が可能  \n- GEM Labの調査環境で得られた知見は将来的な未知生命の迅速解析・意思決定を後押しする\n\n---\n\n## ❓ FAQ\n\n**Q1: Gemini LLMを使う際に注意すべき点は？**  \n- セキュリティトークン管理を厳重にし、不正利用を防止してください。  \n- モデルの応答生成パラメータはケースに応じて調整し、無用な長文生成を避けることが重要です。  \n\n**Q2: Difyノーコードプラットフォームの無料プランで制限は？**  \n- 一部機能制限や同時利用リクエスト数制限があります。大規模運用時は有料プラン検討を推奨します。  \n\n**Q3: BigQueryの料金を抑える工夫は？**  \n- ログは必要最小限に絞り、パーティショニングやクラスタリングを活用してクエリコスト低減を図ります。  \n\n**Q4: 他言語やフレームワークでの応用は？**  \n- REST APIベースなので、Python以外にNode.jsやGoなど任意言語からの連携が可能です。\n\n---\n\n## 🔗 参考文献・リンク集\n\n- [Dify 公式サイト](https://www.dify.ai/)  \n- [Google Cloud Vertex AI Gemini LLM](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/gemini-models)  \n- [BigQuery 公式ドキュメント](https://cloud.google.com/bigquery/docs)  \n- [Next.js API Routes](https://nextjs.org/docs/api-routes/introduction)  \n- 過去の関連Qiita記事  \n  - [PythonでQiita記事投稿を自動化するパイプライン構築](https://qiita.com/cocokara_bioinfo/items/4bd415ef2f801497951e)  \n  - [Python × GitHub Actions でのQiita自動投稿パイプライン](https://qiita.com/cocokara_bioinfo/items/7440c80d8e6a98177957)  \n\n---\n\nGEM Labの調査活動は今後もAIとクラウド技術を駆使した未知生命解析高度化を目指します。次回はGemini LLMのカスタムチューニングや多言語チャットボット展開に迫る予定です。乞うご期待ください。\n",
      "coediting": false,
      "comments_count": 0,
      "created_at": "2025-12-07T20:08:00+09:00",
      "group": null,
      "id": "0db33ffad46d14781952",
      "likes_count": 0,
      "private": false,
      "reactions_count": 0,
      "stocks_count": 0,
      "tags": [
        {
          "name": "Python",
          "versions": []
        },
        {
          "name": "自動化",
          "versions": []
        }
      ],
      "title": "DifyとGemini LLMを活用したバイオインフォマティクス向けRAGチャットボット構築とBigQuery連携実装ガイド",
      "updated_at": "2025-12-07T20:08:00+09:00",
      "url": "https://qiita.com/cocokara_bioinfo/items/0db33ffad46d14781952",
      "user": {
        "description": "ポッケ村出身の名もなき若手生物学研究員です。\r\n現代の技術やエンジニア知識を学びながらモンスターハンターの生態・生物学研究に日々励んでおります！\r\nまだまだ勉強不足なところはありますが、皆さんに少しでも学びになるものをお届けできればとの思いで発信させていただきます\r\n\r\n※フィクションとして、時にTips記事として楽しんでいただければ幸いです",
        "facebook_id": "",
        "followees_count": 3,
        "followers_count": 0,
        "github_login_name": null,
        "id": "cocokara_bioinfo",
        "items_count": 4,
        "linkedin_id": "",
        "location": "",
        "name": "シャル・S 調査員",
        "organization": "Genome & Ecology Monster-Lab (架空)",
        "permanent_id": 4288059,
        "profile_image_url": "https://lh3.googleusercontent.com/a/ACg8ocLkgrrRuDzozKQ4XeInetzc0um1rPWRGXY2daT9pLIi1z1JdQ=s96-c",
        "team_only": false,
        "twitter_screen_name": null,
        "website_url": ""
      },
      "page_views_count": 192,
      "team_membership": null,
      "organization_url_name": null,
      "slide": false,
      "_source": "my_popular"
    },
    {
      "rendered_body": "<hr data-sourcepos=\"1:1-2:0\">\n<blockquote data-sourcepos=\"3:1-7:93\">\n<p data-sourcepos=\"3:3-3:20\"><strong>対象読者</strong></p>\n<ul data-sourcepos=\"4:3-7:93\">\n<li data-sourcepos=\"4:3-4:97\">日々のコーディングやデータ解析を効率化したいエンジニア・研究者</li>\n<li data-sourcepos=\"5:3-5:65\">GitHub Copilotの次に試すAIツールを探している方</li>\n<li data-sourcepos=\"6:3-6:105\">バイオインフォマティクスに興味があり、AIをどう活用できるか知りたい方</li>\n<li data-sourcepos=\"7:3-7:93\">機密性の高いデータを扱うため、クラウドAIの利用に懸念がある方</li>\n</ul>\n</blockquote>\n<blockquote data-sourcepos=\"9:1-15:82\">\n<p data-sourcepos=\"9:3-9:41\"><strong>動作確認環境 / 前提条件</strong></p>\n<ul data-sourcepos=\"10:3-15:82\">\n<li data-sourcepos=\"10:3-10:46\">OS: macOS Sonoma (Apple M1) / Ubuntu 22.04</li>\n<li data-sourcepos=\"11:3-11:18\">Cursor: 0.33.1</li>\n<li data-sourcepos=\"12:3-12:18\">Ollama: 0.1.43</li>\n<li data-sourcepos=\"13:3-13:17\">Python: 3.10+</li>\n<li data-sourcepos=\"14:3-14:46\">Dockerが利用可能な環境（推奨）</li>\n<li data-sourcepos=\"15:3-15:82\">기본적인コマンドライン操作、Pythonプログラミングの知識</li>\n</ul>\n</blockquote>\n<blockquote data-sourcepos=\"17:1-20:162\">\n<p data-sourcepos=\"17:3-17:55\"><strong>この記事で得られること（3点程度）</strong></p>\n<ol data-sourcepos=\"18:3-20:162\">\n<li data-sourcepos=\"18:3-18:118\">AIネイティブエディタ「Cursor」の基本的な使い方と、開発効率を上げるための活用法</li>\n<li data-sourcepos=\"19:3-19:128\">ローカル環境で大規模言語モデル（LLM）を動かすツール「Ollama」のセットアップと利用方法</li>\n<li data-sourcepos=\"20:3-20:162\">クラウドAIとローカルLLMを使い分ける、セキュリティと利便性を両立した「ハイブリッドAI解析環境」の構築ノウハウ</li>\n</ol>\n</blockquote>\n<hr data-sourcepos=\"22:1-23:0\">\n<h2 data-sourcepos=\"24:1-24:50\">\n<span id=\"-導入背景課題なぜ重要か\" class=\"fragment\"></span><a href=\"#-%E5%B0%8E%E5%85%A5%E8%83%8C%E6%99%AF%E8%AA%B2%E9%A1%8C%E3%81%AA%E3%81%9C%E9%87%8D%E8%A6%81%E3%81%8B\"><i class=\"fa fa-link\"></i></a>🧭 導入：背景・課題・なぜ重要か</h2>\n<p data-sourcepos=\"26:1-26:628\">GEM Lab（遺伝生態モンスター研究所）の調査員として、我々は日々、未知のモンスター生命体から得られる膨大なゲノムデータと格闘しています。シーケンサーから出力されるテラバイト級のデータを処理し、生命の謎に迫る…聞こえは良いですが、その実態は地道な作業の連続です。解析パイプラインの構築、バグだらけのスクリプトのデバッグ、そして山のような結果の可視化。正直、解析の本質的な部分にたどり着く前に、力尽きてしまうこともしばしばです。</p>\n<p data-sourcepos=\"28:1-28:151\">以前の記事では、GitHub Actionsを使って調査報告（Qiita記事）の投稿を自動化し、「報告」の効率化を図りました。</p>\n<ul data-sourcepos=\"30:1-32:0\">\n<li data-sourcepos=\"30:1-30:183\"><a href=\"https://qiita.com/cocokara_bioinfo/items/4bd415ef2f801497951e\" id=\"reference-a3a720fd02c72cd0d1e0\">【ハマりどころ満載】PythonでQiita記事投稿を自動化するパイプライン構築で爆速改善！</a></li>\n<li data-sourcepos=\"31:1-32:0\"><a href=\"https://qiita.com/cocokara_bioinfo/items/7440c80d8e6a98177957\" id=\"reference-c6a1dcda5efdfdb270e0\">Python × GitHub Actions で始める！Qiita 自動投稿パイプライン構築術</a></li>\n</ul>\n<p data-sourcepos=\"33:1-33:165\">しかし、今回はさらに踏み込み、<strong>「解析」そのものをAIの力で加速させる</strong>ための開発・解析環境についてご紹介します。</p>\n<p data-sourcepos=\"35:1-35:302\">GitHub Copilotは既に多くの開発者にとって手放せないツールとなりましたが、時々「もっと文脈を理解してくれたら…」「このプロジェクト全体のことを分かってくれた上で提案してほしい…」と感じることはないでしょうか？</p>\n<p data-sourcepos=\"37:1-37:549\">この記事では、単なるコード補完ツールを超え、開発者の「思考のパートナー」となるAI駆動の開発環境を構築する方法を解説します。具体的には、AIネイティブエディタ<strong>Cursor</strong>と、ローカル環境でLLMを動かす<strong>Ollama</strong>を組み合わせ、利便性とセキュリティを両立させたハイブリッド環境を目指します。この環境があれば、複雑なモンスターの遺伝子解析も、もっと速く、もっと創造的に進められるはずです。</p>\n<hr data-sourcepos=\"39:1-40:0\">\n<h2 data-sourcepos=\"41:1-41:65\">\n<span id=\"-トピックの概要専門外にも分かる説明\" class=\"fragment\"></span><a href=\"#-%E3%83%88%E3%83%94%E3%83%83%E3%82%AF%E3%81%AE%E6%A6%82%E8%A6%81%E5%B0%82%E9%96%80%E5%A4%96%E3%81%AB%E3%82%82%E5%88%86%E3%81%8B%E3%82%8B%E8%AA%AC%E6%98%8E\"><i class=\"fa fa-link\"></i></a>📘 トピックの概要（専門外にも分かる説明）</h2>\n<h3 data-sourcepos=\"43:1-43:33\">\n<span id=\"ai駆動開発環境とは\" class=\"fragment\"></span><a href=\"#ai%E9%A7%86%E5%8B%95%E9%96%8B%E7%99%BA%E7%92%B0%E5%A2%83%E3%81%A8%E3%81%AF\"><i class=\"fa fa-link\"></i></a>AI駆動開発環境とは？</h3>\n<p data-sourcepos=\"45:1-45:267\">「AI駆動開発環境」とは、AI（特に大規模言語モデル, LLM）が開発ワークフローのあらゆる側面に深く統合された環境のことです。これは、単にコードを補完する（Code Completion）だけではありません。</p>\n<ul data-sourcepos=\"47:1-51:0\">\n<li data-sourcepos=\"47:1-47:136\">\n<strong>対話型コーディング</strong>: チャット形式でAIに指示し、コードを生成・修正・リファクタリングする。</li>\n<li data-sourcepos=\"48:1-48:196\">\n<strong>コンテキスト理解</strong>: 開いているファイルだけでなく、プロジェクト全体のコードベースやドキュメントをAIが理解し、より的確な提案を行う。</li>\n<li data-sourcepos=\"49:1-49:139\">\n<strong>デバッグ支援</strong>: エラーメッセージをAIに貼り付けるだけで、原因の特定や修正案を提示してくれる。</li>\n<li data-sourcepos=\"50:1-51:0\">\n<strong>ドキュメント生成</strong>: 既存のコードから仕様書やコメントを自動で生成する。</li>\n</ul>\n<h3 data-sourcepos=\"52:1-52:67\">\n<span id=\"なぜバイオインフォマティクスで重要なのか\" class=\"fragment\"></span><a href=\"#%E3%81%AA%E3%81%9C%E3%83%90%E3%82%A4%E3%82%AA%E3%82%A4%E3%83%B3%E3%83%95%E3%82%A9%E3%83%9E%E3%83%86%E3%82%A3%E3%82%AF%E3%82%B9%E3%81%A7%E9%87%8D%E8%A6%81%E3%81%AA%E3%81%AE%E3%81%8B\"><i class=\"fa fa-link\"></i></a>なぜバイオインフォマティクスで重要なのか？</h3>\n<p data-sourcepos=\"54:1-54:226\">バイオインフォマティクスの世界は、専門的なツールやライブラリ（例: Biopython, Samtools, GATK）、そして複雑なデータフォーマット（FASTA, FASTQ, BAM, VCF）に溢れています。</p>\n<ul data-sourcepos=\"56:1-59:0\">\n<li data-sourcepos=\"56:1-56:241\">\n<strong>学習コストの削減</strong>: 「このライブラリでVCFファイルをパースするにはどう書けば？」といった初歩的な問いにAIが即座に答えてくれるため、学習コストを大幅に削減できます。</li>\n<li data-sourcepos=\"57:1-57:214\">\n<strong>定型作業の自動化</strong>: 塩基配列のクリーニングやフォーマット変換など、頻繁に発生する定型的な前処理スクリプトをAIに一瞬で生成させることができます。</li>\n<li data-sourcepos=\"58:1-59:0\">\n<strong>解析の再現性向上</strong>: AIに依頼して、解析手順をドキュメント化したり、Jupyter Notebookに適切なマークダウン説明を追加したりすることで、解析の再現性を高められます。</li>\n</ul>\n<h3 data-sourcepos=\"60:1-60:60\">\n<span id=\"今回構築するハイブリッドai解析環境\" class=\"fragment\"></span><a href=\"#%E4%BB%8A%E5%9B%9E%E6%A7%8B%E7%AF%89%E3%81%99%E3%82%8B%E3%83%8F%E3%82%A4%E3%83%96%E3%83%AA%E3%83%83%E3%83%89ai%E8%A7%A3%E6%9E%90%E7%92%B0%E5%A2%83\"><i class=\"fa fa-link\"></i></a>今回構築する「ハイブリッドAI解析環境」</h3>\n<p data-sourcepos=\"62:1-62:181\">この記事で提案するのは、クラウドベースの強力なAIと、手元のマシンで動くセキュアなAIを組み合わせた「ハイブリッド環境」です。</p>\n<p data-sourcepos=\"64:1-64:32\">[文章で図解イメージ案]</p>\n<div class=\"code-frame\" data-lang=\"text\" data-sourcepos=\"65:1-88:3\"><div class=\"highlight\"><pre><code>+-------------------------------------------------------------+\n|                     開発者 (GEM Lab 調査員)                   |\n+-------------------------------------------------------------+\n      |                                      |\n      | エディタ上で対話・コーディング         |\n      |                                      |\n+-------------------------------------------------------------+\n|                 Cursor (AIネイティブエディタ)                 |\n+-------------------------------------------------------------+\n      |                                      |\n      | (1) 一般的な質問/コード生成          | (2) 機密情報を含むコードの相談\n      | (インターネット経由)                 | (ローカルネットワーク内)\n      |                                      |\n+--------------------------+         +-------------------------+\n|   クラウドAI (GPT-4など)   |         |  ローカルLLM (Ollama)   |\n| (OpenAI API)             |         | (Llama3, CodeLlamaなど) |\n+--------------------------+         +-------------------------+\n                                           ^\n                                           |\n                               +-----------------------------+\n                               | モンスター遺伝子データ (機密) |\n                               +-----------------------------+\n</code></pre></div></div>\n<p data-sourcepos=\"90:1-90:108\">このアーキテクチャのポイントは、<strong>扱う情報に応じてAIを使い分ける</strong>点です。</p>\n<ol data-sourcepos=\"91:1-93:0\">\n<li data-sourcepos=\"91:1-91:302\">\n<strong>クラウドAI (Cursor経由)</strong>: 一般的なアルゴリズムの相談や、公開されているライブラリの使い方など、機密情報を含まないタスクに使用します。最新かつ非常に高性能なモデル（GPT-4など）の能力を最大限に活用できます。</li>\n<li data-sourcepos=\"92:1-93:0\">\n<strong>ローカルLLM (Ollama)</strong>: モンスターの遺伝子配列など、絶対に外部に送信できない機密データを含むコードのデバッグや解析ロジックの相談に使用します。これにより、セキュリティを確保しつつAIの支援を受けられます。</li>\n</ol>\n<hr data-sourcepos=\"94:1-95:0\">\n<h2 data-sourcepos=\"96:1-96:62\">\n<span id=\"-技術的な仕組み実装アーキテクチャ\" class=\"fragment\"></span><a href=\"#-%E6%8A%80%E8%A1%93%E7%9A%84%E3%81%AA%E4%BB%95%E7%B5%84%E3%81%BF%E5%AE%9F%E8%A3%85%E3%82%A2%E3%83%BC%E3%82%AD%E3%83%86%E3%82%AF%E3%83%81%E3%83%A3\"><i class=\"fa fa-link\"></i></a>🔧 技術的な仕組み・実装・アーキテクチャ</h2>\n<h3 data-sourcepos=\"98:1-98:48\">\n<span id=\"1-aiネイティブエディタcursor\" class=\"fragment\"></span><a href=\"#1-ai%E3%83%8D%E3%82%A4%E3%83%86%E3%82%A3%E3%83%96%E3%82%A8%E3%83%87%E3%82%A3%E3%82%BFcursor\"><i class=\"fa fa-link\"></i></a>1. AIネイティブエディタ「Cursor」</h3>\n<p data-sourcepos=\"100:1-101:297\"><strong>Cursorとは？</strong><br>\n<a href=\"https://cursor.sh/\" rel=\"nofollow noopener\" target=\"_blank\">Cursor</a>は、VSCodeをフォークして開発された、AI機能を第一に考えて設計されたコードエディタです。VSCodeの拡張機能エコシステムをそのまま利用できるため、既存のVSCodeユーザーはスムーズに移行できます。</p>\n<p data-sourcepos=\"103:1-103:56\"><strong>なぜVSCode + CopilotではなくCursorなのか？</strong></p>\n<ul data-sourcepos=\"104:1-107:0\">\n<li data-sourcepos=\"104:1-104:369\">\n<strong>深いコンテキスト理解</strong>: <code>@</code>シンボルを使って、特定のファイル（<code>@file.py</code>）やドキュメント（<code>@docs</code>）をAIのコンテキストに含めることができます。これにより、「このファイルの実装を参考にして、新しい関数を作って」といった、より精度の高い指示が可能になります。</li>\n<li data-sourcepos=\"105:1-105:308\">\n<strong>インラインでの編集・チャット</strong>: コードを選択して<code>Cmd+K</code>（Windows/Linuxでは<code>Ctrl+K</code>）を押すだけで、その場でAIと対話し、コードを直接編集させることができます。エディタとチャットウィンドウを行き来する必要がありません。</li>\n<li data-sourcepos=\"106:1-107:0\">\n<strong>AIによるリファクタリング</strong>: 「この関数の変数名を分かりやすくして」「このクラスにテストコードを書いて」といったリファクタリング作業をAIに一任できます。</li>\n</ul>\n<p data-sourcepos=\"108:1-108:34\"><strong>メリット／デメリット</strong></p>\n<ul data-sourcepos=\"109:1-111:0\">\n<li data-sourcepos=\"109:1-109:151\">\n<strong>メリット</strong>: 開発速度が劇的に向上する。複雑なコードベースの理解が容易になる。AIとの対話がシームレス。</li>\n<li data-sourcepos=\"110:1-111:0\">\n<strong>デメリット</strong>: デフォルトではCursorのサーバーを経由してOpenAIのAPIを利用するため、プライバシーポリシーの確認が必要。一部機能は有料。</li>\n</ul>\n<p data-sourcepos=\"112:1-113:506\"><strong>初心者がつまずくポイント</strong><br>\nプロンプトの書き方に少しコツが必要です。ただ「〇〇して」と書くのではなく、「あなたは経験豊富なバイオインフォマティシャンです。Biopythonを使って、FASTAファイルからGC含量を計算する関数を書いてください。エラーハンドリングも考慮してください。」のように、<strong>役割（ペルソナ）、文脈、詳細な要件</strong>を伝えることで、生成されるコードの質が格段に向上します。</p>\n<h3 data-sourcepos=\"115:1-115:46\">\n<span id=\"2-ローカルllm実行環境ollama\" class=\"fragment\"></span><a href=\"#2-%E3%83%AD%E3%83%BC%E3%82%AB%E3%83%ABllm%E5%AE%9F%E8%A1%8C%E7%92%B0%E5%A2%83ollama\"><i class=\"fa fa-link\"></i></a>2. ローカルLLM実行環境「Ollama」</h3>\n<p data-sourcepos=\"117:1-118:296\"><strong>Ollamaとは？</strong><br>\n<a href=\"https://ollama.com/\" rel=\"nofollow noopener\" target=\"_blank\">Ollama</a>は、Llama 3, Code Llama, MistralといったオープンソースのLLMを、自分のPC上で驚くほど簡単に実行できるようにするツールです。複雑な環境構築は不要で、数個のコマンドを打つだけで準備が完了します。</p>\n<p data-sourcepos=\"120:1-121:404\"><strong>なぜローカルLLMが必要なのか？</strong><br>\n最大の理由は<strong>セキュリティ</strong>です。GEM Labが扱うモンスターの遺伝子情報は最高機密事項。これを外部のAPIに送信することは絶対に許されません。Ollamaを使えば、全ての処理がローカルマシン内で完結するため、情報漏洩のリスクをゼロにできます。オフライン環境でも動作するのも大きな利点です。</p>\n<p data-sourcepos=\"123:1-123:34\"><strong>メリット／デメリット</strong></p>\n<ul data-sourcepos=\"124:1-126:0\">\n<li data-sourcepos=\"124:1-124:131\">\n<strong>メリット</strong>: 高いセキュリティとプライバシー。オフライン利用可能。API利用料がかからない。</li>\n<li data-sourcepos=\"125:1-126:0\">\n<strong>デメリット</strong>: 高性能なモデルを動かすには、相応のマシンスペック（特にメモリとGPU）が必要。クラウドの最新モデル（GPT-4oなど）と比較すると性能が劣る場合がある。</li>\n</ul>\n<p data-sourcepos=\"127:1-127:40\"><strong>初心者がつまずくポイント</strong></p>\n<ul data-sourcepos=\"128:1-130:0\">\n<li data-sourcepos=\"128:1-128:288\">\n<strong>メモリ不足</strong>: 大規模なモデルを実行しようとすると、メモリ不足で動作が遅くなったり、エラーが発生したりします。まずは<code>llama3:8b</code>（80億パラメータ）のような比較的小さなモデルから試すのがおすすめです。</li>\n<li data-sourcepos=\"129:1-130:0\">\n<strong>モデルの選択</strong>: 用途に応じてモデルを選ぶ必要があります。コーディング支援なら<code>codellama</code>、汎用的な対話なら<code>llama3</code>、日本語性能を重視するなら<code>gemma:7b</code>など、様々な選択肢があります。Ollamaの<a href=\"https://ollama.com/library\" rel=\"nofollow noopener\" target=\"_blank\">ライブラリページ</a>で探してみましょう。</li>\n</ul>\n<hr data-sourcepos=\"131:1-132:0\">\n<h2 data-sourcepos=\"133:1-133:53\">\n<span id=\"-実践編動くコードコマンド例\" class=\"fragment\"></span><a href=\"#-%E5%AE%9F%E8%B7%B5%E7%B7%A8%E5%8B%95%E3%81%8F%E3%82%B3%E3%83%BC%E3%83%89%E3%82%B3%E3%83%9E%E3%83%B3%E3%83%89%E4%BE%8B\"><i class=\"fa fa-link\"></i></a>🧪 実践編：動くコード／コマンド例</h2>\n<h3 data-sourcepos=\"135:1-135:19\">\n<span id=\"1-環境構築\" class=\"fragment\"></span><a href=\"#1-%E7%92%B0%E5%A2%83%E6%A7%8B%E7%AF%89\"><i class=\"fa fa-link\"></i></a>1. 環境構築</h3>\n<h4 data-sourcepos=\"137:1-137:35\">\n<span id=\"a-cursorのインストール\" class=\"fragment\"></span><a href=\"#a-cursor%E3%81%AE%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB\"><i class=\"fa fa-link\"></i></a>a. Cursorのインストール</h4>\n<ol data-sourcepos=\"138:1-141:0\">\n<li data-sourcepos=\"138:1-138:133\">\n<a href=\"https://cursor.sh/\" rel=\"nofollow noopener\" target=\"_blank\">公式サイト</a>にアクセスし、お使いのOS用のインストーラをダウンロードします。</li>\n<li data-sourcepos=\"139:1-139:112\">ダウンロードしたファイルを実行し、アプリケーションをインストールします。</li>\n<li data-sourcepos=\"140:1-141:0\">起動するとVSCodeと非常によく似た画面が表示されます。既存のVSCode設定や拡張機能もインポートできます。</li>\n</ol>\n<h4 data-sourcepos=\"142:1-142:56\">\n<span id=\"b-ollamaのインストールとセットアップ\" class=\"fragment\"></span><a href=\"#b-ollama%E3%81%AE%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB%E3%81%A8%E3%82%BB%E3%83%83%E3%83%88%E3%82%A2%E3%83%83%E3%83%97\"><i class=\"fa fa-link\"></i></a>b. Ollamaのインストールとセットアップ</h4>\n<p data-sourcepos=\"144:1-144:28\"><strong>macOS / Linux の場合:</strong></p>\n<div class=\"code-frame\" data-lang=\"bash\" data-sourcepos=\"145:1-148:3\"><div class=\"highlight\"><pre><code><span class=\"c\"># 公式サイトのインストールスクリプトを実行</span>\ncurl <span class=\"nt\">-fsSL</span> https://ollama.com/install.sh | sh\n</code></pre></div></div>\n<p data-sourcepos=\"150:1-151:115\"><strong>Windows の場合:</strong><br>\n<a href=\"https://ollama.com/download\" rel=\"nofollow noopener\" target=\"_blank\">公式サイト</a>からインストーラをダウンロードして実行します。</p>\n<p data-sourcepos=\"153:1-154:158\"><strong>Llama 3 (8B) モデルのダウンロード:</strong><br>\nインストール後、ターミナルで以下のコマンドを実行します。モデルのダウンロードが始まります（数GBあります）。</p>\n<div class=\"code-frame\" data-lang=\"bash\" data-sourcepos=\"156:1-164:3\"><div class=\"highlight\"><pre><code><span class=\"c\"># Llama 3 (8B) instructモデルをプル</span>\nollama pull llama3:8b\n\n<span class=\"c\"># 成功ログの例</span>\n<span class=\"c\"># pulling manifest</span>\n<span class=\"c\"># pulling 2ab3b58f9049... 100% ▕██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████- 4.7g/s 4.7 GB</span>\n<span class=\"c\"># success</span>\n</code></pre></div></div>\n<h3 data-sourcepos=\"166:1-166:45\">\n<span id=\"2-cursorによるクラウドai活用例\" class=\"fragment\"></span><a href=\"#2-cursor%E3%81%AB%E3%82%88%E3%82%8B%E3%82%AF%E3%83%A9%E3%82%A6%E3%83%89ai%E6%B4%BB%E7%94%A8%E4%BE%8B\"><i class=\"fa fa-link\"></i></a>2. CursorによるクラウドAI活用例</h3>\n<p data-sourcepos=\"168:1-168:111\">ここでは、一般的なバイオインフォマティクスのタスクをCursorに依頼してみます。</p>\n<p data-sourcepos=\"170:1-170:188\"><strong>シナリオ:</strong> <code>monster_sequences.fasta</code> というFASTA形式のファイルから、特定のID (<code>MONSTER_007</code>) を持つ配列を抽出するPythonスクリプトを作成します。</p>\n<ol data-sourcepos=\"172:1-185:0\">\n<li data-sourcepos=\"172:1-172:62\">\n<code>main.py</code> という空のファイルを作成します。</li>\n<li data-sourcepos=\"173:1-183:7\">\n<code>Cmd+L</code> (Windows/Linux: <code>Ctrl+L</code>) でチャットウィンドウを開き、以下のプロンプトを入力します。\n<div class=\"code-frame\" data-lang=\"text\" data-sourcepos=\"174:5-183:7\"><div class=\"highlight\"><pre><code>あなたは熟練のPythonプログラマです。\nBiopythonライブラリを使って、FASTAファイルから特定のIDを持つシーケンスを抽出するコマンドラインツールを作成してください。\n\n要件：\n- 入力ファイルパスとシーケンスIDを引数として受け取ること。\n- 該当するIDが見つかった場合は、そのシーケンスを標準出力に出力すること。\n- 見つからなかった場合は、エラーメッセージを出力すること。\n- argparseを使って、使いやすいインターフェースにすること。\n</code></pre></div></div>\n</li>\n<li data-sourcepos=\"184:1-185:0\">AIがコードを生成します。以下はその一例です。</li>\n</ol>\n<div class=\"code-frame\" data-lang=\"python\" data-sourcepos=\"186:1-229:3\"><div class=\"highlight\"><pre><code><span class=\"c1\"># main.py (AIが生成したコード)\n</span><span class=\"kn\">import</span> <span class=\"n\">argparse</span>\n<span class=\"kn\">from</span> <span class=\"n\">Bio</span> <span class=\"kn\">import</span> <span class=\"n\">SeqIO</span>\n<span class=\"kn\">import</span> <span class=\"n\">sys</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">extract_sequence_by_id</span><span class=\"p\">(</span><span class=\"n\">fasta_file</span><span class=\"p\">,</span> <span class=\"n\">sequence_id</span><span class=\"p\">):</span>\n    <span class=\"sh\">\"\"\"</span><span class=\"s\">\n    Extracts a sequence from a FASTA file by its ID.\n\n    Args:\n        fasta_file (str): Path to the input FASTA file.\n        sequence_id (str): The ID of the sequence to extract.\n\n    Returns:\n        Bio.SeqRecord.SeqRecord or None: The found sequence record, or None if not found.\n    </span><span class=\"sh\">\"\"\"</span>\n    <span class=\"k\">try</span><span class=\"p\">:</span>\n        <span class=\"k\">for</span> <span class=\"n\">record</span> <span class=\"ow\">in</span> <span class=\"n\">SeqIO</span><span class=\"p\">.</span><span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"n\">fasta_file</span><span class=\"p\">,</span> <span class=\"sh\">\"</span><span class=\"s\">fasta</span><span class=\"sh\">\"</span><span class=\"p\">):</span>\n            <span class=\"k\">if</span> <span class=\"n\">record</span><span class=\"p\">.</span><span class=\"nb\">id</span> <span class=\"o\">==</span> <span class=\"n\">sequence_id</span><span class=\"p\">:</span>\n                <span class=\"k\">return</span> <span class=\"n\">record</span>\n        <span class=\"k\">return</span> <span class=\"bp\">None</span>\n    <span class=\"k\">except</span> <span class=\"nb\">FileNotFoundError</span><span class=\"p\">:</span>\n        <span class=\"nf\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"sh\">\"</span><span class=\"s\">Error: The file </span><span class=\"sh\">'</span><span class=\"si\">{</span><span class=\"n\">fasta_file</span><span class=\"si\">}</span><span class=\"sh\">'</span><span class=\"s\"> was not found.</span><span class=\"sh\">\"</span><span class=\"p\">,</span> <span class=\"nb\">file</span><span class=\"o\">=</span><span class=\"n\">sys</span><span class=\"p\">.</span><span class=\"n\">stderr</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"bp\">None</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">main</span><span class=\"p\">():</span>\n    <span class=\"n\">parser</span> <span class=\"o\">=</span> <span class=\"n\">argparse</span><span class=\"p\">.</span><span class=\"nc\">ArgumentParser</span><span class=\"p\">(</span><span class=\"n\">description</span><span class=\"o\">=</span><span class=\"sh\">\"</span><span class=\"s\">Extract a specific sequence from a FASTA file.</span><span class=\"sh\">\"</span><span class=\"p\">)</span>\n    <span class=\"n\">parser</span><span class=\"p\">.</span><span class=\"nf\">add_argument</span><span class=\"p\">(</span><span class=\"sh\">\"</span><span class=\"s\">fasta_file</span><span class=\"sh\">\"</span><span class=\"p\">,</span> <span class=\"nb\">help</span><span class=\"o\">=</span><span class=\"sh\">\"</span><span class=\"s\">Path to the input FASTA file.</span><span class=\"sh\">\"</span><span class=\"p\">)</span>\n    <span class=\"n\">parser</span><span class=\"p\">.</span><span class=\"nf\">add_argument</span><span class=\"p\">(</span><span class=\"sh\">\"</span><span class=\"s\">sequence_id</span><span class=\"sh\">\"</span><span class=\"p\">,</span> <span class=\"nb\">help</span><span class=\"o\">=</span><span class=\"sh\">\"</span><span class=\"s\">The ID of the sequence to extract.</span><span class=\"sh\">\"</span><span class=\"p\">)</span>\n    <span class=\"n\">args</span> <span class=\"o\">=</span> <span class=\"n\">parser</span><span class=\"p\">.</span><span class=\"nf\">parse_args</span><span class=\"p\">()</span>\n\n    <span class=\"n\">found_record</span> <span class=\"o\">=</span> <span class=\"nf\">extract_sequence_by_id</span><span class=\"p\">(</span><span class=\"n\">args</span><span class=\"p\">.</span><span class=\"n\">fasta_file</span><span class=\"p\">,</span> <span class=\"n\">args</span><span class=\"p\">.</span><span class=\"n\">sequence_id</span><span class=\"p\">)</span>\n\n    <span class=\"k\">if</span> <span class=\"n\">found_record</span><span class=\"p\">:</span>\n        <span class=\"nf\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"sh\">\"</span><span class=\"s\">&gt;</span><span class=\"si\">{</span><span class=\"n\">found_record</span><span class=\"p\">.</span><span class=\"n\">description</span><span class=\"si\">}</span><span class=\"sh\">\"</span><span class=\"p\">)</span>\n        <span class=\"nf\">print</span><span class=\"p\">(</span><span class=\"n\">found_record</span><span class=\"p\">.</span><span class=\"n\">seq</span><span class=\"p\">)</span>\n    <span class=\"k\">else</span><span class=\"p\">:</span>\n        <span class=\"nf\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"sh\">\"</span><span class=\"s\">Sequence with ID </span><span class=\"sh\">'</span><span class=\"si\">{</span><span class=\"n\">args</span><span class=\"p\">.</span><span class=\"n\">sequence_id</span><span class=\"si\">}</span><span class=\"sh\">'</span><span class=\"s\"> not found in </span><span class=\"sh\">'</span><span class=\"si\">{</span><span class=\"n\">args</span><span class=\"p\">.</span><span class=\"n\">fasta_file</span><span class=\"si\">}</span><span class=\"sh\">'</span><span class=\"s\">.</span><span class=\"sh\">\"</span><span class=\"p\">,</span> <span class=\"nb\">file</span><span class=\"o\">=</span><span class=\"n\">sys</span><span class=\"p\">.</span><span class=\"n\">stderr</span><span class=\"p\">)</span>\n        <span class=\"n\">sys</span><span class=\"p\">.</span><span class=\"nf\">exit</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n\n<span class=\"k\">if</span> <span class=\"n\">__name__</span> <span class=\"o\">==</span> <span class=\"sh\">\"</span><span class=\"s\">__main__</span><span class=\"sh\">\"</span><span class=\"p\">:</span>\n    <span class=\"nf\">main</span><span class=\"p\">()</span>\n</code></pre></div></div>\n<ol data-sourcepos=\"231:1-233:0\">\n<li data-sourcepos=\"231:1-233:0\">次に、このコードをリファクタリングしてみましょう。<code>extract_sequence_by_id</code>関数を選択して<code>Cmd+K</code> (Ctrl+K) を押し、こう指示します。<br>\n<code>この関数に型ヒントを追加し、docstringをGoogleスタイルに変更してください。</code>\n</li>\n</ol>\n<p data-sourcepos=\"234:1-234:86\">すると、AIが即座にコードを以下のように書き換えてくれます。</p>\n<div class=\"code-frame\" data-lang=\"python\" data-sourcepos=\"236:1-266:3\"><div class=\"highlight\"><pre><code><span class=\"c1\"># main.py (リファクタリング後のコード)\n</span><span class=\"kn\">import</span> <span class=\"n\">argparse</span>\n<span class=\"kn\">from</span> <span class=\"n\">Bio</span> <span class=\"kn\">import</span> <span class=\"n\">SeqIO</span>\n<span class=\"kn\">from</span> <span class=\"n\">Bio.SeqRecord</span> <span class=\"kn\">import</span> <span class=\"n\">SeqRecord</span>\n<span class=\"kn\">import</span> <span class=\"n\">sys</span>\n<span class=\"kn\">from</span> <span class=\"n\">typing</span> <span class=\"kn\">import</span> <span class=\"n\">Optional</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">extract_sequence_by_id</span><span class=\"p\">(</span><span class=\"n\">fasta_file</span><span class=\"p\">:</span> <span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">sequence_id</span><span class=\"p\">:</span> <span class=\"nb\">str</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">SeqRecord</span><span class=\"p\">]:</span>\n    <span class=\"sh\">\"\"\"</span><span class=\"s\">Extracts a sequence from a FASTA file by its ID.\n\n    Args:\n        fasta_file (str): Path to the input FASTA file.\n        sequence_id (str): The ID of the sequence to extract.\n\n    Returns:\n        Optional[SeqRecord]: The found sequence record, or None if not found or\n                             if the file does not exist.\n    </span><span class=\"sh\">\"\"\"</span>\n    <span class=\"k\">try</span><span class=\"p\">:</span>\n        <span class=\"k\">for</span> <span class=\"n\">record</span> <span class=\"ow\">in</span> <span class=\"n\">SeqIO</span><span class=\"p\">.</span><span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"n\">fasta_file</span><span class=\"p\">,</span> <span class=\"sh\">\"</span><span class=\"s\">fasta</span><span class=\"sh\">\"</span><span class=\"p\">):</span>\n            <span class=\"k\">if</span> <span class=\"n\">record</span><span class=\"p\">.</span><span class=\"nb\">id</span> <span class=\"o\">==</span> <span class=\"n\">sequence_id</span><span class=\"p\">:</span>\n                <span class=\"k\">return</span> <span class=\"n\">record</span>\n        <span class=\"k\">return</span> <span class=\"bp\">None</span>\n    <span class=\"k\">except</span> <span class=\"nb\">FileNotFoundError</span><span class=\"p\">:</span>\n        <span class=\"nf\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"sh\">\"</span><span class=\"s\">Error: The file </span><span class=\"sh\">'</span><span class=\"si\">{</span><span class=\"n\">fasta_file</span><span class=\"si\">}</span><span class=\"sh\">'</span><span class=\"s\"> was not found.</span><span class=\"sh\">\"</span><span class=\"p\">,</span> <span class=\"nb\">file</span><span class=\"o\">=</span><span class=\"n\">sys</span><span class=\"p\">.</span><span class=\"n\">stderr</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"bp\">None</span>\n\n<span class=\"c1\"># (main関数は変更なし)\n</span><span class=\"bp\">...</span>\n</code></pre></div></div>\n<p data-sourcepos=\"268:1-268:111\">このように、対話的にコーディングとリファクタリングを進めることができます。</p>\n<h3 data-sourcepos=\"270:1-270:46\">\n<span id=\"3-ollamaによるローカルllm活用例\" class=\"fragment\"></span><a href=\"#3-ollama%E3%81%AB%E3%82%88%E3%82%8B%E3%83%AD%E3%83%BC%E3%82%AB%E3%83%ABllm%E6%B4%BB%E7%94%A8%E4%BE%8B\"><i class=\"fa fa-link\"></i></a>3. OllamaによるローカルLLM活用例</h3>\n<p data-sourcepos=\"272:1-272:192\"><strong>シナリオ:</strong> モンスターの機密ゲノムデータ（という想定のダミーデータ）を含むスクリプトのデバッグを、情報を外部に送らずに行います。</p>\n<ol data-sourcepos=\"274:1-329:0\">\n<li data-sourcepos=\"274:1-282:0\">\n<p data-sourcepos=\"274:5-274:76\">まず、ターミナルでOllamaの対話モードを開始します。</p>\n<div class=\"code-frame\" data-lang=\"bash\" data-sourcepos=\"275:5-277:7\"><div class=\"highlight\"><pre><code>ollama run llama3:8b\n</code></pre></div></div>\n<div class=\"code-frame\" data-lang=\"text\" data-sourcepos=\"278:5-280:7\"><div class=\"highlight\"><pre><code>&gt;&gt;&gt;\n</code></pre></div></div>\n<p data-sourcepos=\"281:5-281:76\">とプロンプトが表示され、入力待機状態になります。</p>\n</li>\n<li data-sourcepos=\"283:1-329:0\">\n<p data-sourcepos=\"283:5-283:215\">ここに、デバッグしたいコードに関する質問を貼り付けます。<strong>機密データそのものではなく、コードのロジックに関する質問をすることがポイントです。</strong></p>\n<p data-sourcepos=\"285:5-285:27\"><strong>プロンプト例:</strong></p>\n<div class=\"code-frame\" data-lang=\"text\" data-sourcepos=\"286:5-291:7\"><div class=\"highlight\"><pre><code>Pythonのコードについて質問です。\n`data`という文字列があり、ここには'A', 'T', 'G', 'C'以外の文字（例えば'N'）が含まれている可能性があります。\nこの文字列から'N'の数を数えるコードを書いていますが、`data.count('N')`よりも効率的な方法はありますか？\nデータは非常に長くなる可能性があります（数ギガバイト）。\n</code></pre></div></div>\n<p data-sourcepos=\"293:5-293:44\"><strong>Ollama (Llama 3) からの回答例:</strong></p>\n<div class=\"code-frame\" data-lang=\"text\" data-sourcepos=\"294:5-314:7\"><div class=\"highlight\"><pre><code>こんにちは！興味深い質問ですね。巨大な文字列で特定の文字を数える場合、パフォーマンスは重要になります。\n\n`data.count('N')`はシンプルで読みやすいですが、PythonのC言語実装レベルで最適化されており、非常に高速です。ほとんどの場合、これで十分です。\n\nしかし、メモリ効率をさらに考慮する場合や、文字列を一度にメモリにロードできない場合は、ジェネレータ式やイテレータを使うアプローチが考えられます。\n\n例えば、ファイルを一行ずつ読み込んで処理する場合：\n\n```python\ndef count_char_in_file(filepath, char_to_count):\n    count = 0\n    with open(filepath, 'r') as f:\n        for line in f:\n            count += line.count(char_to_count)\n    return count\n\n# 使い方\n# n_count = count_char_in_file('huge_genome_file.txt', 'N')\n# print(f\"The character 'N' appears {n_count} times.\")\n</code></pre></div></div>\n<p data-sourcepos=\"316:5-316:160\">この方法は、ファイル全体を一度にメモリに読み込まないため、巨大なファイルに対してもメモリ効率が良いです。</p>\n<p data-sourcepos=\"318:5-318:160\">もし文字列がすでにメモリ上にあるが、他の処理と並行してカウントしたい場合は、単純なループも考えられます。</p>\n<div class=\"code-frame\" data-lang=\"python\" data-sourcepos=\"320:5-323:7\"><div class=\"highlight\"><pre><code><span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"sh\">\"</span><span class=\"s\">ATGCGNATGC...</span><span class=\"sh\">\"</span> <span class=\"c1\"># 巨大な文字列と仮定\n</span><span class=\"n\">n_count</span> <span class=\"o\">=</span> <span class=\"nf\">sum</span><span class=\"p\">(</span><span class=\"mi\">1</span> <span class=\"k\">for</span> <span class=\"n\">char</span> <span class=\"ow\">in</span> <span class=\"n\">data</span> <span class=\"k\">if</span> <span class=\"n\">char</span> <span class=\"o\">==</span> <span class=\"sh\">'</span><span class=\"s\">N</span><span class=\"sh\">'</span><span class=\"p\">)</span>\n</code></pre></div></div>\n<p data-sourcepos=\"325:5-325:244\">このジェネレータ式を使った方法は、<code>count()</code>メソッドとパフォーマンス的には大差ないことが多いですが、より複雑な条件（例：'N'または'n'を数える）を追加するのが容易です。</p>\n<p data-sourcepos=\"327:5-327:246\">結論として、シンプルさで言えば<code>data.count('N')</code>が最善です。メモリが懸念される巨大なファイルの場合は、ファイルをチャンクまたは行ごとに読み込むアプローチをお勧めします。</p>\n<div class=\"code-frame\" data-lang=\"text\" data-sourcepos=\"328:5-330:141\"><div class=\"highlight\"><pre><code>\n</code></pre></div></div>\n</li>\n</ol>\n<p data-sourcepos=\"330:1-330:141\">このように、ローカル環境で完結させながら、具体的なコードの改善案や代替案を得ることができます。</p>\n<h3 data-sourcepos=\"332:1-332:84\">\n<span id=\"4-ハイブリッド戦略の実践-cursorからローカルllmを呼び出す\" class=\"fragment\"></span><a href=\"#4-%E3%83%8F%E3%82%A4%E3%83%96%E3%83%AA%E3%83%83%E3%83%89%E6%88%A6%E7%95%A5%E3%81%AE%E5%AE%9F%E8%B7%B5-cursor%E3%81%8B%E3%82%89%E3%83%AD%E3%83%BC%E3%82%AB%E3%83%ABllm%E3%82%92%E5%91%BC%E3%81%B3%E5%87%BA%E3%81%99\"><i class=\"fa fa-link\"></i></a>4. ハイブリッド戦略の実践: CursorからローカルLLMを呼び出す</h3>\n<p data-sourcepos=\"334:1-334:98\">Cursorの真価は、使用するAIモデルを柔軟に切り替えられる点にあります。</p>\n<ol data-sourcepos=\"336:1-341:0\">\n<li data-sourcepos=\"336:1-336:67\">Cursorで <code>Cmd+,</code> (Ctrl+,) を押して設定を開きます。</li>\n<li data-sourcepos=\"337:1-337:84\">\"Models\" を検索し、\"Model Provider\" のセクションを見つけます。</li>\n<li data-sourcepos=\"338:1-338:76\">\"Add a new model...\" をクリックし、\"Ollama\" を選択します。</li>\n<li data-sourcepos=\"339:1-339:86\">設定で、使用したいモデル名（例: <code>llama3:8b</code>）を入力します。</li>\n<li data-sourcepos=\"340:1-341:0\">これで、チャットウィンドウやインライン編集時に、モデル選択ドロップダウンから<code>Ollama/llama3:8b</code>を選べるようになります。</li>\n</ol>\n<p data-sourcepos=\"342:1-342:246\">これにより、「この一般的な関数はGPT-4で生成し、この機密データに触れる部分のデバッグはローカルのLlama 3で」といった使い分けが、同じエディタ内でシームレスに実現できます。</p>\n<hr data-sourcepos=\"344:1-345:0\">\n<h2 data-sourcepos=\"346:1-346:35\">\n<span id=\"-応用発展実用例\" class=\"fragment\"></span><a href=\"#-%E5%BF%9C%E7%94%A8%E7%99%BA%E5%B1%95%E5%AE%9F%E7%94%A8%E4%BE%8B\"><i class=\"fa fa-link\"></i></a>🚀 応用・発展・実用例</h2>\n<p data-sourcepos=\"348:1-348:83\">このハイブリッドAI解析環境は、様々な場面で応用できます。</p>\n<ul data-sourcepos=\"350:1-358:0\">\n<li data-sourcepos=\"350:1-350:394\">\n<strong>新規パイプラインの設計</strong>: NextflowやSnakemakeのようなワークフロー言語のボイラープレートをAIに生成させ、迅速にパイプラインの骨格を作ることができます。「Snakemakeを使って、FASTQファイルをTrimmomaticでトリミングし、BWAでマッピングするルールの雛形を書いて」といった指示が有効です。</li>\n<li data-sourcepos=\"351:1-351:254\">\n<strong>データ可視化の高速化</strong>: MatplotlibやSeabornを使った複雑なグラフ（例: 火山プロット、クラスタリングのヒートマップ）の描画コードをAIに生成させ、自分はデータの解釈に集中できます。</li>\n<li data-sourcepos=\"352:1-354:264\">\n<strong>他技術との統合</strong>:\n<ul data-sourcepos=\"353:5-354:264\">\n<li data-sourcepos=\"353:5-353:239\">\n<strong>Docker</strong>: <code>Dockerfile</code>の作成や最適化をAIに相談できます。「Python 3.10ベースで、BiopythonとPandasをインストールするDockerfileを書いて」と依頼すれば、すぐに雛形が手に入ります。</li>\n<li data-sourcepos=\"354:5-354:264\">\n<strong>Jupyter</strong>: データ探索フェーズでは、Jupyter Lab内で<a href=\"https://github.com/jupyter-ai/jupyter-ai\" rel=\"nofollow noopener\" target=\"_blank\">Jupyter AI</a>拡張機能を使うことで、ノートブック上で直接LLMと対話し、コードセルを生成させることが可能です。</li>\n</ul>\n</li>\n<li data-sourcepos=\"355:1-358:0\">\n<strong>モンスター生命体の解析への応用</strong>:\n<ul data-sourcepos=\"356:5-358:0\">\n<li data-sourcepos=\"356:5-356:209\">未知の遺伝子配列が与えられた際、「この配列に似た機能を持つ既知の遺伝子をBLASTで検索するためのBiopythonスクリプトを書いて」とCursorに依頼する。</li>\n<li data-sourcepos=\"357:5-358:0\">発見された新種モンスターのゲノムアセンブリ結果（機密）について、「このアセンブリ結果に含まれるコンティグのN50を計算するPythonスクリプトを、メモリ効率を考慮して書いて」とOllamaに相談する。</li>\n</ul>\n</li>\n</ul>\n<hr data-sourcepos=\"359:1-360:0\">\n<h2 data-sourcepos=\"361:1-361:32\">\n<span id=\"-まとめtakeaways\" class=\"fragment\"></span><a href=\"#-%E3%81%BE%E3%81%A8%E3%82%81takeaways\"><i class=\"fa fa-link\"></i></a>📝 まとめ（Takeaways）</h2>\n<p data-sourcepos=\"363:1-363:110\">この記事で紹介した「ハイブリッドAI解析環境」の重要なポイントをまとめます。</p>\n<ul data-sourcepos=\"365:1-370:0\">\n<li data-sourcepos=\"365:1-365:198\">\n<strong>AIは「相棒」</strong>: AI駆動開発は、単なるコード補完ではなく、設計・実装・デバッグ・ドキュメント化の全工程を支援する強力なパートナーです。</li>\n<li data-sourcepos=\"366:1-366:202\">\n<strong>Cursorで開発を加速</strong>: AIネイティブエディタCursorは、深いコンテキスト理解とシームレスな対話機能により、開発体験を次のレベルに引き上げます。</li>\n<li data-sourcepos=\"367:1-367:211\">\n<strong>Ollamaでセキュリティを確保</strong>: 機密データを扱う際は、Ollamaを使ってローカル環境でLLMを実行することで、情報漏洩のリスクなくAIの恩恵を受けられます。</li>\n<li data-sourcepos=\"368:1-368:259\">\n<strong>ハイブリッドが最適解</strong>: クラウドAIの性能とローカルLLMのセキュリティを使い分ける「ハイブリッド戦略」が、現代の多くの開発・解析業務において現実的かつ強力なソリューションです。</li>\n<li data-sourcepos=\"369:1-370:0\">\n<strong>まずは試すことから</strong>: CursorとOllamaのインストールは非常に簡単です。まずは手元のPCに導入し、日々のちょっとした作業からAIに任せてみることをお勧めします。</li>\n</ul>\n<hr data-sourcepos=\"371:1-372:0\">\n<h2 data-sourcepos=\"373:1-373:55\">\n<span id=\"-faq読者が抱きそうな疑問と回答\" class=\"fragment\"></span><a href=\"#-faq%E8%AA%AD%E8%80%85%E3%81%8C%E6%8A%B1%E3%81%8D%E3%81%9D%E3%81%86%E3%81%AA%E7%96%91%E5%95%8F%E3%81%A8%E5%9B%9E%E7%AD%94\"><i class=\"fa fa-link\"></i></a>❓ FAQ（読者が抱きそうな疑問と回答）</h2>\n<p data-sourcepos=\"375:1-376:410\"><strong>Q1: マシンスペックが低いPCでもローカルLLMは使えますか？</strong><br>\nA1: はい、使えますがモデルの選択が重要になります。Ollamaは比較的軽量ですが、快適な動作には16GB以上のRAMを推奨します。もし動作が重い場合は、<code>llama3:8b</code>よりもさらに小さいモデル、例えば<code>tinydolphin</code>や<code>qwen:4b</code>などを試してみてください。これらは性能は少し落ちますが、要求スペックは低くなります。</p>\n<p data-sourcepos=\"378:1-379:484\"><strong>Q2: Cursorは無料ですか？ 有料プランとの違いは何ですか？</strong><br>\nA2: Cursorには無料枠があります。無料枠では、GPT-4などの高性能モデルを月に一定回数利用できます。回数制限を超えて利用したい場合や、より高度な機能（プロジェクト全体をAIに読み込ませる\"Auto-repo\"など）を使いたい場合は、有料プランへのアップグレードが必要です。ただし、Ollamaと連携してローカルLLMを使う分には、回数制限なく無料で利用できます。</p>\n<p data-sourcepos=\"381:1-382:394\"><strong>Q3: AIが生成したコードの信頼性はどのように担保すればよいですか？</strong><br>\nA3: 非常に重要な質問です。AIが生成したコードは<strong>絶対に鵜呑みにしてはいけません</strong>。それはあくまで「非常に優秀なアシスタントが書いた下書き」と捉えるべきです。特に、バイオインフォマティクスのような科学的な正確性が求められる分野では、以下の点を確認することが不可欠です。</p>\n<ol data-sourcepos=\"383:1-386:0\">\n<li data-sourcepos=\"383:1-383:154\">\n<strong>ロジックの検証</strong>: 生成されたコードのアルゴリズムが、意図した解析手法と一致しているか必ず確認します。</li>\n<li data-sourcepos=\"384:1-384:142\">\n<strong>テスト</strong>: 小さなダミーデータセットでコードを動かし、期待通りの結果が得られるかテストします。</li>\n<li data-sourcepos=\"385:1-386:0\">\n<strong>ライブラリのドキュメント参照</strong>: 使用されている関数やオプションが適切か、公式ドキュメントで裏を取る習慣をつけましょう。</li>\n</ol>\n<hr data-sourcepos=\"387:1-388:0\">\n<h2 data-sourcepos=\"389:1-389:35\">\n<span id=\"-参考文献リンク集\" class=\"fragment\"></span><a href=\"#-%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE%E3%83%AA%E3%83%B3%E3%82%AF%E9%9B%86\"><i class=\"fa fa-link\"></i></a>🔗 参考文献・リンク集</h2>\n<ul data-sourcepos=\"391:1-395:111\">\n<li data-sourcepos=\"391:1-391:70\">\n<strong>Cursor 公式サイト</strong>: <a href=\"https://cursor.sh/\" rel=\"nofollow noopener\" target=\"_blank\">https://cursor.sh/</a>\n</li>\n<li data-sourcepos=\"392:1-392:72\">\n<strong>Ollama 公式サイト</strong>: <a href=\"https://ollama.com/\" rel=\"nofollow noopener\" target=\"_blank\">https://ollama.com/</a>\n</li>\n<li data-sourcepos=\"393:1-393:84\">\n<strong>Ollama Model Library</strong>: <a href=\"https://ollama.com/library\" rel=\"nofollow noopener\" target=\"_blank\">https://ollama.com/library</a>\n</li>\n<li data-sourcepos=\"394:1-394:73\">\n<strong>Biopython Project</strong>: <a href=\"https://biopython.org/\" rel=\"nofollow noopener\" target=\"_blank\">https://biopython.org/</a>\n</li>\n<li data-sourcepos=\"395:1-395:111\">\n<strong>Jupyter AI (GitHub)</strong>: <a href=\"https://github.com/jupyter-ai/jupyter-ai\" rel=\"nofollow noopener\" target=\"_blank\">https://github.com/jupyter-ai/jupyter-ai</a>\n</li>\n</ul>\n",
      "body": "---\n\n> **対象読者**  \n> - 日々のコーディングやデータ解析を効率化したいエンジニア・研究者\n> - GitHub Copilotの次に試すAIツールを探している方\n> - バイオインフォマティクスに興味があり、AIをどう活用できるか知りたい方\n> - 機密性の高いデータを扱うため、クラウドAIの利用に懸念がある方\n\n> **動作確認環境 / 前提条件**  \n> - OS: macOS Sonoma (Apple M1) / Ubuntu 22.04\n> - Cursor: 0.33.1\n> - Ollama: 0.1.43\n> - Python: 3.10+\n> - Dockerが利用可能な環境（推奨）\n> - 기본적인コマンドライン操作、Pythonプログラミングの知識\n\n> **この記事で得られること（3点程度）**\n> 1. AIネイティブエディタ「Cursor」の基本的な使い方と、開発効率を上げるための活用法\n> 2. ローカル環境で大規模言語モデル（LLM）を動かすツール「Ollama」のセットアップと利用方法\n> 3. クラウドAIとローカルLLMを使い分ける、セキュリティと利便性を両立した「ハイブリッドAI解析環境」の構築ノウハウ\n\n---\n\n## 🧭 導入：背景・課題・なぜ重要か\n\nGEM Lab（遺伝生態モンスター研究所）の調査員として、我々は日々、未知のモンスター生命体から得られる膨大なゲノムデータと格闘しています。シーケンサーから出力されるテラバイト級のデータを処理し、生命の謎に迫る…聞こえは良いですが、その実態は地道な作業の連続です。解析パイプラインの構築、バグだらけのスクリプトのデバッグ、そして山のような結果の可視化。正直、解析の本質的な部分にたどり着く前に、力尽きてしまうこともしばしばです。\n\n以前の記事では、GitHub Actionsを使って調査報告（Qiita記事）の投稿を自動化し、「報告」の効率化を図りました。\n\n- [【ハマりどころ満載】PythonでQiita記事投稿を自動化するパイプライン構築で爆速改善！](https://qiita.com/cocokara_bioinfo/items/4bd415ef2f801497951e)\n- [Python × GitHub Actions で始める！Qiita 自動投稿パイプライン構築術](https://qiita.com/cocokara_bioinfo/items/7440c80d8e6a98177957)\n\nしかし、今回はさらに踏み込み、**「解析」そのものをAIの力で加速させる**ための開発・解析環境についてご紹介します。\n\nGitHub Copilotは既に多くの開発者にとって手放せないツールとなりましたが、時々「もっと文脈を理解してくれたら…」「このプロジェクト全体のことを分かってくれた上で提案してほしい…」と感じることはないでしょうか？\n\nこの記事では、単なるコード補完ツールを超え、開発者の「思考のパートナー」となるAI駆動の開発環境を構築する方法を解説します。具体的には、AIネイティブエディタ**Cursor**と、ローカル環境でLLMを動かす**Ollama**を組み合わせ、利便性とセキュリティを両立させたハイブリッド環境を目指します。この環境があれば、複雑なモンスターの遺伝子解析も、もっと速く、もっと創造的に進められるはずです。\n\n---\n\n## 📘 トピックの概要（専門外にも分かる説明）\n\n### AI駆動開発環境とは？\n\n「AI駆動開発環境」とは、AI（特に大規模言語モデル, LLM）が開発ワークフローのあらゆる側面に深く統合された環境のことです。これは、単にコードを補完する（Code Completion）だけではありません。\n\n- **対話型コーディング**: チャット形式でAIに指示し、コードを生成・修正・リファクタリングする。\n- **コンテキスト理解**: 開いているファイルだけでなく、プロジェクト全体のコードベースやドキュメントをAIが理解し、より的確な提案を行う。\n- **デバッグ支援**: エラーメッセージをAIに貼り付けるだけで、原因の特定や修正案を提示してくれる。\n- **ドキュメント生成**: 既存のコードから仕様書やコメントを自動で生成する。\n\n### なぜバイオインフォマティクスで重要なのか？\n\nバイオインフォマティクスの世界は、専門的なツールやライブラリ（例: Biopython, Samtools, GATK）、そして複雑なデータフォーマット（FASTA, FASTQ, BAM, VCF）に溢れています。\n\n- **学習コストの削減**: 「このライブラリでVCFファイルをパースするにはどう書けば？」といった初歩的な問いにAIが即座に答えてくれるため、学習コストを大幅に削減できます。\n- **定型作業の自動化**: 塩基配列のクリーニングやフォーマット変換など、頻繁に発生する定型的な前処理スクリプトをAIに一瞬で生成させることができます。\n- **解析の再現性向上**: AIに依頼して、解析手順をドキュメント化したり、Jupyter Notebookに適切なマークダウン説明を追加したりすることで、解析の再現性を高められます。\n\n### 今回構築する「ハイブリッドAI解析環境」\n\nこの記事で提案するのは、クラウドベースの強力なAIと、手元のマシンで動くセキュアなAIを組み合わせた「ハイブリッド環境」です。\n\n[文章で図解イメージ案]\n```\n+-------------------------------------------------------------+\n|                     開発者 (GEM Lab 調査員)                   |\n+-------------------------------------------------------------+\n      |                                      |\n      | エディタ上で対話・コーディング         |\n      |                                      |\n+-------------------------------------------------------------+\n|                 Cursor (AIネイティブエディタ)                 |\n+-------------------------------------------------------------+\n      |                                      |\n      | (1) 一般的な質問/コード生成          | (2) 機密情報を含むコードの相談\n      | (インターネット経由)                 | (ローカルネットワーク内)\n      |                                      |\n+--------------------------+         +-------------------------+\n|   クラウドAI (GPT-4など)   |         |  ローカルLLM (Ollama)   |\n| (OpenAI API)             |         | (Llama3, CodeLlamaなど) |\n+--------------------------+         +-------------------------+\n                                           ^\n                                           |\n                               +-----------------------------+\n                               | モンスター遺伝子データ (機密) |\n                               +-----------------------------+\n```\n\nこのアーキテクチャのポイントは、**扱う情報に応じてAIを使い分ける**点です。\n1.  **クラウドAI (Cursor経由)**: 一般的なアルゴリズムの相談や、公開されているライブラリの使い方など、機密情報を含まないタスクに使用します。最新かつ非常に高性能なモデル（GPT-4など）の能力を最大限に活用できます。\n2.  **ローカルLLM (Ollama)**: モンスターの遺伝子配列など、絶対に外部に送信できない機密データを含むコードのデバッグや解析ロジックの相談に使用します。これにより、セキュリティを確保しつつAIの支援を受けられます。\n\n---\n\n## 🔧 技術的な仕組み・実装・アーキテクチャ\n\n### 1. AIネイティブエディタ「Cursor」\n\n**Cursorとは？**\n[Cursor](https://cursor.sh/)は、VSCodeをフォークして開発された、AI機能を第一に考えて設計されたコードエディタです。VSCodeの拡張機能エコシステムをそのまま利用できるため、既存のVSCodeユーザーはスムーズに移行できます。\n\n**なぜVSCode + CopilotではなくCursorなのか？**\n- **深いコンテキスト理解**: `@`シンボルを使って、特定のファイル（`@file.py`）やドキュメント（`@docs`）をAIのコンテキストに含めることができます。これにより、「このファイルの実装を参考にして、新しい関数を作って」といった、より精度の高い指示が可能になります。\n- **インラインでの編集・チャット**: コードを選択して`Cmd+K`（Windows/Linuxでは`Ctrl+K`）を押すだけで、その場でAIと対話し、コードを直接編集させることができます。エディタとチャットウィンドウを行き来する必要がありません。\n- **AIによるリファクタリング**: 「この関数の変数名を分かりやすくして」「このクラスにテストコードを書いて」といったリファクタリング作業をAIに一任できます。\n\n**メリット／デメリット**\n- **メリット**: 開発速度が劇的に向上する。複雑なコードベースの理解が容易になる。AIとの対話がシームレス。\n- **デメリット**: デフォルトではCursorのサーバーを経由してOpenAIのAPIを利用するため、プライバシーポリシーの確認が必要。一部機能は有料。\n\n**初心者がつまずくポイント**\nプロンプトの書き方に少しコツが必要です。ただ「〇〇して」と書くのではなく、「あなたは経験豊富なバイオインフォマティシャンです。Biopythonを使って、FASTAファイルからGC含量を計算する関数を書いてください。エラーハンドリングも考慮してください。」のように、**役割（ペルソナ）、文脈、詳細な要件**を伝えることで、生成されるコードの質が格段に向上します。\n\n### 2. ローカルLLM実行環境「Ollama」\n\n**Ollamaとは？**\n[Ollama](https://ollama.com/)は、Llama 3, Code Llama, MistralといったオープンソースのLLMを、自分のPC上で驚くほど簡単に実行できるようにするツールです。複雑な環境構築は不要で、数個のコマンドを打つだけで準備が完了します。\n\n**なぜローカルLLMが必要なのか？**\n最大の理由は**セキュリティ**です。GEM Labが扱うモンスターの遺伝子情報は最高機密事項。これを外部のAPIに送信することは絶対に許されません。Ollamaを使えば、全ての処理がローカルマシン内で完結するため、情報漏洩のリスクをゼロにできます。オフライン環境でも動作するのも大きな利点です。\n\n**メリット／デメリット**\n- **メリット**: 高いセキュリティとプライバシー。オフライン利用可能。API利用料がかからない。\n- **デメリット**: 高性能なモデルを動かすには、相応のマシンスペック（特にメモリとGPU）が必要。クラウドの最新モデル（GPT-4oなど）と比較すると性能が劣る場合がある。\n\n**初心者がつまずくポイント**\n- **メモリ不足**: 大規模なモデルを実行しようとすると、メモリ不足で動作が遅くなったり、エラーが発生したりします。まずは`llama3:8b`（80億パラメータ）のような比較的小さなモデルから試すのがおすすめです。\n- **モデルの選択**: 用途に応じてモデルを選ぶ必要があります。コーディング支援なら`codellama`、汎用的な対話なら`llama3`、日本語性能を重視するなら`gemma:7b`など、様々な選択肢があります。Ollamaの[ライブラリページ](https://ollama.com/library)で探してみましょう。\n\n---\n\n## 🧪 実践編：動くコード／コマンド例\n\n### 1. 環境構築\n\n#### a. Cursorのインストール\n1.  [公式サイト](https://cursor.sh/)にアクセスし、お使いのOS用のインストーラをダウンロードします。\n2.  ダウンロードしたファイルを実行し、アプリケーションをインストールします。\n3.  起動するとVSCodeと非常によく似た画面が表示されます。既存のVSCode設定や拡張機能もインポートできます。\n\n#### b. Ollamaのインストールとセットアップ\n\n**macOS / Linux の場合:**\n```bash\n# 公式サイトのインストールスクリプトを実行\ncurl -fsSL https://ollama.com/install.sh | sh\n```\n\n**Windows の場合:**\n[公式サイト](https://ollama.com/download)からインストーラをダウンロードして実行します。\n\n**Llama 3 (8B) モデルのダウンロード:**\nインストール後、ターミナルで以下のコマンドを実行します。モデルのダウンロードが始まります（数GBあります）。\n\n```bash\n# Llama 3 (8B) instructモデルをプル\nollama pull llama3:8b\n\n# 成功ログの例\n# pulling manifest\n# pulling 2ab3b58f9049... 100% ▕██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████- 4.7g/s 4.7 GB\n# success\n```\n\n### 2. CursorによるクラウドAI活用例\n\nここでは、一般的なバイオインフォマティクスのタスクをCursorに依頼してみます。\n\n**シナリオ:** `monster_sequences.fasta` というFASTA形式のファイルから、特定のID (`MONSTER_007`) を持つ配列を抽出するPythonスクリプトを作成します。\n\n1.  `main.py` という空のファイルを作成します。\n2.  `Cmd+L` (Windows/Linux: `Ctrl+L`) でチャットウィンドウを開き、以下のプロンプトを入力します。\n    ```\n    あなたは熟練のPythonプログラマです。\n    Biopythonライブラリを使って、FASTAファイルから特定のIDを持つシーケンスを抽出するコマンドラインツールを作成してください。\n\n    要件：\n    - 入力ファイルパスとシーケンスIDを引数として受け取ること。\n    - 該当するIDが見つかった場合は、そのシーケンスを標準出力に出力すること。\n    - 見つからなかった場合は、エラーメッセージを出力すること。\n    - argparseを使って、使いやすいインターフェースにすること。\n    ```\n3.  AIがコードを生成します。以下はその一例です。\n\n```python\n# main.py (AIが生成したコード)\nimport argparse\nfrom Bio import SeqIO\nimport sys\n\ndef extract_sequence_by_id(fasta_file, sequence_id):\n    \"\"\"\n    Extracts a sequence from a FASTA file by its ID.\n\n    Args:\n        fasta_file (str): Path to the input FASTA file.\n        sequence_id (str): The ID of the sequence to extract.\n\n    Returns:\n        Bio.SeqRecord.SeqRecord or None: The found sequence record, or None if not found.\n    \"\"\"\n    try:\n        for record in SeqIO.parse(fasta_file, \"fasta\"):\n            if record.id == sequence_id:\n                return record\n        return None\n    except FileNotFoundError:\n        print(f\"Error: The file '{fasta_file}' was not found.\", file=sys.stderr)\n        return None\n\ndef main():\n    parser = argparse.ArgumentParser(description=\"Extract a specific sequence from a FASTA file.\")\n    parser.add_argument(\"fasta_file\", help=\"Path to the input FASTA file.\")\n    parser.add_argument(\"sequence_id\", help=\"The ID of the sequence to extract.\")\n    args = parser.parse_args()\n\n    found_record = extract_sequence_by_id(args.fasta_file, args.sequence_id)\n\n    if found_record:\n        print(f\">{found_record.description}\")\n        print(found_record.seq)\n    else:\n        print(f\"Sequence with ID '{args.sequence_id}' not found in '{args.fasta_file}'.\", file=sys.stderr)\n        sys.exit(1)\n\nif __name__ == \"__main__\":\n    main()\n```\n\n4.  次に、このコードをリファクタリングしてみましょう。`extract_sequence_by_id`関数を選択して`Cmd+K` (Ctrl+K) を押し、こう指示します。\n    `この関数に型ヒントを追加し、docstringをGoogleスタイルに変更してください。`\n\nすると、AIが即座にコードを以下のように書き換えてくれます。\n\n```python\n# main.py (リファクタリング後のコード)\nimport argparse\nfrom Bio import SeqIO\nfrom Bio.SeqRecord import SeqRecord\nimport sys\nfrom typing import Optional\n\ndef extract_sequence_by_id(fasta_file: str, sequence_id: str) -> Optional[SeqRecord]:\n    \"\"\"Extracts a sequence from a FASTA file by its ID.\n\n    Args:\n        fasta_file (str): Path to the input FASTA file.\n        sequence_id (str): The ID of the sequence to extract.\n\n    Returns:\n        Optional[SeqRecord]: The found sequence record, or None if not found or\n                             if the file does not exist.\n    \"\"\"\n    try:\n        for record in SeqIO.parse(fasta_file, \"fasta\"):\n            if record.id == sequence_id:\n                return record\n        return None\n    except FileNotFoundError:\n        print(f\"Error: The file '{fasta_file}' was not found.\", file=sys.stderr)\n        return None\n\n# (main関数は変更なし)\n...\n```\n\nこのように、対話的にコーディングとリファクタリングを進めることができます。\n\n### 3. OllamaによるローカルLLM活用例\n\n**シナリオ:** モンスターの機密ゲノムデータ（という想定のダミーデータ）を含むスクリプトのデバッグを、情報を外部に送らずに行います。\n\n1.  まず、ターミナルでOllamaの対話モードを開始します。\n    ```bash\n    ollama run llama3:8b\n    ```\n    ```\n    >>>\n    ```\n    とプロンプトが表示され、入力待機状態になります。\n\n2.  ここに、デバッグしたいコードに関する質問を貼り付けます。**機密データそのものではなく、コードのロジックに関する質問をすることがポイントです。**\n\n    **プロンプト例:**\n    ```\n    Pythonのコードについて質問です。\n    `data`という文字列があり、ここには'A', 'T', 'G', 'C'以外の文字（例えば'N'）が含まれている可能性があります。\n    この文字列から'N'の数を数えるコードを書いていますが、`data.count('N')`よりも効率的な方法はありますか？\n    データは非常に長くなる可能性があります（数ギガバイト）。\n    ```\n    \n    **Ollama (Llama 3) からの回答例:**\n    ```\n    こんにちは！興味深い質問ですね。巨大な文字列で特定の文字を数える場合、パフォーマンスは重要になります。\n\n    `data.count('N')`はシンプルで読みやすいですが、PythonのC言語実装レベルで最適化されており、非常に高速です。ほとんどの場合、これで十分です。\n\n    しかし、メモリ効率をさらに考慮する場合や、文字列を一度にメモリにロードできない場合は、ジェネレータ式やイテレータを使うアプローチが考えられます。\n\n    例えば、ファイルを一行ずつ読み込んで処理する場合：\n\n    ```python\n    def count_char_in_file(filepath, char_to_count):\n        count = 0\n        with open(filepath, 'r') as f:\n            for line in f:\n                count += line.count(char_to_count)\n        return count\n\n    # 使い方\n    # n_count = count_char_in_file('huge_genome_file.txt', 'N')\n    # print(f\"The character 'N' appears {n_count} times.\")\n    ```\n\n    この方法は、ファイル全体を一度にメモリに読み込まないため、巨大なファイルに対してもメモリ効率が良いです。\n\n    もし文字列がすでにメモリ上にあるが、他の処理と並行してカウントしたい場合は、単純なループも考えられます。\n\n    ```python\n    data = \"ATGCGNATGC...\" # 巨大な文字列と仮定\n    n_count = sum(1 for char in data if char == 'N')\n    ```\n\n    このジェネレータ式を使った方法は、`count()`メソッドとパフォーマンス的には大差ないことが多いですが、より複雑な条件（例：'N'または'n'を数える）を追加するのが容易です。\n\n    結論として、シンプルさで言えば`data.count('N')`が最善です。メモリが懸念される巨大なファイルの場合は、ファイルをチャンクまたは行ごとに読み込むアプローチをお勧めします。\n    ```\n\nこのように、ローカル環境で完結させながら、具体的なコードの改善案や代替案を得ることができます。\n\n### 4. ハイブリッド戦略の実践: CursorからローカルLLMを呼び出す\n\nCursorの真価は、使用するAIモデルを柔軟に切り替えられる点にあります。\n\n1.  Cursorで `Cmd+,` (Ctrl+,) を押して設定を開きます。\n2.  \"Models\" を検索し、\"Model Provider\" のセクションを見つけます。\n3.  \"Add a new model...\" をクリックし、\"Ollama\" を選択します。\n4.  設定で、使用したいモデル名（例: `llama3:8b`）を入力します。\n5.  これで、チャットウィンドウやインライン編集時に、モデル選択ドロップダウンから`Ollama/llama3:8b`を選べるようになります。\n\nこれにより、「この一般的な関数はGPT-4で生成し、この機密データに触れる部分のデバッグはローカルのLlama 3で」といった使い分けが、同じエディタ内でシームレスに実現できます。\n\n---\n\n## 🚀 応用・発展・実用例\n\nこのハイブリッドAI解析環境は、様々な場面で応用できます。\n\n- **新規パイプラインの設計**: NextflowやSnakemakeのようなワークフロー言語のボイラープレートをAIに生成させ、迅速にパイプラインの骨格を作ることができます。「Snakemakeを使って、FASTQファイルをTrimmomaticでトリミングし、BWAでマッピングするルールの雛形を書いて」といった指示が有効です。\n- **データ可視化の高速化**: MatplotlibやSeabornを使った複雑なグラフ（例: 火山プロット、クラスタリングのヒートマップ）の描画コードをAIに生成させ、自分はデータの解釈に集中できます。\n- **他技術との統合**:\n    - **Docker**: `Dockerfile`の作成や最適化をAIに相談できます。「Python 3.10ベースで、BiopythonとPandasをインストールするDockerfileを書いて」と依頼すれば、すぐに雛形が手に入ります。\n    - **Jupyter**: データ探索フェーズでは、Jupyter Lab内で[Jupyter AI](https://github.com/jupyter-ai/jupyter-ai)拡張機能を使うことで、ノートブック上で直接LLMと対話し、コードセルを生成させることが可能です。\n- **モンスター生命体の解析への応用**:\n    - 未知の遺伝子配列が与えられた際、「この配列に似た機能を持つ既知の遺伝子をBLASTで検索するためのBiopythonスクリプトを書いて」とCursorに依頼する。\n    - 発見された新種モンスターのゲノムアセンブリ結果（機密）について、「このアセンブリ結果に含まれるコンティグのN50を計算するPythonスクリプトを、メモリ効率を考慮して書いて」とOllamaに相談する。\n\n---\n\n## 📝 まとめ（Takeaways）\n\nこの記事で紹介した「ハイブリッドAI解析環境」の重要なポイントをまとめます。\n\n- **AIは「相棒」**: AI駆動開発は、単なるコード補完ではなく、設計・実装・デバッグ・ドキュメント化の全工程を支援する強力なパートナーです。\n- **Cursorで開発を加速**: AIネイティブエディタCursorは、深いコンテキスト理解とシームレスな対話機能により、開発体験を次のレベルに引き上げます。\n- **Ollamaでセキュリティを確保**: 機密データを扱う際は、Ollamaを使ってローカル環境でLLMを実行することで、情報漏洩のリスクなくAIの恩恵を受けられます。\n- **ハイブリッドが最適解**: クラウドAIの性能とローカルLLMのセキュリティを使い分ける「ハイブリッド戦略」が、現代の多くの開発・解析業務において現実的かつ強力なソリューションです。\n- **まずは試すことから**: CursorとOllamaのインストールは非常に簡単です。まずは手元のPCに導入し、日々のちょっとした作業からAIに任せてみることをお勧めします。\n\n---\n\n## ❓ FAQ（読者が抱きそうな疑問と回答）\n\n**Q1: マシンスペックが低いPCでもローカルLLMは使えますか？**\nA1: はい、使えますがモデルの選択が重要になります。Ollamaは比較的軽量ですが、快適な動作には16GB以上のRAMを推奨します。もし動作が重い場合は、`llama3:8b`よりもさらに小さいモデル、例えば`tinydolphin`や`qwen:4b`などを試してみてください。これらは性能は少し落ちますが、要求スペックは低くなります。\n\n**Q2: Cursorは無料ですか？ 有料プランとの違いは何ですか？**\nA2: Cursorには無料枠があります。無料枠では、GPT-4などの高性能モデルを月に一定回数利用できます。回数制限を超えて利用したい場合や、より高度な機能（プロジェクト全体をAIに読み込ませる\"Auto-repo\"など）を使いたい場合は、有料プランへのアップグレードが必要です。ただし、Ollamaと連携してローカルLLMを使う分には、回数制限なく無料で利用できます。\n\n**Q3: AIが生成したコードの信頼性はどのように担保すればよいですか？**\nA3: 非常に重要な質問です。AIが生成したコードは**絶対に鵜呑みにしてはいけません**。それはあくまで「非常に優秀なアシスタントが書いた下書き」と捉えるべきです。特に、バイオインフォマティクスのような科学的な正確性が求められる分野では、以下の点を確認することが不可欠です。\n1.  **ロジックの検証**: 生成されたコードのアルゴリズムが、意図した解析手法と一致しているか必ず確認します。\n2.  **テスト**: 小さなダミーデータセットでコードを動かし、期待通りの結果が得られるかテストします。\n3.  **ライブラリのドキュメント参照**: 使用されている関数やオプションが適切か、公式ドキュメントで裏を取る習慣をつけましょう。\n\n---\n\n## 🔗 参考文献・リンク集\n\n- **Cursor 公式サイト**: [https://cursor.sh/](https://cursor.sh/)\n- **Ollama 公式サイト**: [https://ollama.com/](https://ollama.com/)\n- **Ollama Model Library**: [https://ollama.com/library](https://ollama.com/library)\n- **Biopython Project**: [https://biopython.org/](https://biopython.org/)\n- **Jupyter AI (GitHub)**: [https://github.com/jupyter-ai/jupyter-ai](https://github.com/jupyter-ai/jupyter-ai)\n",
      "coediting": false,
      "comments_count": 0,
      "created_at": "2025-12-05T18:21:34+09:00",
      "group": null,
      "id": "5ca46b45f0ba191895c9",
      "likes_count": 0,
      "private": false,
      "reactions_count": 0,
      "stocks_count": 0,
      "tags": [
        {
          "name": "Python",
          "versions": []
        },
        {
          "name": "自動化",
          "versions": []
        }
      ],
      "title": "AI駆動でモンスター遺伝子解析を加速！CursorとローカルLLMで作る次世代バイオインフォ環境",
      "updated_at": "2025-12-05T18:21:34+09:00",
      "url": "https://qiita.com/cocokara_bioinfo/items/5ca46b45f0ba191895c9",
      "user": {
        "description": "ポッケ村出身の名もなき若手生物学研究員です。\r\n現代の技術やエンジニア知識を学びながらモンスターハンターの生態・生物学研究に日々励んでおります！\r\nまだまだ勉強不足なところはありますが、皆さんに少しでも学びになるものをお届けできればとの思いで発信させていただきます\r\n\r\n※フィクションとして、時にTips記事として楽しんでいただければ幸いです",
        "facebook_id": "",
        "followees_count": 3,
        "followers_count": 0,
        "github_login_name": null,
        "id": "cocokara_bioinfo",
        "items_count": 4,
        "linkedin_id": "",
        "location": "",
        "name": "シャル・S 調査員",
        "organization": "Genome & Ecology Monster-Lab (架空)",
        "permanent_id": 4288059,
        "profile_image_url": "https://lh3.googleusercontent.com/a/ACg8ocLkgrrRuDzozKQ4XeInetzc0um1rPWRGXY2daT9pLIi1z1JdQ=s96-c",
        "team_only": false,
        "twitter_screen_name": null,
        "website_url": ""
      },
      "page_views_count": 158,
      "team_membership": null,
      "organization_url_name": null,
      "slide": false,
      "_source": "my_popular"
    },
    {
      "rendered_body": "<blockquote data-sourcepos=\"1:1-2:126\">\n<p data-sourcepos=\"1:3-2:126\"><strong>対象読者</strong><br>\nPython をある程度書けるエンジニア、GitHub Actions に興味がある方、Qiita 投稿を効率化したい方</p>\n</blockquote>\n<blockquote data-sourcepos=\"4:1-9:26\">\n<p data-sourcepos=\"4:3-4:41\"><strong>動作確認環境 / 前提条件</strong></p>\n<ul data-sourcepos=\"5:3-9:26\">\n<li data-sourcepos=\"5:3-5:27\">macOS Monterey (12.6.3)</li>\n<li data-sourcepos=\"6:3-6:14\">Python 3.9</li>\n<li data-sourcepos=\"7:3-7:12\">pip 23.0</li>\n<li data-sourcepos=\"8:3-8:26\">GitHub アカウント</li>\n<li data-sourcepos=\"9:3-9:26\">Qiita API トークン</li>\n</ul>\n</blockquote>\n<blockquote data-sourcepos=\"11:1-14:65\">\n<p data-sourcepos=\"11:3-11:39\"><strong>この記事で得られること</strong></p>\n<ul data-sourcepos=\"12:3-14:65\">\n<li data-sourcepos=\"12:3-12:53\">Qiita API を利用した記事投稿の自動化</li>\n<li data-sourcepos=\"13:3-13:68\">GitHub Actions を利用した CI/CD パイプラインの構築</li>\n<li data-sourcepos=\"14:3-14:65\">Python スクリプトのテストとデプロイの自動化</li>\n</ul>\n</blockquote>\n<h2 data-sourcepos=\"16:1-16:50\">\n<span id=\"-導入背景課題なぜ重要か\" class=\"fragment\"></span><a href=\"#-%E5%B0%8E%E5%85%A5%E8%83%8C%E6%99%AF%E8%AA%B2%E9%A1%8C%E3%81%AA%E3%81%9C%E9%87%8D%E8%A6%81%E3%81%8B\"><i class=\"fa fa-link\"></i></a>🧭 導入：背景・課題・なぜ重要か</h2>\n<p data-sourcepos=\"18:1-18:307\">日々の業務や学習で得た知識を Qiita に投稿するのは、エンジニアにとって非常に有益な習慣です。しかし、「記事を書く時間がない」「投稿が面倒」といった理由で、せっかくの知識が埋もれてしまうことも少なくありません。</p>\n<p data-sourcepos=\"20:1-20:269\">そこで、この記事では <strong>Python と GitHub Actions を活用して、Qiita への記事投稿を自動化するパイプライン</strong> を構築します。これにより、記事作成に集中し、より多くの知識を共有できるようになります。</p>\n<p data-sourcepos=\"22:1-22:469\">以前の記事 <a href=\"https://qiita.com/cocokara_bioinfo/items/78b20fc5aff614e609e2\" id=\"reference-146fe97063490483165a\">使用例</a> では、Qiita 投稿の効率化について紹介しましたが、今回はさらに一歩進んで、完全に自動化されたパイプラインを構築します。この自動化によって、記事の作成から投稿までの一連のフローが劇的に改善され、より多くの時間を記事の質向上に費やすことができるようになります。</p>\n<h2 data-sourcepos=\"24:1-24:29\">\n<span id=\"-トピックの概要\" class=\"fragment\"></span><a href=\"#-%E3%83%88%E3%83%94%E3%83%83%E3%82%AF%E3%81%AE%E6%A6%82%E8%A6%81\"><i class=\"fa fa-link\"></i></a>📘 トピックの概要</h2>\n<p data-sourcepos=\"26:1-26:248\">今回のトピックは、<strong>Qiita API を利用した記事投稿の自動化</strong> です。Qiita API を利用することで、プログラムから Qiita に記事を投稿したり、既存の記事を更新したりすることができます。</p>\n<p data-sourcepos=\"28:1-28:323\"><strong>GitHub Actions</strong> は、GitHub 上で CI/CD (継続的インテグレーション/継続的デリバリー) パイプラインを構築するためのサービスです。GitHub リポジトリへのプッシュやプルリクエストをトリガーとして、自動的にテストやデプロイを実行できます。</p>\n<p data-sourcepos=\"30:1-30:69\">今回のパイプラインのイメージは以下の通りです。</p>\n<p data-sourcepos=\"32:1-32:35\"><strong>文章で図解イメージ案:</strong></p>\n<ol data-sourcepos=\"34:1-38:0\">\n<li data-sourcepos=\"34:1-34:82\">GitHub リポジトリに Markdown ファイル (Qiita 記事) をプッシュ</li>\n<li data-sourcepos=\"35:1-35:43\">GitHub Actions がプッシュを検知</li>\n<li data-sourcepos=\"36:1-36:109\">Python スクリプトが Markdown ファイルを読み込み、Qiita API を利用して記事を投稿</li>\n<li data-sourcepos=\"37:1-38:0\">投稿結果を GitHub Actions のログに出力</li>\n</ol>\n<p data-sourcepos=\"39:1-39:622\">バイオインフォマティクス分野では、大量のデータを解析し、その結果を共有する必要があります。この自動投稿パイプラインは、解析結果を Qiita で共有する際に非常に役立ちます。例えば、ある遺伝子セットに対する解析結果を自動的に Qiita に投稿し、他の研究者と共有することができます。これは、<strong>遺伝子配列という「文字列データ」</strong> を解析し、その結果を共有するという点で、ソフトウェア開発におけるドキュメント生成と似た側面を持っています。</p>\n<h2 data-sourcepos=\"41:1-41:62\">\n<span id=\"-技術的な仕組み実装アーキテクチャ\" class=\"fragment\"></span><a href=\"#-%E6%8A%80%E8%A1%93%E7%9A%84%E3%81%AA%E4%BB%95%E7%B5%84%E3%81%BF%E5%AE%9F%E8%A3%85%E3%82%A2%E3%83%BC%E3%82%AD%E3%83%86%E3%82%AF%E3%83%81%E3%83%A3\"><i class=\"fa fa-link\"></i></a>🔧 技術的な仕組み・実装・アーキテクチャ</h2>\n<p data-sourcepos=\"43:1-43:72\">今回のパイプラインは、以下の要素で構成されます。</p>\n<ol data-sourcepos=\"45:1-48:0\">\n<li data-sourcepos=\"45:1-45:96\">\n<strong>Python スクリプト</strong>: Qiita API を利用して記事を投稿するスクリプト。</li>\n<li data-sourcepos=\"46:1-46:161\">\n<strong>GitHub Actions ワークフロー</strong>: リポジトリへのプッシュをトリガーとして、Python スクリプトを実行するワークフロー。</li>\n<li data-sourcepos=\"47:1-48:0\">\n<strong>Qiita API トークン</strong>: Qiita API を利用するための認証情報。GitHub Actions のシークレットとして安全に管理します。</li>\n</ol>\n<p data-sourcepos=\"49:1-49:17\"><strong>メリット:</strong></p>\n<ul data-sourcepos=\"51:1-54:0\">\n<li data-sourcepos=\"51:1-51:43\">記事投稿の手間を大幅に削減</li>\n<li data-sourcepos=\"52:1-52:37\">継続的な知識共有を促進</li>\n<li data-sourcepos=\"53:1-54:0\">チーム内での情報共有を円滑化</li>\n</ul>\n<p data-sourcepos=\"55:1-55:20\"><strong>デメリット:</strong></p>\n<ul data-sourcepos=\"57:1-59:0\">\n<li data-sourcepos=\"57:1-57:59\">Qiita API の仕様変更に対応する必要がある</li>\n<li data-sourcepos=\"58:1-59:0\">GitHub Actions の設定に慣れる必要がある</li>\n</ul>\n<p data-sourcepos=\"60:1-60:26\"><strong>ハマりポイント:</strong></p>\n<ul data-sourcepos=\"62:1-64:0\">\n<li data-sourcepos=\"62:1-62:127\">Qiita API トークンの管理: GitHub Actions のシークレットとして安全に管理する必要があります。</li>\n<li data-sourcepos=\"63:1-64:0\">Python スクリプトの依存関係: GitHub Actions の環境に Python のライブラリをインストールする必要があります。</li>\n</ul>\n<h2 data-sourcepos=\"65:1-65:53\">\n<span id=\"-実践編動くコードコマンド例\" class=\"fragment\"></span><a href=\"#-%E5%AE%9F%E8%B7%B5%E7%B7%A8%E5%8B%95%E3%81%8F%E3%82%B3%E3%83%BC%E3%83%89%E3%82%B3%E3%83%9E%E3%83%B3%E3%83%89%E4%BE%8B\"><i class=\"fa fa-link\"></i></a>🧪 実践編：動くコード／コマンド例</h2>\n<div class=\"code-frame\" data-lang=\"bash\" data-sourcepos=\"67:1-70:3\"><div class=\"highlight\"><pre><code><span class=\"c\"># 必要なライブラリのインストール</span>\npip <span class=\"nb\">install </span>requests python-dotenv\n</code></pre></div></div>\n<div class=\"code-frame\" data-lang=\"python\" data-sourcepos=\"72:1-109:3\"><div class=\"highlight\"><pre><code><span class=\"c1\"># Qiita API を利用して記事を投稿する Python スクリプト (qiita_poster.py)\n</span><span class=\"kn\">import</span> <span class=\"n\">os</span>\n<span class=\"kn\">import</span> <span class=\"n\">requests</span>\n<span class=\"kn\">from</span> <span class=\"n\">dotenv</span> <span class=\"kn\">import</span> <span class=\"n\">load_dotenv</span>\n\n<span class=\"nf\">load_dotenv</span><span class=\"p\">()</span>\n\n<span class=\"n\">QIITA_API_TOKEN</span> <span class=\"o\">=</span> <span class=\"n\">os</span><span class=\"p\">.</span><span class=\"n\">environ</span><span class=\"p\">.</span><span class=\"nf\">get</span><span class=\"p\">(</span><span class=\"sh\">\"</span><span class=\"s\">QIITA_API_TOKEN</span><span class=\"sh\">\"</span><span class=\"p\">)</span>\n<span class=\"n\">QIITA_ENDPOINT</span> <span class=\"o\">=</span> <span class=\"sh\">\"</span><span class=\"s\">https://qiita.com/api/v2/items</span><span class=\"sh\">\"</span>\n<span class=\"n\">HEADERS</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"sh\">\"</span><span class=\"s\">Authorization</span><span class=\"sh\">\"</span><span class=\"p\">:</span> <span class=\"sa\">f</span><span class=\"sh\">\"</span><span class=\"s\">Bearer </span><span class=\"si\">{</span><span class=\"n\">QIITA_API_TOKEN</span><span class=\"si\">}</span><span class=\"sh\">\"</span><span class=\"p\">,</span>\n    <span class=\"sh\">\"</span><span class=\"s\">Content-Type</span><span class=\"sh\">\"</span><span class=\"p\">:</span> <span class=\"sh\">\"</span><span class=\"s\">application/json</span><span class=\"sh\">\"</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">post_to_qiita</span><span class=\"p\">(</span><span class=\"n\">title</span><span class=\"p\">,</span> <span class=\"n\">body</span><span class=\"p\">,</span> <span class=\"n\">tags</span><span class=\"p\">,</span> <span class=\"n\">is_private</span><span class=\"o\">=</span><span class=\"bp\">False</span><span class=\"p\">):</span>\n    <span class=\"sh\">\"\"\"</span><span class=\"s\">Qiita に記事を投稿する</span><span class=\"sh\">\"\"\"</span>\n    <span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n        <span class=\"sh\">\"</span><span class=\"s\">title</span><span class=\"sh\">\"</span><span class=\"p\">:</span> <span class=\"n\">title</span><span class=\"p\">,</span>\n        <span class=\"sh\">\"</span><span class=\"s\">body</span><span class=\"sh\">\"</span><span class=\"p\">:</span> <span class=\"n\">body</span><span class=\"p\">,</span>\n        <span class=\"sh\">\"</span><span class=\"s\">tags</span><span class=\"sh\">\"</span><span class=\"p\">:</span> <span class=\"p\">[{</span><span class=\"sh\">\"</span><span class=\"s\">name</span><span class=\"sh\">\"</span><span class=\"p\">:</span> <span class=\"n\">tag</span><span class=\"p\">}</span> <span class=\"k\">for</span> <span class=\"n\">tag</span> <span class=\"ow\">in</span> <span class=\"n\">tags</span><span class=\"p\">],</span>\n        <span class=\"sh\">\"</span><span class=\"s\">private</span><span class=\"sh\">\"</span><span class=\"p\">:</span> <span class=\"n\">is_private</span><span class=\"p\">,</span>\n    <span class=\"p\">}</span>\n    <span class=\"n\">response</span> <span class=\"o\">=</span> <span class=\"n\">requests</span><span class=\"p\">.</span><span class=\"nf\">post</span><span class=\"p\">(</span><span class=\"n\">QIITA_ENDPOINT</span><span class=\"p\">,</span> <span class=\"n\">headers</span><span class=\"o\">=</span><span class=\"n\">HEADERS</span><span class=\"p\">,</span> <span class=\"n\">json</span><span class=\"o\">=</span><span class=\"n\">data</span><span class=\"p\">)</span>\n    <span class=\"n\">response</span><span class=\"p\">.</span><span class=\"nf\">raise_for_status</span><span class=\"p\">()</span>  <span class=\"c1\"># エラーが発生した場合に例外を発生させる\n</span>    <span class=\"k\">return</span> <span class=\"n\">response</span><span class=\"p\">.</span><span class=\"nf\">json</span><span class=\"p\">()</span>\n\n<span class=\"k\">if</span> <span class=\"n\">__name__</span> <span class=\"o\">==</span> <span class=\"sh\">\"</span><span class=\"s\">__main__</span><span class=\"sh\">\"</span><span class=\"p\">:</span>\n    <span class=\"n\">title</span> <span class=\"o\">=</span> <span class=\"sh\">\"</span><span class=\"s\">テスト投稿</span><span class=\"sh\">\"</span>\n    <span class=\"n\">body</span> <span class=\"o\">=</span> <span class=\"sh\">\"</span><span class=\"s\">これはテスト投稿です。</span><span class=\"sh\">\"</span>\n    <span class=\"n\">tags</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"sh\">\"</span><span class=\"s\">Python</span><span class=\"sh\">\"</span><span class=\"p\">,</span> <span class=\"sh\">\"</span><span class=\"s\">Qiita</span><span class=\"sh\">\"</span><span class=\"p\">,</span> <span class=\"sh\">\"</span><span class=\"s\">GitHub Actions</span><span class=\"sh\">\"</span><span class=\"p\">]</span>\n\n    <span class=\"k\">try</span><span class=\"p\">:</span>\n        <span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"nf\">post_to_qiita</span><span class=\"p\">(</span><span class=\"n\">title</span><span class=\"p\">,</span> <span class=\"n\">body</span><span class=\"p\">,</span> <span class=\"n\">tags</span><span class=\"p\">)</span>\n        <span class=\"nf\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"sh\">\"</span><span class=\"s\">投稿成功！ URL: </span><span class=\"si\">{</span><span class=\"n\">result</span><span class=\"p\">[</span><span class=\"sh\">'</span><span class=\"s\">url</span><span class=\"sh\">'</span><span class=\"p\">]</span><span class=\"si\">}</span><span class=\"sh\">\"</span><span class=\"p\">)</span>\n    <span class=\"k\">except</span> <span class=\"n\">requests</span><span class=\"p\">.</span><span class=\"n\">exceptions</span><span class=\"p\">.</span><span class=\"n\">RequestException</span> <span class=\"k\">as</span> <span class=\"n\">e</span><span class=\"p\">:</span>\n        <span class=\"nf\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"sh\">\"</span><span class=\"s\">投稿失敗: </span><span class=\"si\">{</span><span class=\"n\">e</span><span class=\"si\">}</span><span class=\"sh\">\"</span><span class=\"p\">)</span>\n</code></pre></div></div>\n<div class=\"code-frame\" data-lang=\"yaml\" data-sourcepos=\"111:1-137:3\"><div class=\"highlight\"><pre><code><span class=\"c1\"># GitHub Actions ワークフローの定義 (qiita_poster.yml)</span>\n<span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">Qiita Poster</span>\n\n<span class=\"na\">on</span><span class=\"pi\">:</span>\n  <span class=\"na\">push</span><span class=\"pi\">:</span>\n    <span class=\"na\">branches</span><span class=\"pi\">:</span>\n      <span class=\"pi\">-</span> <span class=\"s\">main</span>\n\n<span class=\"na\">jobs</span><span class=\"pi\">:</span>\n  <span class=\"na\">deploy</span><span class=\"pi\">:</span>\n    <span class=\"na\">runs-on</span><span class=\"pi\">:</span> <span class=\"s\">ubuntu-latest</span>\n    <span class=\"na\">steps</span><span class=\"pi\">:</span>\n      <span class=\"pi\">-</span> <span class=\"na\">uses</span><span class=\"pi\">:</span> <span class=\"s\">actions/checkout@v3</span>\n      <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">Set up Python </span><span class=\"m\">3.9</span>\n        <span class=\"na\">uses</span><span class=\"pi\">:</span> <span class=\"s\">actions/setup-python@v3</span>\n        <span class=\"na\">with</span><span class=\"pi\">:</span>\n          <span class=\"na\">python-version</span><span class=\"pi\">:</span> <span class=\"m\">3.9</span>\n      <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">Install dependencies</span>\n        <span class=\"na\">run</span><span class=\"pi\">:</span> <span class=\"pi\">|</span>\n          <span class=\"s\">python -m pip install --upgrade pip</span>\n          <span class=\"s\">pip install -r requirements.txt</span>\n      <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">Run Qiita Poster</span>\n        <span class=\"na\">env</span><span class=\"pi\">:</span>\n          <span class=\"na\">QIITA_API_TOKEN</span><span class=\"pi\">:</span> <span class=\"s\">${{ secrets.QIITA_API_TOKEN }}</span>\n        <span class=\"na\">run</span><span class=\"pi\">:</span> <span class=\"s\">python qiita_poster.py</span>\n</code></pre></div></div>\n<p data-sourcepos=\"139:1-139:17\"><strong>実行手順:</strong></p>\n<ol data-sourcepos=\"141:1-146:0\">\n<li data-sourcepos=\"141:1-141:47\">GitHub リポジトリを作成します。</li>\n<li data-sourcepos=\"142:1-142:84\">\n<code>qiita_poster.py</code> と <code>qiita_poster.yml</code> をリポジトリに追加します。</li>\n<li data-sourcepos=\"143:1-143:122\">\n<code>requirements.txt</code> ファイルを作成し、必要なライブラリ (requests, python-dotenv) を記述します。</li>\n<li data-sourcepos=\"144:1-144:145\">Qiita API トークンを取得し、GitHub リポジトリの Settings &gt; Secrets &gt; Actions に <code>QIITA_API_TOKEN</code> として登録します。</li>\n<li data-sourcepos=\"145:1-146:0\">リポジトリにプッシュすると、GitHub Actions が自動的に実行され、Qiita に記事が投稿されます。</li>\n</ol>\n<p data-sourcepos=\"147:1-147:20\"><strong>成功時ログ:</strong></p>\n<div class=\"code-frame\" data-lang=\"text\" data-sourcepos=\"149:1-151:3\"><div class=\"highlight\"><pre><code>投稿成功！ URL: https://qiita.com/your_qiita_id/items/xxxxxxxxxxxxxxxxxxxx\n</code></pre></div></div>\n<p data-sourcepos=\"153:1-153:20\"><strong>失敗時ログ:</strong></p>\n<div class=\"code-frame\" data-lang=\"text\" data-sourcepos=\"155:1-157:3\"><div class=\"highlight\"><pre><code>投稿失敗: 401 Client Error: Unauthorized for url: https://qiita.com/api/v2/items\n</code></pre></div></div>\n<p data-sourcepos=\"159:1-159:14\"><strong>注意点:</strong></p>\n<ul data-sourcepos=\"161:1-164:0\">\n<li data-sourcepos=\"161:1-161:88\">\n<code>qiita_poster.py</code> の <code>title</code>、<code>body</code>、<code>tags</code> を適宜変更してください。</li>\n<li data-sourcepos=\"162:1-162:134\">\n<code>qiita_poster.yml</code> の <code>branches</code> を、プッシュをトリガーとするブランチに合わせて変更してください。</li>\n<li data-sourcepos=\"163:1-164:0\">\n<code>requirements.txt</code> には、Python スクリプトに必要なすべてのライブラリを記述してください。</li>\n</ul>\n<h2 data-sourcepos=\"165:1-165:35\">\n<span id=\"-応用発展実用例\" class=\"fragment\"></span><a href=\"#-%E5%BF%9C%E7%94%A8%E7%99%BA%E5%B1%95%E5%AE%9F%E7%94%A8%E4%BE%8B\"><i class=\"fa fa-link\"></i></a>🚀 応用・発展・実用例</h2>\n<ul data-sourcepos=\"167:1-172:0\">\n<li data-sourcepos=\"167:1-167:125\">\n<strong>記事内容の自動生成</strong>: AI を活用して記事の草稿を自動生成し、それを Qiita に投稿する。</li>\n<li data-sourcepos=\"168:1-168:182\">\n<strong>定期的な情報共有</strong>: 定期的に実行されるスクリプトを作成し、特定の情報を Qiita に自動投稿する（例：日々のニュースサマリ）。</li>\n<li data-sourcepos=\"169:1-169:179\">\n<strong>Docker 化</strong>: Python スクリプトを Docker コンテナ化することで、環境依存性の問題を解消し、より安定したパイプラインを構築する。</li>\n<li data-sourcepos=\"170:1-170:135\">\n<strong>可視化</strong>: データの可視化ツール (例: Matplotlib, Seaborn) で生成したグラフを Qiita 記事に埋め込む。</li>\n<li data-sourcepos=\"171:1-172:0\">\n<strong>創薬</strong>: 実験データや解析結果を自動的に Qiita に投稿し、研究チーム内での情報共有を効率化する。</li>\n</ul>\n<h2 data-sourcepos=\"173:1-173:32\">\n<span id=\"-まとめtakeaways\" class=\"fragment\"></span><a href=\"#-%E3%81%BE%E3%81%A8%E3%82%81takeaways\"><i class=\"fa fa-link\"></i></a>📝 まとめ（Takeaways）</h2>\n<p data-sourcepos=\"175:1-177:130\">生成日時: 2025-12-05 17:04:09<br>\nステータス: draft<br>\nタグ: Qiita, チュートリアル, Python, 自動化, ワークフロー, GitHubActions, CI/CD, 効率化, API, 初心者向け</p>\n",
      "body": "> **対象読者**  \n> Python をある程度書けるエンジニア、GitHub Actions に興味がある方、Qiita 投稿を効率化したい方\n\n> **動作確認環境 / 前提条件**  \n> - macOS Monterey (12.6.3)\n> - Python 3.9\n> - pip 23.0\n> - GitHub アカウント\n> - Qiita API トークン\n\n> **この記事で得られること**\n> - Qiita API を利用した記事投稿の自動化\n> - GitHub Actions を利用した CI/CD パイプラインの構築\n> - Python スクリプトのテストとデプロイの自動化\n\n## 🧭 導入：背景・課題・なぜ重要か\n\n日々の業務や学習で得た知識を Qiita に投稿するのは、エンジニアにとって非常に有益な習慣です。しかし、「記事を書く時間がない」「投稿が面倒」といった理由で、せっかくの知識が埋もれてしまうことも少なくありません。\n\nそこで、この記事では **Python と GitHub Actions を活用して、Qiita への記事投稿を自動化するパイプライン** を構築します。これにより、記事作成に集中し、より多くの知識を共有できるようになります。\n\n以前の記事 [使用例](https://qiita.com/cocokara_bioinfo/items/78b20fc5aff614e609e2) では、Qiita 投稿の効率化について紹介しましたが、今回はさらに一歩進んで、完全に自動化されたパイプラインを構築します。この自動化によって、記事の作成から投稿までの一連のフローが劇的に改善され、より多くの時間を記事の質向上に費やすことができるようになります。\n\n## 📘 トピックの概要\n\n今回のトピックは、**Qiita API を利用した記事投稿の自動化** です。Qiita API を利用することで、プログラムから Qiita に記事を投稿したり、既存の記事を更新したりすることができます。\n\n**GitHub Actions** は、GitHub 上で CI/CD (継続的インテグレーション/継続的デリバリー) パイプラインを構築するためのサービスです。GitHub リポジトリへのプッシュやプルリクエストをトリガーとして、自動的にテストやデプロイを実行できます。\n\n今回のパイプラインのイメージは以下の通りです。\n\n**文章で図解イメージ案:**\n\n1.  GitHub リポジトリに Markdown ファイル (Qiita 記事) をプッシュ\n2.  GitHub Actions がプッシュを検知\n3.  Python スクリプトが Markdown ファイルを読み込み、Qiita API を利用して記事を投稿\n4.  投稿結果を GitHub Actions のログに出力\n\nバイオインフォマティクス分野では、大量のデータを解析し、その結果を共有する必要があります。この自動投稿パイプラインは、解析結果を Qiita で共有する際に非常に役立ちます。例えば、ある遺伝子セットに対する解析結果を自動的に Qiita に投稿し、他の研究者と共有することができます。これは、**遺伝子配列という「文字列データ」** を解析し、その結果を共有するという点で、ソフトウェア開発におけるドキュメント生成と似た側面を持っています。\n\n## 🔧 技術的な仕組み・実装・アーキテクチャ\n\n今回のパイプラインは、以下の要素で構成されます。\n\n1.  **Python スクリプト**: Qiita API を利用して記事を投稿するスクリプト。\n2.  **GitHub Actions ワークフロー**: リポジトリへのプッシュをトリガーとして、Python スクリプトを実行するワークフロー。\n3.  **Qiita API トークン**: Qiita API を利用するための認証情報。GitHub Actions のシークレットとして安全に管理します。\n\n**メリット:**\n\n*   記事投稿の手間を大幅に削減\n*   継続的な知識共有を促進\n*   チーム内での情報共有を円滑化\n\n**デメリット:**\n\n*   Qiita API の仕様変更に対応する必要がある\n*   GitHub Actions の設定に慣れる必要がある\n\n**ハマりポイント:**\n\n*   Qiita API トークンの管理: GitHub Actions のシークレットとして安全に管理する必要があります。\n*   Python スクリプトの依存関係: GitHub Actions の環境に Python のライブラリをインストールする必要があります。\n\n## 🧪 実践編：動くコード／コマンド例\n\n```bash\n# 必要なライブラリのインストール\npip install requests python-dotenv\n```\n\n```python\n# Qiita API を利用して記事を投稿する Python スクリプト (qiita_poster.py)\nimport os\nimport requests\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nQIITA_API_TOKEN = os.environ.get(\"QIITA_API_TOKEN\")\nQIITA_ENDPOINT = \"https://qiita.com/api/v2/items\"\nHEADERS = {\n    \"Authorization\": f\"Bearer {QIITA_API_TOKEN}\",\n    \"Content-Type\": \"application/json\",\n}\n\ndef post_to_qiita(title, body, tags, is_private=False):\n    \"\"\"Qiita に記事を投稿する\"\"\"\n    data = {\n        \"title\": title,\n        \"body\": body,\n        \"tags\": [{\"name\": tag} for tag in tags],\n        \"private\": is_private,\n    }\n    response = requests.post(QIITA_ENDPOINT, headers=HEADERS, json=data)\n    response.raise_for_status()  # エラーが発生した場合に例外を発生させる\n    return response.json()\n\nif __name__ == \"__main__\":\n    title = \"テスト投稿\"\n    body = \"これはテスト投稿です。\"\n    tags = [\"Python\", \"Qiita\", \"GitHub Actions\"]\n\n    try:\n        result = post_to_qiita(title, body, tags)\n        print(f\"投稿成功！ URL: {result['url']}\")\n    except requests.exceptions.RequestException as e:\n        print(f\"投稿失敗: {e}\")\n```\n\n```yaml\n# GitHub Actions ワークフローの定義 (qiita_poster.yml)\nname: Qiita Poster\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - name: Set up Python 3.9\n        uses: actions/setup-python@v3\n        with:\n          python-version: 3.9\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install -r requirements.txt\n      - name: Run Qiita Poster\n        env:\n          QIITA_API_TOKEN: ${{ secrets.QIITA_API_TOKEN }}\n        run: python qiita_poster.py\n```\n\n**実行手順:**\n\n1.  GitHub リポジトリを作成します。\n2.  `qiita_poster.py` と `qiita_poster.yml` をリポジトリに追加します。\n3.  `requirements.txt` ファイルを作成し、必要なライブラリ (requests, python-dotenv) を記述します。\n4.  Qiita API トークンを取得し、GitHub リポジトリの Settings > Secrets > Actions に `QIITA_API_TOKEN` として登録します。\n5.  リポジトリにプッシュすると、GitHub Actions が自動的に実行され、Qiita に記事が投稿されます。\n\n**成功時ログ:**\n\n```\n投稿成功！ URL: https://qiita.com/your_qiita_id/items/xxxxxxxxxxxxxxxxxxxx\n```\n\n**失敗時ログ:**\n\n```\n投稿失敗: 401 Client Error: Unauthorized for url: https://qiita.com/api/v2/items\n```\n\n**注意点:**\n\n*   `qiita_poster.py` の `title`、`body`、`tags` を適宜変更してください。\n*   `qiita_poster.yml` の `branches` を、プッシュをトリガーとするブランチに合わせて変更してください。\n*   `requirements.txt` には、Python スクリプトに必要なすべてのライブラリを記述してください。\n\n## 🚀 応用・発展・実用例\n\n*   **記事内容の自動生成**: AI を活用して記事の草稿を自動生成し、それを Qiita に投稿する。\n*   **定期的な情報共有**: 定期的に実行されるスクリプトを作成し、特定の情報を Qiita に自動投稿する（例：日々のニュースサマリ）。\n*   **Docker 化**: Python スクリプトを Docker コンテナ化することで、環境依存性の問題を解消し、より安定したパイプラインを構築する。\n*   **可視化**: データの可視化ツール (例: Matplotlib, Seaborn) で生成したグラフを Qiita 記事に埋め込む。\n*   **創薬**: 実験データや解析結果を自動的に Qiita に投稿し、研究チーム内での情報共有を効率化する。\n\n## 📝 まとめ（Takeaways）\n\n生成日時: 2025-12-05 17:04:09\nステータス: draft\nタグ: Qiita, チュートリアル, Python, 自動化, ワークフロー, GitHubActions, CI/CD, 効率化, API, 初心者向け\n",
      "coediting": false,
      "comments_count": 0,
      "created_at": "2025-12-05T17:04:22+09:00",
      "group": null,
      "id": "7440c80d8e6a98177957",
      "likes_count": 0,
      "private": false,
      "reactions_count": 0,
      "stocks_count": 0,
      "tags": [
        {
          "name": "Qiita",
          "versions": []
        },
        {
          "name": "Python",
          "versions": []
        },
        {
          "name": "自動化",
          "versions": []
        },
        {
          "name": "チュートリアル",
          "versions": []
        },
        {
          "name": "ワークフロー",
          "versions": []
        }
      ],
      "title": "Python × GitHub Actions で始める！Qiita 自動投稿パイプライン構築術",
      "updated_at": "2025-12-05T17:04:22+09:00",
      "url": "https://qiita.com/cocokara_bioinfo/items/7440c80d8e6a98177957",
      "user": {
        "description": "ポッケ村出身の名もなき若手生物学研究員です。\r\n現代の技術やエンジニア知識を学びながらモンスターハンターの生態・生物学研究に日々励んでおります！\r\nまだまだ勉強不足なところはありますが、皆さんに少しでも学びになるものをお届けできればとの思いで発信させていただきます\r\n\r\n※フィクションとして、時にTips記事として楽しんでいただければ幸いです",
        "facebook_id": "",
        "followees_count": 3,
        "followers_count": 0,
        "github_login_name": null,
        "id": "cocokara_bioinfo",
        "items_count": 4,
        "linkedin_id": "",
        "location": "",
        "name": "シャル・S 調査員",
        "organization": "Genome & Ecology Monster-Lab (架空)",
        "permanent_id": 4288059,
        "profile_image_url": "https://lh3.googleusercontent.com/a/ACg8ocLkgrrRuDzozKQ4XeInetzc0um1rPWRGXY2daT9pLIi1z1JdQ=s96-c",
        "team_only": false,
        "twitter_screen_name": null,
        "website_url": ""
      },
      "page_views_count": 139,
      "team_membership": null,
      "organization_url_name": null,
      "slide": false,
      "_source": "my_popular"
    },
    {
      "rendered_body": "<blockquote data-sourcepos=\"1:1-2:162\">\n<p data-sourcepos=\"1:3-2:162\"><strong>対象読者</strong><br>\nPython を利用したことがあるエンジニア、GitHub Actions を利用したことがあるエンジニア、Qiita への投稿を効率化したい方</p>\n</blockquote>\n<blockquote data-sourcepos=\"4:1-9:211\">\n<p data-sourcepos=\"4:3-4:41\"><strong>動作確認環境 / 前提条件</strong></p>\n<ul data-sourcepos=\"5:3-9:211\">\n<li data-sourcepos=\"5:3-5:24\">macOS Ventura 13.6.3</li>\n<li data-sourcepos=\"6:3-6:17\">Python 3.11.5</li>\n<li data-sourcepos=\"7:3-7:26\">GitHub アカウント</li>\n<li data-sourcepos=\"8:3-8:95\">Qiita API v2 の理解（<a href=\"https://qiita.com/api/v2/docs\">公式ドキュメント</a>参照）</li>\n<li data-sourcepos=\"9:3-9:211\">以前の記事「<a href=\"https://qiita.com/cocokara_bioinfo/items/7440c80d8e6a98177957\" id=\"reference-f84ecb787f5c23d4b71a\">Python × GitHub Actions で始める！Qiita 自動投稿パイプライン構築術</a>」の内容を理解していること</li>\n</ul>\n</blockquote>\n<blockquote data-sourcepos=\"11:1-14:88\">\n<p data-sourcepos=\"11:3-11:39\"><strong>この記事で得られること</strong></p>\n<ul data-sourcepos=\"12:3-14:88\">\n<li data-sourcepos=\"12:3-12:78\">Qiita 記事投稿を自動化する Python スクリプトの構築方法</li>\n<li data-sourcepos=\"13:3-13:74\">GitHub Actions を利用した CI/CD パイプラインの構築方法</li>\n<li data-sourcepos=\"14:3-14:88\">自動化パイプライン構築におけるハマりどころと、その解決策</li>\n</ul>\n</blockquote>\n<h2 data-sourcepos=\"17:1-17:45\">\n<span id=\"実際に躓いたポイントと解決策\" class=\"fragment\"></span><a href=\"#%E5%AE%9F%E9%9A%9B%E3%81%AB%E8%BA%93%E3%81%84%E3%81%9F%E3%83%9D%E3%82%A4%E3%83%B3%E3%83%88%E3%81%A8%E8%A7%A3%E6%B1%BA%E7%AD%96\"><i class=\"fa fa-link\"></i></a>実際に躓いたポイントと解決策</h2>\n<h3 data-sourcepos=\"19:1-19:41\">\n<span id=\"1-gemini-apiのモデル名エラー\" class=\"fragment\"></span><a href=\"#1-gemini-api%E3%81%AE%E3%83%A2%E3%83%87%E3%83%AB%E5%90%8D%E3%82%A8%E3%83%A9%E3%83%BC\"><i class=\"fa fa-link\"></i></a>1. Gemini APIのモデル名エラー</h3>\n<p data-sourcepos=\"21:1-21:12\"><strong>問題</strong>:</p>\n<div class=\"code-frame\" data-lang=\"text\" data-sourcepos=\"22:1-24:3\"><div class=\"highlight\"><pre><code>404 models/gemini-1.5-flash is not found for API version v1beta\n</code></pre></div></div>\n<p data-sourcepos=\"26:1-26:12\"><strong>原因</strong>:</p>\n<ul data-sourcepos=\"27:1-29:0\">\n<li data-sourcepos=\"27:1-27:138\">設定ファイルで<code>gemini-1.5-flash</code>を指定していたが、実際に利用可能なモデルは<code>models/gemini-2.0-flash</code>だった</li>\n<li data-sourcepos=\"28:1-29:0\">Google Gemini APIは定期的にモデル名が更新される</li>\n</ul>\n<p data-sourcepos=\"30:1-30:14\"><strong>解決策</strong>:</p>\n<div class=\"code-frame\" data-lang=\"python\" data-sourcepos=\"31:1-45:3\"><div class=\"highlight\"><pre><code><span class=\"c1\"># 利用可能なモデルを確認\n</span><span class=\"n\">models</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">m</span> <span class=\"k\">for</span> <span class=\"n\">m</span> <span class=\"ow\">in</span> <span class=\"n\">genai</span><span class=\"p\">.</span><span class=\"nf\">list_models</span><span class=\"p\">()</span> \n          <span class=\"k\">if</span> <span class=\"sh\">'</span><span class=\"s\">generateContent</span><span class=\"sh\">'</span> <span class=\"ow\">in</span> <span class=\"n\">m</span><span class=\"p\">.</span><span class=\"n\">supported_generation_methods</span><span class=\"p\">]</span>\n<span class=\"c1\"># 結果: models/gemini-2.0-flash, models/gemini-2.5-flash など\n</span>\n<span class=\"c1\"># 設定ファイルを更新\n</span><span class=\"p\">{</span>\n  <span class=\"sh\">\"</span><span class=\"s\">api</span><span class=\"sh\">\"</span><span class=\"p\">:</span> <span class=\"p\">{</span>\n    <span class=\"sh\">\"</span><span class=\"s\">gemini</span><span class=\"sh\">\"</span><span class=\"p\">:</span> <span class=\"p\">{</span>\n      <span class=\"sh\">\"</span><span class=\"s\">model</span><span class=\"sh\">\"</span><span class=\"p\">:</span> <span class=\"sh\">\"</span><span class=\"s\">models/gemini-2.0-flash</span><span class=\"sh\">\"</span>  <span class=\"c1\"># models/プレフィックスが必要\n</span>    <span class=\"p\">}</span>\n  <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n<p data-sourcepos=\"47:1-47:129\"><strong>学んだこと</strong>: APIの仕様変更に備えて、利用可能なモデルを動的に確認する仕組みを追加すべき</p>\n<h3 data-sourcepos=\"49:1-49:60\">\n<span id=\"2-windowsコンソールのunicode文字表示エラー\" class=\"fragment\"></span><a href=\"#2-windows%E3%82%B3%E3%83%B3%E3%82%BD%E3%83%BC%E3%83%AB%E3%81%AEunicode%E6%96%87%E5%AD%97%E8%A1%A8%E7%A4%BA%E3%82%A8%E3%83%A9%E3%83%BC\"><i class=\"fa fa-link\"></i></a>2. WindowsコンソールのUnicode文字表示エラー</h3>\n<p data-sourcepos=\"51:1-51:11\"><strong>問題</strong>:</p>\n<div class=\"code-frame\" data-lang=\"text\" data-sourcepos=\"52:1-54:3\"><div class=\"highlight\"><pre><code>UnicodeEncodeError: 'cp932' codec can't encode character '✓' in position 0\n</code></pre></div></div>\n<p data-sourcepos=\"56:1-56:12\"><strong>原因</strong>:</p>\n<ul data-sourcepos=\"57:1-58:0\">\n<li data-sourcepos=\"57:1-58:0\">WindowsのPowerShellでは、Unicode文字（✓、⚠、✗）がデフォルトのエンコーディング（cp932）で表示できない</li>\n</ul>\n<p data-sourcepos=\"59:1-59:14\"><strong>解決策</strong>:</p>\n<div class=\"code-frame\" data-lang=\"python\" data-sourcepos=\"60:1-65:3\"><div class=\"highlight\"><pre><code><span class=\"c1\"># Unicode文字を通常の文字に置き換え\n</span><span class=\"nf\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"sh\">\"</span><span class=\"s\">[OK] 処理が完了しました</span><span class=\"sh\">\"</span><span class=\"p\">)</span>  <span class=\"c1\"># ✓ → [OK]\n</span><span class=\"nf\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"sh\">\"</span><span class=\"s\">[WARN] 警告メッセージ</span><span class=\"sh\">\"</span><span class=\"p\">)</span>    <span class=\"c1\"># ⚠ → [WARN]\n</span><span class=\"nf\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"sh\">\"</span><span class=\"s\">[ERROR] エラーが発生</span><span class=\"sh\">\"</span><span class=\"p\">)</span>     <span class=\"c1\"># ✗ → [ERROR]\n</span></code></pre></div></div>\n<p data-sourcepos=\"67:1-67:160\"><strong>学んだこと</strong>: クロスプラットフォーム対応では、Unicode文字の使用を避けるか、エンコーディングを明示的に設定する</p>\n<h3 data-sourcepos=\"69:1-69:55\">\n<span id=\"3-qiita-apiのタグ数制限による403エラー\" class=\"fragment\"></span><a href=\"#3-qiita-api%E3%81%AE%E3%82%BF%E3%82%B0%E6%95%B0%E5%88%B6%E9%99%90%E3%81%AB%E3%82%88%E3%82%8B403%E3%82%A8%E3%83%A9%E3%83%BC\"><i class=\"fa fa-link\"></i></a>3. Qiita APIのタグ数制限による403エラー</h3>\n<p data-sourcepos=\"71:1-71:11\"><strong>問題</strong>:</p>\n<div class=\"code-frame\" data-lang=\"text\" data-sourcepos=\"72:1-74:3\"><div class=\"highlight\"><pre><code>HTTPエラー: 403 - {'message': 'Forbidden', 'type': 'forbidden'}\n</code></pre></div></div>\n<p data-sourcepos=\"76:1-76:12\"><strong>原因</strong>:</p>\n<ul data-sourcepos=\"77:1-79:0\">\n<li data-sourcepos=\"77:1-77:124\">動的タグ生成で9個のタグを生成していたが、Qiita APIはタグを最大5個までしか受け付けない</li>\n<li data-sourcepos=\"78:1-79:0\">APIドキュメントを確認せずに実装していた</li>\n</ul>\n<p data-sourcepos=\"80:1-80:14\"><strong>解決策</strong>:</p>\n<div class=\"code-frame\" data-lang=\"python\" data-sourcepos=\"81:1-86:3\"><div class=\"highlight\"><pre><code><span class=\"c1\"># タグを5個に制限\n</span><span class=\"k\">if</span> <span class=\"nf\">len</span><span class=\"p\">(</span><span class=\"n\">tags</span><span class=\"p\">)</span> <span class=\"o\">&gt;</span> <span class=\"mi\">5</span><span class=\"p\">:</span>\n    <span class=\"nf\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"sh\">\"</span><span class=\"s\">[WARN] タグが</span><span class=\"si\">{</span><span class=\"nf\">len</span><span class=\"p\">(</span><span class=\"n\">tags</span><span class=\"p\">)</span><span class=\"si\">}</span><span class=\"s\">個ありますが、Qiita APIの制限により5個に制限します</span><span class=\"sh\">\"</span><span class=\"p\">)</span>\n<span class=\"n\">qiita_tags</span> <span class=\"o\">=</span> <span class=\"p\">[{</span><span class=\"sh\">\"</span><span class=\"s\">name</span><span class=\"sh\">\"</span><span class=\"p\">:</span> <span class=\"n\">tag</span><span class=\"p\">}</span> <span class=\"k\">for</span> <span class=\"n\">tag</span> <span class=\"ow\">in</span> <span class=\"n\">tags</span><span class=\"p\">[:</span><span class=\"mi\">5</span><span class=\"p\">]]</span>\n</code></pre></div></div>\n<p data-sourcepos=\"88:1-88:21\"><strong>学んだこと</strong>:</p>\n<ul data-sourcepos=\"89:1-91:0\">\n<li data-sourcepos=\"89:1-89:47\">APIの仕様を事前に確認する重要性</li>\n<li data-sourcepos=\"90:1-91:0\">エラーメッセージが不十分な場合、リクエスト内容を詳細にログ出力して原因を特定する</li>\n</ul>\n<h3 data-sourcepos=\"92:1-92:40\">\n<span id=\"4-llmプロンプトの設計ミス\" class=\"fragment\"></span><a href=\"#4-llm%E3%83%97%E3%83%AD%E3%83%B3%E3%83%97%E3%83%88%E3%81%AE%E8%A8%AD%E8%A8%88%E3%83%9F%E3%82%B9\"><i class=\"fa fa-link\"></i></a>4. LLMプロンプトの設計ミス</h3>\n<p data-sourcepos=\"94:1-94:12\"><strong>問題</strong>:</p>\n<ul data-sourcepos=\"95:1-97:0\">\n<li data-sourcepos=\"95:1-95:111\">タイトル案を3つ生成していたが、実際のタイトルが「使用例」になってしまった</li>\n<li data-sourcepos=\"96:1-97:0\">パース処理でタイトルが正しく抽出できなかった</li>\n</ul>\n<p data-sourcepos=\"98:1-98:11\"><strong>原因</strong>:</p>\n<ul data-sourcepos=\"99:1-101:0\">\n<li data-sourcepos=\"99:1-99:138\">プロンプトで「タイトル案（3つ）」を指示していたが、実際のタイトルを明確に指定していなかった</li>\n<li data-sourcepos=\"100:1-101:0\">パース処理がタイトル案セクションをスキップできていなかった</li>\n</ul>\n<p data-sourcepos=\"102:1-102:14\"><strong>解決策</strong>:</p>\n<div class=\"code-frame\" data-lang=\"markdown\" data-sourcepos=\"103:1-108:3\"><div class=\"highlight\"><pre><code><span class=\"gh\"># プロンプトの修正</span>\n<span class=\"gs\">**重要**</span>: 記事の最初の行に、実際に使用するタイトルを<span class=\"sb\">`# `</span>で始まるMarkdownの見出し形式で記述してください。\n\nタイトル案は不要です。最初の<span class=\"sb\">`# `</span>行がそのまま記事のタイトルとして使用されます。\n</code></pre></div></div>\n<div class=\"code-frame\" data-lang=\"python\" data-sourcepos=\"110:1-123:3\"><div class=\"highlight\"><pre><code><span class=\"c1\"># パース処理の改善\n</span><span class=\"n\">skip_title_section</span> <span class=\"o\">=</span> <span class=\"bp\">False</span>\n<span class=\"k\">for</span> <span class=\"n\">line</span> <span class=\"ow\">in</span> <span class=\"n\">lines</span><span class=\"p\">:</span>\n    <span class=\"c1\"># タイトル案セクションを検出してスキップ\n</span>    <span class=\"k\">if</span> <span class=\"sh\">\"</span><span class=\"s\">タイトル案</span><span class=\"sh\">\"</span> <span class=\"ow\">in</span> <span class=\"n\">line</span><span class=\"p\">:</span>\n        <span class=\"n\">skip_title_section</span> <span class=\"o\">=</span> <span class=\"bp\">True</span>\n        <span class=\"k\">continue</span>\n    \n    <span class=\"c1\"># 最初の`# `で始まる行をタイトルとして取得\n</span>    <span class=\"k\">if</span> <span class=\"ow\">not</span> <span class=\"n\">found_main_title</span> <span class=\"ow\">and</span> <span class=\"n\">line</span><span class=\"p\">.</span><span class=\"nf\">startswith</span><span class=\"p\">(</span><span class=\"sh\">\"</span><span class=\"s\"># </span><span class=\"sh\">\"</span><span class=\"p\">):</span>\n        <span class=\"n\">title</span> <span class=\"o\">=</span> <span class=\"n\">line</span><span class=\"p\">.</span><span class=\"nf\">replace</span><span class=\"p\">(</span><span class=\"sh\">\"</span><span class=\"s\"># </span><span class=\"sh\">\"</span><span class=\"p\">,</span> <span class=\"sh\">\"\"</span><span class=\"p\">).</span><span class=\"nf\">strip</span><span class=\"p\">()</span>\n        <span class=\"n\">found_main_title</span> <span class=\"o\">=</span> <span class=\"bp\">True</span>\n</code></pre></div></div>\n<p data-sourcepos=\"125:1-125:21\"><strong>学んだこと</strong>:</p>\n<ul data-sourcepos=\"126:1-128:0\">\n<li data-sourcepos=\"126:1-126:65\">LLMへのプロンプトは明確で具体的な指示が必要</li>\n<li data-sourcepos=\"127:1-128:0\">出力形式を厳密に指定することで、パース処理を簡潔にできる</li>\n</ul>\n<h3 data-sourcepos=\"129:1-129:43\">\n<span id=\"5-エラーハンドリングの不足\" class=\"fragment\"></span><a href=\"#5-%E3%82%A8%E3%83%A9%E3%83%BC%E3%83%8F%E3%83%B3%E3%83%89%E3%83%AA%E3%83%B3%E3%82%B0%E3%81%AE%E4%B8%8D%E8%B6%B3\"><i class=\"fa fa-link\"></i></a>5. エラーハンドリングの不足</h3>\n<p data-sourcepos=\"131:1-131:12\"><strong>問題</strong>:</p>\n<ul data-sourcepos=\"132:1-134:0\">\n<li data-sourcepos=\"132:1-132:68\">403エラーが発生した際、原因が特定しづらかった</li>\n<li data-sourcepos=\"133:1-134:0\">デバッグ情報が不足していた</li>\n</ul>\n<p data-sourcepos=\"135:1-135:14\"><strong>解決策</strong>:</p>\n<div class=\"code-frame\" data-lang=\"python\" data-sourcepos=\"136:1-152:3\"><div class=\"highlight\"><pre><code><span class=\"c1\"># デバッグ情報の追加\n</span><span class=\"nf\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"sh\">\"</span><span class=\"s\">[DEBUG] アクセストークン: </span><span class=\"si\">{</span><span class=\"n\">token_preview</span><span class=\"si\">}</span><span class=\"sh\">\"</span><span class=\"p\">)</span>\n<span class=\"nf\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"sh\">\"</span><span class=\"s\">[DEBUG] リクエストURL: </span><span class=\"si\">{</span><span class=\"n\">self</span><span class=\"p\">.</span><span class=\"n\">base_url</span><span class=\"si\">}</span><span class=\"s\">/items</span><span class=\"sh\">\"</span><span class=\"p\">)</span>\n<span class=\"nf\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"sh\">\"</span><span class=\"s\">[DEBUG] ペイロード: title=</span><span class=\"si\">{</span><span class=\"n\">title</span><span class=\"p\">[</span><span class=\"si\">:</span><span class=\"mi\">50</span><span class=\"p\">]</span><span class=\"si\">}</span><span class=\"s\">, tags=</span><span class=\"si\">{</span><span class=\"nf\">len</span><span class=\"p\">(</span><span class=\"n\">tags</span><span class=\"p\">)</span><span class=\"si\">}</span><span class=\"s\">個</span><span class=\"sh\">\"</span><span class=\"p\">)</span>\n<span class=\"nf\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"sh\">\"</span><span class=\"s\">[DEBUG] レスポンスステータス: </span><span class=\"si\">{</span><span class=\"n\">response</span><span class=\"p\">.</span><span class=\"n\">status_code</span><span class=\"si\">}</span><span class=\"sh\">\"</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># エラーメッセージの改善\n</span><span class=\"k\">if</span> <span class=\"n\">e</span><span class=\"p\">.</span><span class=\"n\">response</span><span class=\"p\">.</span><span class=\"n\">status_code</span> <span class=\"o\">==</span> <span class=\"mi\">403</span><span class=\"p\">:</span>\n    <span class=\"n\">error_msg</span> <span class=\"o\">+=</span> <span class=\"sh\">\"</span><span class=\"s\">\n\n考えられる原因:</span><span class=\"sh\">\"</span>\n    <span class=\"n\">error_msg</span> <span class=\"o\">+=</span> <span class=\"sh\">\"</span><span class=\"s\">\n- アクセストークンのスコープが不足しています</span><span class=\"sh\">\"</span>\n    <span class=\"n\">error_msg</span> <span class=\"o\">+=</span> <span class=\"sh\">\"</span><span class=\"s\">\n- タグ数が5個を超えています（Qiita APIの制限）</span><span class=\"sh\">\"</span>\n</code></pre></div></div>\n<p data-sourcepos=\"154:1-154:21\"><strong>学んだこと</strong>:</p>\n<ul data-sourcepos=\"155:1-157:0\">\n<li data-sourcepos=\"155:1-155:98\">エラー発生時には、リクエスト内容とレスポンスを詳細にログ出力する</li>\n<li data-sourcepos=\"156:1-157:0\">よくあるエラーについては、解決策を提示する</li>\n</ul>\n<h2 data-sourcepos=\"158:1-158:27\">\n<span id=\"工夫したポイント\" class=\"fragment\"></span><a href=\"#%E5%B7%A5%E5%A4%AB%E3%81%97%E3%81%9F%E3%83%9D%E3%82%A4%E3%83%B3%E3%83%88\"><i class=\"fa fa-link\"></i></a>工夫したポイント</h2>\n<h3 data-sourcepos=\"160:1-160:40\">\n<span id=\"1-プロンプト管理システム\" class=\"fragment\"></span><a href=\"#1-%E3%83%97%E3%83%AD%E3%83%B3%E3%83%97%E3%83%88%E7%AE%A1%E7%90%86%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0\"><i class=\"fa fa-link\"></i></a>1. プロンプト管理システム</h3>\n<p data-sourcepos=\"162:1-162:83\">プロンプトをMarkdownファイルとして管理し、変数置換に対応：</p>\n<div class=\"code-frame\" data-lang=\"python\" data-sourcepos=\"164:1-176:3\"><div class=\"highlight\"><pre><code><span class=\"c1\"># data/prompts/article_generation_prompt.md\n</span><span class=\"n\">トピック</span><span class=\"p\">:</span> <span class=\"p\">{</span><span class=\"n\">topic</span><span class=\"p\">}</span>\n<span class=\"n\">リサーチ結果</span><span class=\"p\">:</span> <span class=\"p\">{</span><span class=\"n\">research_results</span><span class=\"p\">}</span>\n<span class=\"n\">過去の投稿</span><span class=\"p\">:</span> <span class=\"p\">{</span><span class=\"n\">past_articles_summary</span><span class=\"p\">}</span>\n\n<span class=\"c1\"># 使用例\n</span><span class=\"n\">prompt</span> <span class=\"o\">=</span> <span class=\"n\">template</span><span class=\"p\">.</span><span class=\"nf\">format</span><span class=\"p\">(</span>\n    <span class=\"n\">topic</span><span class=\"o\">=</span><span class=\"n\">selected_topic</span><span class=\"p\">,</span>\n    <span class=\"n\">research_results</span><span class=\"o\">=</span><span class=\"n\">research_results</span><span class=\"p\">,</span>\n    <span class=\"n\">past_articles_summary</span><span class=\"o\">=</span><span class=\"n\">past_articles_summary</span>\n<span class=\"p\">)</span>\n</code></pre></div></div>\n<p data-sourcepos=\"178:1-178:18\"><strong>メリット</strong>:</p>\n<ul data-sourcepos=\"179:1-182:0\">\n<li data-sourcepos=\"179:1-179:35\">プロンプトの変更が容易</li>\n<li data-sourcepos=\"180:1-180:38\">バージョン管理がしやすい</li>\n<li data-sourcepos=\"181:1-182:0\">複数のプロンプトを管理できる</li>\n</ul>\n<h3 data-sourcepos=\"183:1-183:34\">\n<span id=\"2-過去の投稿参照機能\" class=\"fragment\"></span><a href=\"#2-%E9%81%8E%E5%8E%BB%E3%81%AE%E6%8A%95%E7%A8%BF%E5%8F%82%E7%85%A7%E6%A9%9F%E8%83%BD\"><i class=\"fa fa-link\"></i></a>2. 過去の投稿参照機能</h3>\n<p data-sourcepos=\"185:1-185:80\">過去のQiita投稿を取得し、ストーリー性のある記事を生成：</p>\n<div class=\"code-frame\" data-lang=\"python\" data-sourcepos=\"187:1-194:3\"><div class=\"highlight\"><pre><code><span class=\"c1\"># 過去の投稿を取得\n</span><span class=\"n\">fetcher</span> <span class=\"o\">=</span> <span class=\"nc\">QiitaFetcher</span><span class=\"p\">()</span>\n<span class=\"n\">items</span> <span class=\"o\">=</span> <span class=\"n\">fetcher</span><span class=\"p\">.</span><span class=\"nf\">fetch_all_my_items</span><span class=\"p\">(</span><span class=\"n\">days_back</span><span class=\"o\">=</span><span class=\"mi\">180</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># 記事生成時に参照\n</span><span class=\"n\">past_articles_summary</span> <span class=\"o\">=</span> <span class=\"n\">qiita_items_manager</span><span class=\"p\">.</span><span class=\"nf\">get_items_summary</span><span class=\"p\">(</span><span class=\"n\">limit</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">)</span>\n</code></pre></div></div>\n<p data-sourcepos=\"196:1-196:18\"><strong>メリット</strong>:</p>\n<ul data-sourcepos=\"197:1-200:0\">\n<li data-sourcepos=\"197:1-197:56\">連続性のある記事シリーズを構築できる</li>\n<li data-sourcepos=\"198:1-198:62\">読者が「次も読みたい」と思える内容になる</li>\n<li data-sourcepos=\"199:1-200:0\">過去の投稿への参照リンクを自動生成</li>\n</ul>\n<h3 data-sourcepos=\"201:1-201:25\">\n<span id=\"3-動的タグ生成\" class=\"fragment\"></span><a href=\"#3-%E5%8B%95%E7%9A%84%E3%82%BF%E3%82%B0%E7%94%9F%E6%88%90\"><i class=\"fa fa-link\"></i></a>3. 動的タグ生成</h3>\n<p data-sourcepos=\"203:1-203:60\">記事内容に応じてLLMが自動的にタグを生成：</p>\n<div class=\"code-frame\" data-lang=\"python\" data-sourcepos=\"205:1-210:3\"><div class=\"highlight\"><pre><code><span class=\"k\">def</span> <span class=\"nf\">generate_dynamic_tags</span><span class=\"p\">(</span><span class=\"n\">title</span><span class=\"p\">:</span> <span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">content</span><span class=\"p\">:</span> <span class=\"nb\">str</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]:</span>\n    <span class=\"c1\"># 記事のタイトルと内容を分析してタグを生成\n</span>    <span class=\"c1\"># 言語・ツール系、目的・行為ベース、プラットフォーム系など\n</span>    <span class=\"c1\"># カテゴリから適切なタグを選ぶ\n</span></code></pre></div></div>\n<p data-sourcepos=\"212:1-212:18\"><strong>メリット</strong>:</p>\n<ul data-sourcepos=\"213:1-216:0\">\n<li data-sourcepos=\"213:1-213:56\">記事内容に最適なタグが自動生成される</li>\n<li data-sourcepos=\"214:1-214:35\">手動でのタグ付けが不要</li>\n<li data-sourcepos=\"215:1-216:0\">タグの漏れを防げる</li>\n</ul>\n<h3 data-sourcepos=\"217:1-217:55\">\n<span id=\"4-モジュール化とエラーハンドリング\" class=\"fragment\"></span><a href=\"#4-%E3%83%A2%E3%82%B8%E3%83%A5%E3%83%BC%E3%83%AB%E5%8C%96%E3%81%A8%E3%82%A8%E3%83%A9%E3%83%BC%E3%83%8F%E3%83%B3%E3%83%89%E3%83%AA%E3%83%B3%E3%82%B0\"><i class=\"fa fa-link\"></i></a>4. モジュール化とエラーハンドリング</h3>\n<p data-sourcepos=\"219:1-219:93\">各機能を独立したモジュールに分割し、エラーハンドリングを強化：</p>\n<div class=\"code-frame\" data-lang=\"python\" data-sourcepos=\"221:1-227:3\"><div class=\"highlight\"><pre><code><span class=\"c1\"># 各モジュールが独立して動作\n</span><span class=\"o\">-</span> <span class=\"n\">research</span><span class=\"o\">/</span><span class=\"n\">collector</span><span class=\"p\">.</span><span class=\"n\">py</span>      <span class=\"c1\"># リサーチ機能\n</span><span class=\"o\">-</span> <span class=\"n\">generator</span><span class=\"o\">/</span><span class=\"n\">article_generator</span><span class=\"p\">.</span><span class=\"n\">py</span>  <span class=\"c1\"># 記事生成\n</span><span class=\"o\">-</span> <span class=\"n\">publisher</span><span class=\"o\">/</span><span class=\"n\">qiita_publisher</span><span class=\"p\">.</span><span class=\"n\">py</span>    <span class=\"c1\"># 投稿機能\n</span><span class=\"o\">-</span> <span class=\"n\">storage</span><span class=\"o\">/</span><span class=\"n\">article_manager</span><span class=\"p\">.</span><span class=\"n\">py</span>      <span class=\"c1\"># 記事管理\n</span></code></pre></div></div>\n<p data-sourcepos=\"229:1-229:18\"><strong>メリット</strong>:</p>\n<ul data-sourcepos=\"230:1-233:0\">\n<li data-sourcepos=\"230:1-230:20\">テストが容易</li>\n<li data-sourcepos=\"231:1-231:35\">機能の追加・変更が容易</li>\n<li data-sourcepos=\"232:1-233:0\">エラーの影響範囲を限定できる</li>\n</ul>\n<h2 data-sourcepos=\"234:1-234:15\">\n<span id=\"参考文献\" class=\"fragment\"></span><a href=\"#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE\"><i class=\"fa fa-link\"></i></a>参考文献</h2>\n<ul data-sourcepos=\"236:1-250:0\">\n<li data-sourcepos=\"236:1-238:0\">\n<p data-sourcepos=\"236:3-236:66\"><a href=\"https://qiita.com/api/v2/docs\">Qiita API v2 ドキュメント</a></p>\n<ul data-sourcepos=\"237:3-238:0\">\n<li data-sourcepos=\"237:3-238:0\">タグの制限（最大5個）などの仕様を確認</li>\n</ul>\n</li>\n<li data-sourcepos=\"239:1-241:0\">\n<p data-sourcepos=\"239:3-239:68\"><a href=\"https://ai.google.dev/docs\" rel=\"nofollow noopener\" target=\"_blank\">Google Gemini API ドキュメント</a></p>\n<ul data-sourcepos=\"240:3-241:0\">\n<li data-sourcepos=\"240:3-241:0\">利用可能なモデル一覧とAPIの使い方</li>\n</ul>\n</li>\n<li data-sourcepos=\"242:1-244:0\">\n<p data-sourcepos=\"242:3-242:69\"><a href=\"https://requests.readthedocs.io/\" rel=\"nofollow noopener\" target=\"_blank\">Python requests ライブラリ</a></p>\n<ul data-sourcepos=\"243:3-244:0\">\n<li data-sourcepos=\"243:3-244:0\">HTTPリクエストのエラーハンドリング方法</li>\n</ul>\n</li>\n<li data-sourcepos=\"245:1-247:0\">\n<p data-sourcepos=\"245:3-245:80\"><a href=\"https://github.com/theskumar/python-dotenv\" rel=\"nofollow noopener\" target=\"_blank\">python-dotenv ドキュメント</a></p>\n<ul data-sourcepos=\"246:3-247:0\">\n<li data-sourcepos=\"246:3-247:0\">環境変数の管理方法</li>\n</ul>\n</li>\n<li data-sourcepos=\"248:1-250:0\">\n<p data-sourcepos=\"248:3-248:105\"><a href=\"https://qiita.com/iimuz/items/4837e9c8043ce7c1262b\" id=\"reference-999283c181ac8b919d7c\">Qiita API を利用した記事投稿の実装例</a></p>\n<ul data-sourcepos=\"249:3-250:0\">\n<li data-sourcepos=\"249:3-250:0\">アクセストークンの取得方法と投稿の実装</li>\n</ul>\n</li>\n</ul>\n<h2 data-sourcepos=\"251:1-251:12\">\n<span id=\"まとめ\" class=\"fragment\"></span><a href=\"#%E3%81%BE%E3%81%A8%E3%82%81\"><i class=\"fa fa-link\"></i></a>まとめ</h2>\n<p data-sourcepos=\"253:1-253:63\">今回の開発を通じて、以下の点を学びました：</p>\n<ol data-sourcepos=\"255:1-260:0\">\n<li data-sourcepos=\"255:1-255:114\">\n<strong>APIの仕様を事前に確認する重要性</strong>: タグ数の制限など、APIの制約を理解しておく</li>\n<li data-sourcepos=\"256:1-256:114\">\n<strong>エラーハンドリングの重要性</strong>: デバッグ情報を充実させ、原因特定を容易にする</li>\n<li data-sourcepos=\"257:1-257:87\">\n<strong>プロンプト設計の重要性</strong>: LLMへの指示は明確で具体的にする</li>\n<li data-sourcepos=\"258:1-258:85\">\n<strong>クロスプラットフォーム対応</strong>: Unicode文字の使用に注意する</li>\n<li data-sourcepos=\"259:1-260:0\">\n<strong>モジュール化の重要性</strong>: 機能を分割し、テストとメンテナンスを容易にする</li>\n</ol>\n<p data-sourcepos=\"261:1-261:108\">これらの経験を活かして、より堅牢なシステムを構築していきたいと思います。</p>\n<h2 data-sourcepos=\"265:1-265:50\">\n<span id=\"-導入背景課題なぜ重要か\" class=\"fragment\"></span><a href=\"#-%E5%B0%8E%E5%85%A5%E8%83%8C%E6%99%AF%E8%AA%B2%E9%A1%8C%E3%81%AA%E3%81%9C%E9%87%8D%E8%A6%81%E3%81%8B\"><i class=\"fa fa-link\"></i></a>🧭 導入：背景・課題・なぜ重要か</h2>\n<p data-sourcepos=\"267:1-267:45\">「記事書くの、めんどくさい…」</p>\n<p data-sourcepos=\"269:1-269:295\">エンジニアなら誰しも一度は思ったことがあるのではないでしょうか？特に Qiita のような技術情報共有プラットフォームでは、継続的なアウトプットが重要だと分かっていても、ついつい後回しにしてしまいがちです。</p>\n<p data-sourcepos=\"271:1-271:369\">以前の記事「<a href=\"https://qiita.com/cocokara_bioinfo/items/7440c80d8e6a98177957\">Python × GitHub Actions で始める！Qiita 自動投稿パイプライン構築術</a>」では、Qiita への記事投稿を自動化する基本的なパイプラインを構築しました。しかし、実際に運用してみると、いくつかの課題が見えてきました。</p>\n<ul data-sourcepos=\"273:1-276:0\">\n<li data-sourcepos=\"273:1-273:152\">\n<strong>ローカル環境との差異</strong>: ローカルで動いていたスクリプトが GitHub Actions 上で動かない…あるあるですよね。</li>\n<li data-sourcepos=\"274:1-274:148\">\n<strong>エラーハンドリングの甘さ</strong>: エラーが発生した場合に、どこが原因なのか特定しにくい…デバッグ地獄！</li>\n<li data-sourcepos=\"275:1-276:0\">\n<strong>API レート制限</strong>: Qiita API のレート制限に引っかかって投稿が失敗する…焦る！</li>\n</ul>\n<p data-sourcepos=\"277:1-277:340\">これらの課題を解決し、より安定した自動投稿パイプラインを構築するために、試行錯誤した過程を共有したいと思います。今回の記事では、これらの <strong>“あるある” な課題</strong> に焦点を当て、具体的な解決策と、さらに効率的な運用方法を紹介します。</p>\n<h2 data-sourcepos=\"279:1-279:65\">\n<span id=\"-トピックの概要専門外にも分かる説明\" class=\"fragment\"></span><a href=\"#-%E3%83%88%E3%83%94%E3%83%83%E3%82%AF%E3%81%AE%E6%A6%82%E8%A6%81%E5%B0%82%E9%96%80%E5%A4%96%E3%81%AB%E3%82%82%E5%88%86%E3%81%8B%E3%82%8B%E8%AA%AC%E6%98%8E\"><i class=\"fa fa-link\"></i></a>📘 トピックの概要（専門外にも分かる説明）</h2>\n<p data-sourcepos=\"281:1-281:89\">今回のテーマは、<strong>Qiita 記事の自動投稿パイプライン構築</strong> です。</p>\n<p data-sourcepos=\"283:1-283:164\"><strong>パイプライン</strong> とは、一連の処理を自動的に実行する仕組みのことです。今回の場合は、以下のような流れになります。</p>\n<ol data-sourcepos=\"285:1-288:0\">\n<li data-sourcepos=\"285:1-285:69\">記事の Markdown ファイルを GitHub リポジトリに push</li>\n<li data-sourcepos=\"286:1-286:79\">GitHub Actions が push を検知して自動的にスクリプトを実行</li>\n<li data-sourcepos=\"287:1-288:0\">スクリプトが Qiita API を利用して記事を投稿</li>\n</ol>\n<p data-sourcepos=\"289:1-289:153\">このパイプラインを構築することで、記事を書いたら GitHub に push するだけで Qiita に投稿されるようになります。</p>\n<p data-sourcepos=\"291:1-291:81\">今回の記事では、特に以下の点に焦点を当てて解説します。</p>\n<ul data-sourcepos=\"293:1-296:0\">\n<li data-sourcepos=\"293:1-293:102\">\n<strong>環境構築</strong>: GitHub Actions 上で Python スクリプトを実行するための環境構築</li>\n<li data-sourcepos=\"294:1-294:121\">\n<strong>エラーハンドリング</strong>: エラーが発生した場合に、原因を特定しやすくするための工夫</li>\n<li data-sourcepos=\"295:1-296:0\">\n<strong>レート制限対策</strong>: Qiita API のレート制限に引っかからないようにするための対策</li>\n</ul>\n<h2 data-sourcepos=\"297:1-297:62\">\n<span id=\"-技術的な仕組み実装アーキテクチャ\" class=\"fragment\"></span><a href=\"#-%E6%8A%80%E8%A1%93%E7%9A%84%E3%81%AA%E4%BB%95%E7%B5%84%E3%81%BF%E5%AE%9F%E8%A3%85%E3%82%A2%E3%83%BC%E3%82%AD%E3%83%86%E3%82%AF%E3%83%81%E3%83%A3\"><i class=\"fa fa-link\"></i></a>🔧 技術的な仕組み・実装・アーキテクチャ</h2>\n<p data-sourcepos=\"299:1-299:84\">今回のパイプラインは、主に以下の要素で構成されています。</p>\n<ol data-sourcepos=\"301:1-304:0\">\n<li data-sourcepos=\"301:1-301:93\">\n<strong>Python スクリプト</strong>: Qiita API を利用して記事を投稿するスクリプト</li>\n<li data-sourcepos=\"302:1-302:109\">\n<strong>GitHub Actions</strong>: GitHub の CI/CD サービス。push をトリガーにしてスクリプトを実行</li>\n<li data-sourcepos=\"303:1-304:0\">\n<strong>Qiita API</strong>: Qiita の記事投稿 API</li>\n</ol>\n<p data-sourcepos=\"305:1-305:151\"><strong>Python スクリプト</strong> は、Markdown ファイルを読み込み、Qiita API に必要な情報を整形してリクエストを送信します。</p>\n<p data-sourcepos=\"307:1-307:287\"><strong>GitHub Actions</strong> は、<code>.github/workflows</code> ディレクトリに YAML ファイルを配置することで、様々なイベントをトリガーにして処理を実行できます。今回は、<code>push</code> イベントをトリガーにして、Python スクリプトを実行します。</p>\n<p data-sourcepos=\"309:1-309:207\"><strong>Qiita API</strong> は、記事の投稿、更新、削除などを行うための API です。API を利用するためには、事前に Qiita でアクセストークンを取得する必要があります。</p>\n<h3 data-sourcepos=\"311:1-311:34\">\n<span id=\"メリットデメリット\" class=\"fragment\"></span><a href=\"#%E3%83%A1%E3%83%AA%E3%83%83%E3%83%88%E3%83%87%E3%83%A1%E3%83%AA%E3%83%83%E3%83%88\"><i class=\"fa fa-link\"></i></a>メリット・デメリット</h3>\n<p data-sourcepos=\"313:1-313:17\"><strong>メリット</strong>:</p>\n<ul data-sourcepos=\"315:1-318:0\">\n<li data-sourcepos=\"315:1-315:52\">記事投稿の手間を大幅に削減できる</li>\n<li data-sourcepos=\"316:1-316:52\">継続的なアウトプットを促進できる</li>\n<li data-sourcepos=\"317:1-318:0\">チームでの記事作成を効率化できる</li>\n</ul>\n<p data-sourcepos=\"319:1-319:20\"><strong>デメリット</strong>:</p>\n<ul data-sourcepos=\"321:1-324:0\">\n<li data-sourcepos=\"321:1-321:37\">初期構築に手間がかかる</li>\n<li data-sourcepos=\"322:1-322:56\">API のレート制限に注意する必要がある</li>\n<li data-sourcepos=\"323:1-324:0\">スクリプトのメンテナンスが必要</li>\n</ul>\n<h3 data-sourcepos=\"325:1-325:37\">\n<span id=\"ハマりポイント注意点\" class=\"fragment\"></span><a href=\"#%E3%83%8F%E3%83%9E%E3%82%8A%E3%83%9D%E3%82%A4%E3%83%B3%E3%83%88%E6%B3%A8%E6%84%8F%E7%82%B9\"><i class=\"fa fa-link\"></i></a>ハマりポイント・注意点</h3>\n<ul data-sourcepos=\"327:1-330:0\">\n<li data-sourcepos=\"327:1-327:85\">\n<strong>環境変数</strong>: GitHub Actions 上で環境変数を設定する必要がある</li>\n<li data-sourcepos=\"328:1-328:107\">\n<strong>依存関係</strong>: 必要な Python ライブラリを <code>requirements.txt</code> に記述する必要がある</li>\n<li data-sourcepos=\"329:1-330:0\">\n<strong>エラーハンドリング</strong>: エラーが発生した場合に、原因を特定できるようにログを出力するようにする</li>\n</ul>\n<h2 data-sourcepos=\"331:1-331:53\">\n<span id=\"-実践編動くコードコマンド例\" class=\"fragment\"></span><a href=\"#-%E5%AE%9F%E8%B7%B5%E7%B7%A8%E5%8B%95%E3%81%8F%E3%82%B3%E3%83%BC%E3%83%89%E3%82%B3%E3%83%9E%E3%83%B3%E3%83%89%E4%BE%8B\"><i class=\"fa fa-link\"></i></a>🧪 実践編：動くコード／コマンド例</h2>\n<h3 data-sourcepos=\"333:1-333:19\">\n<span id=\"1-環境構築\" class=\"fragment\"></span><a href=\"#1-%E7%92%B0%E5%A2%83%E6%A7%8B%E7%AF%89\"><i class=\"fa fa-link\"></i></a>1. 環境構築</h3>\n<p data-sourcepos=\"335:1-335:74\">まず、必要な Python ライブラリをインストールします。</p>\n<div class=\"code-frame\" data-lang=\"bash\" data-sourcepos=\"337:1-340:3\"><div class=\"highlight\"><pre><code><span class=\"c\"># 必要なライブラリをインストール</span>\npip <span class=\"nb\">install </span>requests python-dotenv\n</code></pre></div></div>\n<p data-sourcepos=\"342:1-342:133\">次に、GitHub リポジトリに <code>.github/workflows/qiita_post.yml</code> ファイルを作成し、以下の内容を記述します。</p>\n<div class=\"code-frame\" data-lang=\"yaml\" data-sourcepos=\"344:1-369:3\"><div class=\"highlight\"><pre><code><span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">Qiita Post</span>\n\n<span class=\"na\">on</span><span class=\"pi\">:</span>\n  <span class=\"na\">push</span><span class=\"pi\">:</span>\n    <span class=\"na\">branches</span><span class=\"pi\">:</span>\n      <span class=\"pi\">-</span> <span class=\"s\">main</span>\n\n<span class=\"na\">jobs</span><span class=\"pi\">:</span>\n  <span class=\"na\">qiita_post</span><span class=\"pi\">:</span>\n    <span class=\"na\">runs-on</span><span class=\"pi\">:</span> <span class=\"s\">ubuntu-latest</span>\n    <span class=\"na\">steps</span><span class=\"pi\">:</span>\n      <span class=\"pi\">-</span> <span class=\"na\">uses</span><span class=\"pi\">:</span> <span class=\"s\">actions/checkout@v3</span>\n      <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">Set up Python </span><span class=\"m\">3.11</span>\n        <span class=\"na\">uses</span><span class=\"pi\">:</span> <span class=\"s\">actions/setup-python@v3</span>\n        <span class=\"na\">with</span><span class=\"pi\">:</span>\n          <span class=\"na\">python-version</span><span class=\"pi\">:</span> <span class=\"s2\">\"</span><span class=\"s\">3.11\"</span>\n      <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">Install dependencies</span>\n        <span class=\"na\">run</span><span class=\"pi\">:</span> <span class=\"pi\">|</span>\n          <span class=\"s\">python -m pip install --upgrade pip</span>\n          <span class=\"s\">pip install -r requirements.txt</span>\n      <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">Run Qiita Post Script</span>\n        <span class=\"na\">env</span><span class=\"pi\">:</span>\n          <span class=\"na\">QIITA_ACCESS_TOKEN</span><span class=\"pi\">:</span> <span class=\"s\">${{ secrets.QIITA_ACCESS_TOKEN }}</span>\n        <span class=\"na\">run</span><span class=\"pi\">:</span> <span class=\"s\">python qiita_post.py</span>\n</code></pre></div></div>\n<p data-sourcepos=\"371:1-371:100\"><code>QIITA_ACCESS_TOKEN</code> は、GitHub リポジトリの Secrets に登録する必要があります。</p>\n<h3 data-sourcepos=\"373:1-373:29\">\n<span id=\"2-python-スクリプト\" class=\"fragment\"></span><a href=\"#2-python-%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%97%E3%83%88\"><i class=\"fa fa-link\"></i></a>2. Python スクリプト</h3>\n<p data-sourcepos=\"375:1-375:88\">次に、<code>qiita_post.py</code> ファイルを作成し、以下の内容を記述します。</p>\n<div class=\"code-frame\" data-lang=\"python\" data-sourcepos=\"377:1-434:134\"><div class=\"highlight\"><pre><code><span class=\"kn\">import</span> <span class=\"n\">os</span>\n<span class=\"kn\">import</span> <span class=\"n\">requests</span>\n<span class=\"kn\">from</span> <span class=\"n\">dotenv</span> <span class=\"kn\">import</span> <span class=\"n\">load_dotenv</span>\n\n<span class=\"nf\">load_dotenv</span><span class=\"p\">()</span>\n\n<span class=\"n\">QIITA_ACCESS_TOKEN</span> <span class=\"o\">=</span> <span class=\"n\">os</span><span class=\"p\">.</span><span class=\"n\">environ</span><span class=\"p\">.</span><span class=\"nf\">get</span><span class=\"p\">(</span><span class=\"sh\">\"</span><span class=\"s\">QIITA_ACCESS_TOKEN</span><span class=\"sh\">\"</span><span class=\"p\">)</span>\n<span class=\"n\">QIITA_API_ENDPOINT</span> <span class=\"o\">=</span> <span class=\"sh\">\"</span><span class=\"s\">https://qiita.com/api/v2/items</span><span class=\"sh\">\"</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">post_to_qiita</span><span class=\"p\">(</span><span class=\"n\">markdown_file_path</span><span class=\"p\">):</span>\n    <span class=\"sh\">\"\"\"</span><span class=\"s\">Qiita に記事を投稿する関数</span><span class=\"sh\">\"\"\"</span>\n    <span class=\"k\">try</span><span class=\"p\">:</span>\n        <span class=\"k\">with</span> <span class=\"nf\">open</span><span class=\"p\">(</span><span class=\"n\">markdown_file_path</span><span class=\"p\">,</span> <span class=\"sh\">\"</span><span class=\"s\">r</span><span class=\"sh\">\"</span><span class=\"p\">,</span> <span class=\"n\">encoding</span><span class=\"o\">=</span><span class=\"sh\">\"</span><span class=\"s\">utf-8</span><span class=\"sh\">\"</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">f</span><span class=\"p\">:</span>\n            <span class=\"n\">markdown_content</span> <span class=\"o\">=</span> <span class=\"n\">f</span><span class=\"p\">.</span><span class=\"nf\">read</span><span class=\"p\">()</span>\n\n        <span class=\"c1\"># タイトルを抽出 (最初の行が # で始まる場合)\n</span>        <span class=\"n\">lines</span> <span class=\"o\">=</span> <span class=\"n\">markdown_content</span><span class=\"p\">.</span><span class=\"nf\">splitlines</span><span class=\"p\">()</span>\n        <span class=\"n\">title</span> <span class=\"o\">=</span> <span class=\"n\">lines</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">].</span><span class=\"nf\">replace</span><span class=\"p\">(</span><span class=\"sh\">\"</span><span class=\"s\"># </span><span class=\"sh\">\"</span><span class=\"p\">,</span> <span class=\"sh\">\"\"</span><span class=\"p\">)</span> <span class=\"k\">if</span> <span class=\"n\">lines</span> <span class=\"ow\">and</span> <span class=\"n\">lines</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">].</span><span class=\"nf\">startswith</span><span class=\"p\">(</span><span class=\"sh\">\"</span><span class=\"s\"># </span><span class=\"sh\">\"</span><span class=\"p\">)</span> <span class=\"k\">else</span> <span class=\"sh\">\"</span><span class=\"s\">No Title</span><span class=\"sh\">\"</span>\n\n        <span class=\"c1\"># Markdown ファイルから必要な情報を抽出\n</span>        <span class=\"n\">body</span> <span class=\"o\">=</span> <span class=\"n\">markdown_content</span>\n        <span class=\"n\">tags</span> <span class=\"o\">=</span> <span class=\"nf\">extract_tags</span><span class=\"p\">(</span><span class=\"n\">markdown_content</span><span class=\"p\">)</span> <span class=\"c1\"># タグを抽出する関数は別途定義\n</span>\n        <span class=\"c1\"># Qiita API に投稿\n</span>        <span class=\"n\">headers</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n            <span class=\"sh\">\"</span><span class=\"s\">Authorization</span><span class=\"sh\">\"</span><span class=\"p\">:</span> <span class=\"sa\">f</span><span class=\"sh\">\"</span><span class=\"s\">Bearer </span><span class=\"si\">{</span><span class=\"n\">QIITA_ACCESS_TOKEN</span><span class=\"si\">}</span><span class=\"sh\">\"</span><span class=\"p\">,</span>\n            <span class=\"sh\">\"</span><span class=\"s\">Content-Type</span><span class=\"sh\">\"</span><span class=\"p\">:</span> <span class=\"sh\">\"</span><span class=\"s\">application/json</span><span class=\"sh\">\"</span><span class=\"p\">,</span>\n        <span class=\"p\">}</span>\n        <span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n            <span class=\"sh\">\"</span><span class=\"s\">title</span><span class=\"sh\">\"</span><span class=\"p\">:</span> <span class=\"n\">title</span><span class=\"p\">,</span>\n            <span class=\"sh\">\"</span><span class=\"s\">body</span><span class=\"sh\">\"</span><span class=\"p\">:</span> <span class=\"n\">body</span><span class=\"p\">,</span>\n            <span class=\"sh\">\"</span><span class=\"s\">tags</span><span class=\"sh\">\"</span><span class=\"p\">:</span> <span class=\"p\">[{</span><span class=\"sh\">\"</span><span class=\"s\">name</span><span class=\"sh\">\"</span><span class=\"p\">:</span> <span class=\"n\">tag</span><span class=\"p\">}</span> <span class=\"k\">for</span> <span class=\"n\">tag</span> <span class=\"ow\">in</span> <span class=\"n\">tags</span><span class=\"p\">],</span>\n            <span class=\"sh\">\"</span><span class=\"s\">private</span><span class=\"sh\">\"</span><span class=\"p\">:</span> <span class=\"bp\">False</span><span class=\"p\">,</span>  <span class=\"c1\"># 公開設定\n</span>        <span class=\"p\">}</span>\n        <span class=\"n\">response</span> <span class=\"o\">=</span> <span class=\"n\">requests</span><span class=\"p\">.</span><span class=\"nf\">post</span><span class=\"p\">(</span><span class=\"n\">QIITA_API_ENDPOINT</span><span class=\"p\">,</span> <span class=\"n\">headers</span><span class=\"o\">=</span><span class=\"n\">headers</span><span class=\"p\">,</span> <span class=\"n\">json</span><span class=\"o\">=</span><span class=\"n\">data</span><span class=\"p\">)</span>\n\n        <span class=\"c1\"># レスポンスを確認\n</span>        <span class=\"n\">response</span><span class=\"p\">.</span><span class=\"nf\">raise_for_status</span><span class=\"p\">()</span>  <span class=\"c1\"># エラーがあれば例外を発生\n</span>        <span class=\"nf\">print</span><span class=\"p\">(</span><span class=\"sh\">\"</span><span class=\"s\">記事の投稿に成功しました！</span><span class=\"sh\">\"</span><span class=\"p\">)</span>\n        <span class=\"nf\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"sh\">\"</span><span class=\"s\">投稿URL: </span><span class=\"si\">{</span><span class=\"n\">response</span><span class=\"p\">.</span><span class=\"nf\">json</span><span class=\"p\">()[</span><span class=\"sh\">'</span><span class=\"s\">url</span><span class=\"sh\">'</span><span class=\"p\">]</span><span class=\"si\">}</span><span class=\"sh\">\"</span><span class=\"p\">)</span>\n\n    <span class=\"k\">except</span> <span class=\"n\">requests</span><span class=\"p\">.</span><span class=\"n\">exceptions</span><span class=\"p\">.</span><span class=\"n\">RequestException</span> <span class=\"k\">as</span> <span class=\"n\">e</span><span class=\"p\">:</span>\n        <span class=\"nf\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"sh\">\"</span><span class=\"s\">APIリクエストエラー: </span><span class=\"si\">{</span><span class=\"n\">e</span><span class=\"si\">}</span><span class=\"sh\">\"</span><span class=\"p\">)</span>\n    <span class=\"k\">except</span> <span class=\"nb\">FileNotFoundError</span><span class=\"p\">:</span>\n        <span class=\"nf\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"sh\">\"</span><span class=\"s\">ファイルが見つかりません: </span><span class=\"si\">{</span><span class=\"n\">markdown_file_path</span><span class=\"si\">}</span><span class=\"sh\">\"</span><span class=\"p\">)</span>\n    <span class=\"k\">except</span> <span class=\"nb\">Exception</span> <span class=\"k\">as</span> <span class=\"n\">e</span><span class=\"p\">:</span>\n        <span class=\"nf\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"sh\">\"</span><span class=\"s\">予期せぬエラーが発生しました: </span><span class=\"si\">{</span><span class=\"n\">e</span><span class=\"si\">}</span><span class=\"sh\">\"</span><span class=\"p\">)</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">extract_tags</span><span class=\"p\">(</span><span class=\"n\">markdown_content</span><span class=\"p\">):</span>\n    <span class=\"sh\">\"\"\"</span><span class=\"s\">Markdown ファイルからタグを抽出する関数（例）</span><span class=\"sh\">\"\"\"</span>\n    <span class=\"c1\"># 簡単な例として、ファイル名からタグを生成\n</span>    <span class=\"c1\"># 実際には、Markdown の内容を解析してタグを抽出する処理を実装する\n</span>    <span class=\"k\">return</span> <span class=\"p\">[</span><span class=\"sh\">\"</span><span class=\"s\">\n\n生成日時: 2025-12-05 17:07:33\nステータス: draft\nタグ: Qiita, 環境構築, Python, エンジニア向け, GitHubActions, スクリプト, CI/CD, Tips, 自動化, パイプライン\n</span></code></pre></div></div>\n",
      "body": "> **対象読者**  \n> Python を利用したことがあるエンジニア、GitHub Actions を利用したことがあるエンジニア、Qiita への投稿を効率化したい方\n\n> **動作確認環境 / 前提条件**  \n> - macOS Ventura 13.6.3\n> - Python 3.11.5\n> - GitHub アカウント\n> - Qiita API v2 の理解（[公式ドキュメント](https://qiita.com/api/v2/docs)参照）\n> - 以前の記事「[Python × GitHub Actions で始める！Qiita 自動投稿パイプライン構築術](https://qiita.com/cocokara_bioinfo/items/7440c80d8e6a98177957)」の内容を理解していること\n\n> **この記事で得られること**\n> - Qiita 記事投稿を自動化する Python スクリプトの構築方法\n> - GitHub Actions を利用した CI/CD パイプラインの構築方法\n> - 自動化パイプライン構築におけるハマりどころと、その解決策\n\n\n## 実際に躓いたポイントと解決策\n\n### 1. Gemini APIのモデル名エラー\n\n**問題**: \n```\n404 models/gemini-1.5-flash is not found for API version v1beta\n```\n\n**原因**: \n- 設定ファイルで`gemini-1.5-flash`を指定していたが、実際に利用可能なモデルは`models/gemini-2.0-flash`だった\n- Google Gemini APIは定期的にモデル名が更新される\n\n**解決策**:\n```python\n# 利用可能なモデルを確認\nmodels = [m for m in genai.list_models() \n          if 'generateContent' in m.supported_generation_methods]\n# 結果: models/gemini-2.0-flash, models/gemini-2.5-flash など\n\n# 設定ファイルを更新\n{\n  \"api\": {\n    \"gemini\": {\n      \"model\": \"models/gemini-2.0-flash\"  # models/プレフィックスが必要\n    }\n  }\n}\n```\n\n**学んだこと**: APIの仕様変更に備えて、利用可能なモデルを動的に確認する仕組みを追加すべき\n\n### 2. WindowsコンソールのUnicode文字表示エラー\n\n**問題**:\n```\nUnicodeEncodeError: 'cp932' codec can't encode character '✓' in position 0\n```\n\n**原因**: \n- WindowsのPowerShellでは、Unicode文字（✓、⚠、✗）がデフォルトのエンコーディング（cp932）で表示できない\n\n**解決策**:\n```python\n# Unicode文字を通常の文字に置き換え\nprint(f\"[OK] 処理が完了しました\")  # ✓ → [OK]\nprint(f\"[WARN] 警告メッセージ\")    # ⚠ → [WARN]\nprint(f\"[ERROR] エラーが発生\")     # ✗ → [ERROR]\n```\n\n**学んだこと**: クロスプラットフォーム対応では、Unicode文字の使用を避けるか、エンコーディングを明示的に設定する\n\n### 3. Qiita APIのタグ数制限による403エラー\n\n**問題**:\n```\nHTTPエラー: 403 - {'message': 'Forbidden', 'type': 'forbidden'}\n```\n\n**原因**: \n- 動的タグ生成で9個のタグを生成していたが、Qiita APIはタグを最大5個までしか受け付けない\n- APIドキュメントを確認せずに実装していた\n\n**解決策**:\n```python\n# タグを5個に制限\nif len(tags) > 5:\n    print(f\"[WARN] タグが{len(tags)}個ありますが、Qiita APIの制限により5個に制限します\")\nqiita_tags = [{\"name\": tag} for tag in tags[:5]]\n```\n\n**学んだこと**: \n- APIの仕様を事前に確認する重要性\n- エラーメッセージが不十分な場合、リクエスト内容を詳細にログ出力して原因を特定する\n\n### 4. LLMプロンプトの設計ミス\n\n**問題**: \n- タイトル案を3つ生成していたが、実際のタイトルが「使用例」になってしまった\n- パース処理でタイトルが正しく抽出できなかった\n\n**原因**:\n- プロンプトで「タイトル案（3つ）」を指示していたが、実際のタイトルを明確に指定していなかった\n- パース処理がタイトル案セクションをスキップできていなかった\n\n**解決策**:\n```markdown\n# プロンプトの修正\n**重要**: 記事の最初の行に、実際に使用するタイトルを`# `で始まるMarkdownの見出し形式で記述してください。\n\nタイトル案は不要です。最初の`# `行がそのまま記事のタイトルとして使用されます。\n```\n\n```python\n# パース処理の改善\nskip_title_section = False\nfor line in lines:\n    # タイトル案セクションを検出してスキップ\n    if \"タイトル案\" in line:\n        skip_title_section = True\n        continue\n    \n    # 最初の`# `で始まる行をタイトルとして取得\n    if not found_main_title and line.startswith(\"# \"):\n        title = line.replace(\"# \", \"\").strip()\n        found_main_title = True\n```\n\n**学んだこと**: \n- LLMへのプロンプトは明確で具体的な指示が必要\n- 出力形式を厳密に指定することで、パース処理を簡潔にできる\n\n### 5. エラーハンドリングの不足\n\n**問題**: \n- 403エラーが発生した際、原因が特定しづらかった\n- デバッグ情報が不足していた\n\n**解決策**:\n```python\n# デバッグ情報の追加\nprint(f\"[DEBUG] アクセストークン: {token_preview}\")\nprint(f\"[DEBUG] リクエストURL: {self.base_url}/items\")\nprint(f\"[DEBUG] ペイロード: title={title[:50]}, tags={len(tags)}個\")\nprint(f\"[DEBUG] レスポンスステータス: {response.status_code}\")\n\n# エラーメッセージの改善\nif e.response.status_code == 403:\n    error_msg += \"\n\n考えられる原因:\"\n    error_msg += \"\n- アクセストークンのスコープが不足しています\"\n    error_msg += \"\n- タグ数が5個を超えています（Qiita APIの制限）\"\n```\n\n**学んだこと**: \n- エラー発生時には、リクエスト内容とレスポンスを詳細にログ出力する\n- よくあるエラーについては、解決策を提示する\n\n## 工夫したポイント\n\n### 1. プロンプト管理システム\n\nプロンプトをMarkdownファイルとして管理し、変数置換に対応：\n\n```python\n# data/prompts/article_generation_prompt.md\nトピック: {topic}\nリサーチ結果: {research_results}\n過去の投稿: {past_articles_summary}\n\n# 使用例\nprompt = template.format(\n    topic=selected_topic,\n    research_results=research_results,\n    past_articles_summary=past_articles_summary\n)\n```\n\n**メリット**: \n- プロンプトの変更が容易\n- バージョン管理がしやすい\n- 複数のプロンプトを管理できる\n\n### 2. 過去の投稿参照機能\n\n過去のQiita投稿を取得し、ストーリー性のある記事を生成：\n\n```python\n# 過去の投稿を取得\nfetcher = QiitaFetcher()\nitems = fetcher.fetch_all_my_items(days_back=180)\n\n# 記事生成時に参照\npast_articles_summary = qiita_items_manager.get_items_summary(limit=10)\n```\n\n**メリット**: \n- 連続性のある記事シリーズを構築できる\n- 読者が「次も読みたい」と思える内容になる\n- 過去の投稿への参照リンクを自動生成\n\n### 3. 動的タグ生成\n\n記事内容に応じてLLMが自動的にタグを生成：\n\n```python\ndef generate_dynamic_tags(title: str, content: str) -> List[str]:\n    # 記事のタイトルと内容を分析してタグを生成\n    # 言語・ツール系、目的・行為ベース、プラットフォーム系など\n    # カテゴリから適切なタグを選ぶ\n```\n\n**メリット**: \n- 記事内容に最適なタグが自動生成される\n- 手動でのタグ付けが不要\n- タグの漏れを防げる\n\n### 4. モジュール化とエラーハンドリング\n\n各機能を独立したモジュールに分割し、エラーハンドリングを強化：\n\n```python\n# 各モジュールが独立して動作\n- research/collector.py      # リサーチ機能\n- generator/article_generator.py  # 記事生成\n- publisher/qiita_publisher.py    # 投稿機能\n- storage/article_manager.py      # 記事管理\n```\n\n**メリット**: \n- テストが容易\n- 機能の追加・変更が容易\n- エラーの影響範囲を限定できる\n\n## 参考文献\n\n- [Qiita API v2 ドキュメント](https://qiita.com/api/v2/docs)\n  - タグの制限（最大5個）などの仕様を確認\n\n- [Google Gemini API ドキュメント](https://ai.google.dev/docs)\n  - 利用可能なモデル一覧とAPIの使い方\n\n- [Python requests ライブラリ](https://requests.readthedocs.io/)\n  - HTTPリクエストのエラーハンドリング方法\n\n- [python-dotenv ドキュメント](https://github.com/theskumar/python-dotenv)\n  - 環境変数の管理方法\n\n- [Qiita API を利用した記事投稿の実装例](https://qiita.com/iimuz/items/4837e9c8043ce7c1262b)\n  - アクセストークンの取得方法と投稿の実装\n\n## まとめ\n\n今回の開発を通じて、以下の点を学びました：\n\n1. **APIの仕様を事前に確認する重要性**: タグ数の制限など、APIの制約を理解しておく\n2. **エラーハンドリングの重要性**: デバッグ情報を充実させ、原因特定を容易にする\n3. **プロンプト設計の重要性**: LLMへの指示は明確で具体的にする\n4. **クロスプラットフォーム対応**: Unicode文字の使用に注意する\n5. **モジュール化の重要性**: 機能を分割し、テストとメンテナンスを容易にする\n\nこれらの経験を活かして、より堅牢なシステムを構築していきたいと思います。\n\n\n\n## 🧭 導入：背景・課題・なぜ重要か\n\n「記事書くの、めんどくさい…」\n\nエンジニアなら誰しも一度は思ったことがあるのではないでしょうか？特に Qiita のような技術情報共有プラットフォームでは、継続的なアウトプットが重要だと分かっていても、ついつい後回しにしてしまいがちです。\n\n以前の記事「[Python × GitHub Actions で始める！Qiita 自動投稿パイプライン構築術](https://qiita.com/cocokara_bioinfo/items/7440c80d8e6a98177957)」では、Qiita への記事投稿を自動化する基本的なパイプラインを構築しました。しかし、実際に運用してみると、いくつかの課題が見えてきました。\n\n*   **ローカル環境との差異**: ローカルで動いていたスクリプトが GitHub Actions 上で動かない…あるあるですよね。\n*   **エラーハンドリングの甘さ**: エラーが発生した場合に、どこが原因なのか特定しにくい…デバッグ地獄！\n*   **API レート制限**: Qiita API のレート制限に引っかかって投稿が失敗する…焦る！\n\nこれらの課題を解決し、より安定した自動投稿パイプラインを構築するために、試行錯誤した過程を共有したいと思います。今回の記事では、これらの **“あるある” な課題** に焦点を当て、具体的な解決策と、さらに効率的な運用方法を紹介します。\n\n## 📘 トピックの概要（専門外にも分かる説明）\n\n今回のテーマは、**Qiita 記事の自動投稿パイプライン構築** です。\n\n**パイプライン** とは、一連の処理を自動的に実行する仕組みのことです。今回の場合は、以下のような流れになります。\n\n1.  記事の Markdown ファイルを GitHub リポジトリに push\n2.  GitHub Actions が push を検知して自動的にスクリプトを実行\n3.  スクリプトが Qiita API を利用して記事を投稿\n\nこのパイプラインを構築することで、記事を書いたら GitHub に push するだけで Qiita に投稿されるようになります。\n\n今回の記事では、特に以下の点に焦点を当てて解説します。\n\n*   **環境構築**: GitHub Actions 上で Python スクリプトを実行するための環境構築\n*   **エラーハンドリング**: エラーが発生した場合に、原因を特定しやすくするための工夫\n*   **レート制限対策**: Qiita API のレート制限に引っかからないようにするための対策\n\n## 🔧 技術的な仕組み・実装・アーキテクチャ\n\n今回のパイプラインは、主に以下の要素で構成されています。\n\n1.  **Python スクリプト**: Qiita API を利用して記事を投稿するスクリプト\n2.  **GitHub Actions**: GitHub の CI/CD サービス。push をトリガーにしてスクリプトを実行\n3.  **Qiita API**: Qiita の記事投稿 API\n\n**Python スクリプト** は、Markdown ファイルを読み込み、Qiita API に必要な情報を整形してリクエストを送信します。\n\n**GitHub Actions** は、`.github/workflows` ディレクトリに YAML ファイルを配置することで、様々なイベントをトリガーにして処理を実行できます。今回は、`push` イベントをトリガーにして、Python スクリプトを実行します。\n\n**Qiita API** は、記事の投稿、更新、削除などを行うための API です。API を利用するためには、事前に Qiita でアクセストークンを取得する必要があります。\n\n### メリット・デメリット\n\n**メリット**:\n\n*   記事投稿の手間を大幅に削減できる\n*   継続的なアウトプットを促進できる\n*   チームでの記事作成を効率化できる\n\n**デメリット**:\n\n*   初期構築に手間がかかる\n*   API のレート制限に注意する必要がある\n*   スクリプトのメンテナンスが必要\n\n### ハマりポイント・注意点\n\n*   **環境変数**: GitHub Actions 上で環境変数を設定する必要がある\n*   **依存関係**: 必要な Python ライブラリを `requirements.txt` に記述する必要がある\n*   **エラーハンドリング**: エラーが発生した場合に、原因を特定できるようにログを出力するようにする\n\n## 🧪 実践編：動くコード／コマンド例\n\n### 1. 環境構築\n\nまず、必要な Python ライブラリをインストールします。\n\n```bash\n# 必要なライブラリをインストール\npip install requests python-dotenv\n```\n\n次に、GitHub リポジトリに `.github/workflows/qiita_post.yml` ファイルを作成し、以下の内容を記述します。\n\n```yaml\nname: Qiita Post\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  qiita_post:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - name: Set up Python 3.11\n        uses: actions/setup-python@v3\n        with:\n          python-version: \"3.11\"\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install -r requirements.txt\n      - name: Run Qiita Post Script\n        env:\n          QIITA_ACCESS_TOKEN: ${{ secrets.QIITA_ACCESS_TOKEN }}\n        run: python qiita_post.py\n```\n\n`QIITA_ACCESS_TOKEN` は、GitHub リポジトリの Secrets に登録する必要があります。\n\n### 2. Python スクリプト\n\n次に、`qiita_post.py` ファイルを作成し、以下の内容を記述します。\n\n```python\nimport os\nimport requests\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nQIITA_ACCESS_TOKEN = os.environ.get(\"QIITA_ACCESS_TOKEN\")\nQIITA_API_ENDPOINT = \"https://qiita.com/api/v2/items\"\n\ndef post_to_qiita(markdown_file_path):\n    \"\"\"Qiita に記事を投稿する関数\"\"\"\n    try:\n        with open(markdown_file_path, \"r\", encoding=\"utf-8\") as f:\n            markdown_content = f.read()\n\n        # タイトルを抽出 (最初の行が # で始まる場合)\n        lines = markdown_content.splitlines()\n        title = lines[0].replace(\"# \", \"\") if lines and lines[0].startswith(\"# \") else \"No Title\"\n\n        # Markdown ファイルから必要な情報を抽出\n        body = markdown_content\n        tags = extract_tags(markdown_content) # タグを抽出する関数は別途定義\n\n        # Qiita API に投稿\n        headers = {\n            \"Authorization\": f\"Bearer {QIITA_ACCESS_TOKEN}\",\n            \"Content-Type\": \"application/json\",\n        }\n        data = {\n            \"title\": title,\n            \"body\": body,\n            \"tags\": [{\"name\": tag} for tag in tags],\n            \"private\": False,  # 公開設定\n        }\n        response = requests.post(QIITA_API_ENDPOINT, headers=headers, json=data)\n\n        # レスポンスを確認\n        response.raise_for_status()  # エラーがあれば例外を発生\n        print(\"記事の投稿に成功しました！\")\n        print(f\"投稿URL: {response.json()['url']}\")\n\n    except requests.exceptions.RequestException as e:\n        print(f\"APIリクエストエラー: {e}\")\n    except FileNotFoundError:\n        print(f\"ファイルが見つかりません: {markdown_file_path}\")\n    except Exception as e:\n        print(f\"予期せぬエラーが発生しました: {e}\")\n\ndef extract_tags(markdown_content):\n    \"\"\"Markdown ファイルからタグを抽出する関数（例）\"\"\"\n    # 簡単な例として、ファイル名からタグを生成\n    # 実際には、Markdown の内容を解析してタグを抽出する処理を実装する\n    return [\"\n\n生成日時: 2025-12-05 17:07:33\nステータス: draft\nタグ: Qiita, 環境構築, Python, エンジニア向け, GitHubActions, スクリプト, CI/CD, Tips, 自動化, パイプライン\n",
      "coediting": false,
      "comments_count": 0,
      "created_at": "2025-12-05T17:09:48+09:00",
      "group": null,
      "id": "4bd415ef2f801497951e",
      "likes_count": 0,
      "private": false,
      "reactions_count": 0,
      "stocks_count": 0,
      "tags": [
        {
          "name": "Qiita",
          "versions": []
        },
        {
          "name": "Python",
          "versions": []
        },
        {
          "name": "環境構築",
          "versions": []
        },
        {
          "name": "エンジニア向け",
          "versions": []
        },
        {
          "name": "GitHubActions",
          "versions": []
        }
      ],
      "title": "【ハマりどころ満載】PythonでQiita記事投稿を自動化するパイプライン構築で爆速改善！",
      "updated_at": "2025-12-05T17:09:48+09:00",
      "url": "https://qiita.com/cocokara_bioinfo/items/4bd415ef2f801497951e",
      "user": {
        "description": "ポッケ村出身の名もなき若手生物学研究員です。\r\n現代の技術やエンジニア知識を学びながらモンスターハンターの生態・生物学研究に日々励んでおります！\r\nまだまだ勉強不足なところはありますが、皆さんに少しでも学びになるものをお届けできればとの思いで発信させていただきます\r\n\r\n※フィクションとして、時にTips記事として楽しんでいただければ幸いです",
        "facebook_id": "",
        "followees_count": 3,
        "followers_count": 0,
        "github_login_name": null,
        "id": "cocokara_bioinfo",
        "items_count": 4,
        "linkedin_id": "",
        "location": "",
        "name": "シャル・S 調査員",
        "organization": "Genome & Ecology Monster-Lab (架空)",
        "permanent_id": 4288059,
        "profile_image_url": "https://lh3.googleusercontent.com/a/ACg8ocLkgrrRuDzozKQ4XeInetzc0um1rPWRGXY2daT9pLIi1z1JdQ=s96-c",
        "team_only": false,
        "twitter_screen_name": null,
        "website_url": ""
      },
      "page_views_count": 130,
      "team_membership": null,
      "organization_url_name": null,
      "slide": false,
      "_source": "my_popular"
    }
  ]
}